(dp1
S'talk_transcript'
p2
(lp3
(lp4
VI write fiction sci-fi thrillers,
p5
aVso if I say "killer robots,"
p6
aVyou'd probably think something like this.
p7
aVBut I'm actually not here to talk about fiction.
p8
aVI'm here to talk about very real killer robots,
p9
aVautonomous combat drones.
p10
aa(lp11
VNow, I'm not referring to Predator and Reaper drones,
p12
aVwhich have a human making targeting decisions.
p13
aVI'm talking about fully autonomous robotic weapons
p14
aVthat make lethal decisions about human beings
p15
aVall on their own.
p16
aVThere's actually a technical term for this: lethal autonomy.
p17
aa(lp18
VNow, lethally autonomous killer robots
p19
aVwould take many forms \u2014 flying, driving,
p20
aVor just lying in wait.
p21
aVAnd actually, they're very quickly becoming a reality.
p22
aVThese are two automatic sniper stations
p23
aVcurrently deployed in the DMZ between North and South Korea.
p24
aVBoth of these machines are capable of automatically
p25
aVidentifying a human target and firing on it,
p26
aVthe one on the left at a distance of over a kilometer.
p27
aVNow, in both cases, there's still a human in the loop
p28
aVto make that lethal firing decision,
p29
aVbut it's not a technological requirement. It's a choice.
p30
aVAnd it's that choice that I want to focus on,
p31
aVbecause as we migrate lethal decision-making
p32
aVfrom humans to software,
p33
aVwe risk not only taking the humanity out of war,
p34
aVbut also changing our social landscape entirely,
p35
aVfar from the battlefield.
p36
aVThat's because the way humans resolve conflict
p37
aVshapes our social landscape.
p38
aVAnd this has always been the case, throughout history.
p39
aa(lp40
VFor example, these were state-of-the-art weapons systems
p41
aVin 1400 A.D.
p42
aVNow they were both very expensive to build and maintain,
p43
aVbut with these you could dominate the populace,
p44
aVand the distribution of political power in feudal society reflected that.
p45
aVPower was focused at the very top.
p46
aVAnd what changed? Technological innovation.
p47
aVGunpowder, cannon.
p48
aVAnd pretty soon, armor and castles were obsolete,
p49
aVand it mattered less who you brought to the battlefield
p50
aVversus how many people you brought to the battlefield.
p51
aVAnd as armies grew in size, the nation-state arose
p52
aVas a political and logistical requirement of defense.
p53
aVAnd as leaders had to rely on more of their populace,
p54
aVthey began to share power.
p55
aVRepresentative government began to form.
p56
aa(lp57
VSo again, the tools we use to resolve conflict
p58
aVshape our social landscape.
p59
aVAutonomous robotic weapons are such a tool,
p60
aVexcept that, by requiring very few people to go to war,
p61
aVthey risk re-centralizing power into very few hands,
p62
aVpossibly reversing a five-century trend toward democracy.
p63
aa(lp64
VNow, I think, knowing this,
p65
aVwe can take decisive steps to preserve our democratic institutions,
p66
aVto do what humans do best, which is adapt.
p67
aVBut time is a factor.
p68
aVSeventy nations are developing remotely-piloted
p69
aVcombat drones of their own,
p70
aVand as you'll see, remotely-piloted combat drones
p71
aVare the precursors to autonomous robotic weapons.
p72
aVThat's because once you've deployed remotely-piloted drones,
p73
aVthere are three powerful factors pushing decision-making
p74
aVaway from humans and on to the weapon platform itself.
p75
aa(lp76
VThe first of these is the deluge of video that drones produce.
p77
aVFor example, in 2004, the U.S. drone fleet produced
p78
aVa grand total of 71 hours of video surveillance for analysis.
p79
aVBy 2011, this had gone up to 300,000 hours,
p80
aVoutstripping human ability to review it all,
p81
aVbut even that number is about to go up drastically.
p82
aVThe Pentagon's Gorgon Stare and Argus programs
p83
aVwill put up to 65 independently operated camera eyes
p84
aVon each drone platform,
p85
aVand this would vastly outstrip human ability to review it.
p86
aVAnd that means visual intelligence software will need
p87
aVto scan it for items of interest.
p88
aVAnd that means very soon
p89
aVdrones will tell humans what to look at,
p90
aVnot the other way around.
p91
aa(lp92
VBut there's a second powerful incentive pushing
p93
aVdecision-making away from humans and onto machines,
p94
aVand that's electromagnetic jamming,
p95
aVsevering the connection between the drone
p96
aVand its operator.
p97
aVNow we saw an example of this in 2011
p98
aVwhen an American RQ-170 Sentinel drone
p99
aVgot a bit confused over Iran due to a GPS spoofing attack,
p100
aVbut any remotely-piloted drone is susceptible to this type of attack,
p101
aVand that means drones
p102
aVwill have to shoulder more decision-making.
p103
aVThey'll know their mission objective,
p104
aVand they'll react to new circumstances without human guidance.
p105
aVThey'll ignore external radio signals
p106
aVand send very few of their own.
p107
aa(lp108
VWhich brings us to, really, the third
p109
aVand most powerful incentive pushing decision-making
p110
aVaway from humans and onto weapons:
p111
aVplausible deniability.
p112
aVNow we live in a global economy.
p113
aVHigh-tech manufacturing is occurring on most continents.
p114
aVCyber espionage is spiriting away advanced designs
p115
aVto parts unknown,
p116
aVand in that environment, it is very likely
p117
aVthat a successful drone design will be knocked off in contract factories,
p118
aVproliferate in the gray market.
p119
aVAnd in that situation, sifting through the wreckage
p120
aVof a suicide drone attack, it will be very difficult to say
p121
aVwho sent that weapon.
p122
aa(lp123
VThis raises the very real possibility
p124
aVof anonymous war.
p125
aVThis could tilt the geopolitical balance on its head,
p126
aVmake it very difficult for a nation to turn its firepower
p127
aVagainst an attacker, and that could shift the balance
p128
aVin the 21st century away from defense and toward offense.
p129
aVIt could make military action a viable option
p130
aVnot just for small nations,
p131
aVbut criminal organizations, private enterprise,
p132
aVeven powerful individuals.
p133
aVIt could create a landscape of rival warlords
p134
aVundermining rule of law and civil society.
p135
aVNow if responsibility and transparency
p136
aVare two of the cornerstones of representative government,
p137
aVautonomous robotic weapons could undermine both.
p138
aa(lp139
VNow you might be thinking that
p140
aVcitizens of high-tech nations
p141
aVwould have the advantage in any robotic war,
p142
aVthat citizens of those nations would be less vulnerable,
p143
aVparticularly against developing nations.
p144
aVBut I think the truth is the exact opposite.
p145
aVI think citizens of high-tech societies
p146
aVare more vulnerable to robotic weapons,
p147
aVand the reason can be summed up in one word: data.
p148
aVData powers high-tech societies.
p149
aVCell phone geolocation, telecom metadata,
p150
aVsocial media, email, text, financial transaction data,
p151
aVtransportation data, it's a wealth of real-time data
p152
aVon the movements and social interactions of people.
p153
aVIn short, we are more visible to machines
p154
aVthan any people in history,
p155
aVand this perfectly suits the targeting needs of autonomous weapons.
p156
aa(lp157
VWhat you're looking at here
p158
aVis a link analysis map of a social group.
p159
aVLines indicate social connectedness between individuals.
p160
aVAnd these types of maps can be automatically generated
p161
aVbased on the data trail modern people leave behind.
p162
aVNow it's typically used to market goods and services
p163
aVto targeted demographics, but it's a dual-use technology,
p164
aVbecause targeting is used in another context.
p165
aVNotice that certain individuals are highlighted.
p166
aVThese are the hubs of social networks.
p167
aVThese are organizers, opinion-makers, leaders,
p168
aVand these people also can be automatically identified
p169
aVfrom their communication patterns.
p170
aVNow, if you're a marketer, you might then target them
p171
aVwith product samples, try to spread your brand
p172
aVthrough their social group.
p173
aVBut if you're a repressive government
p174
aVsearching for political enemies, you might instead remove them,
p175
aVeliminate them, disrupt their social group,
p176
aVand those who remain behind lose social cohesion
p177
aVand organization.
p178
aVNow in a world of cheap, proliferating robotic weapons,
p179
aVborders would offer very little protection
p180
aVto critics of distant governments
p181
aVor trans-national criminal organizations.
p182
aVPopular movements agitating for change
p183
aVcould be detected early and their leaders eliminated
p184
aVbefore their ideas achieve critical mass.
p185
aVAnd ideas achieving critical mass
p186
aVis what political activism in popular government is all about.
p187
aVAnonymous lethal weapons could make lethal action
p188
aVan easy choice for all sorts of competing interests.
p189
aVAnd this would put a chill on free speech
p190
aVand popular political action, the very heart of democracy.
p191
aa(lp192
VAnd this is why we need an international treaty
p193
aVon robotic weapons, and in particular a global ban
p194
aVon the development and deployment of killer robots.
p195
aVNow we already have international treaties
p196
aVon nuclear and biological weapons, and, while imperfect,
p197
aVthese have largely worked.
p198
aVBut robotic weapons might be every bit as dangerous,
p199
aVbecause they will almost certainly be used,
p200
aVand they would also be corrosive to our democratic institutions.
p201
aa(lp202
VNow in November 2012 the U.S. Department of Defense
p203
aVissued a directive requiring
p204
aVa human being be present in all lethal decisions.
p205
aVThis temporarily effectively banned autonomous weapons in the U.S. military,
p206
aVbut that directive needs to be made permanent.
p207
aVAnd it could set the stage for global action.
p208
aVBecause we need an international legal framework
p209
aVfor robotic weapons.
p210
aVAnd we need it now, before there's a devastating attack
p211
aVor a terrorist incident that causes nations of the world
p212
aVto rush to adopt these weapons
p213
aVbefore thinking through the consequences.
p214
aVAutonomous robotic weapons concentrate too much power
p215
aVin too few hands, and they would imperil democracy itself.
p216
aa(lp217
VNow, don't get me wrong, I think there are tons
p218
aVof great uses for unarmed civilian drones:
p219
aVenvironmental monitoring, search and rescue, logistics.
p220
aVIf we have an international treaty on robotic weapons,
p221
aVhow do we gain the benefits of autonomous drones
p222
aVand vehicles while still protecting ourselves
p223
aVagainst illegal robotic weapons?
p224
aa(lp225
VI think the secret will be transparency.
p226
aVNo robot should have an expectation of privacy
p227
aVin a public place.
p228
aa(lp229
V(Applause)
p230
aa(lp231
VEach robot and drone should have
p232
aVa cryptographically signed I.D. burned in at the factory
p233
aVthat can be used to track its movement through public spaces.
p234
aVWe have license plates on cars, tail numbers on aircraft.
p235
aVThis is no different.
p236
aVAnd every citizen should be able to download an app
p237
aVthat shows the population of drones and autonomous vehicles
p238
aVmoving through public spaces around them,
p239
aVboth right now and historically.
p240
aVAnd civic leaders should deploy sensors and civic drones
p241
aVto detect rogue drones,
p242
aVand instead of sending killer drones of their own up to shoot them down,
p243
aVthey should notify humans to their presence.
p244
aVAnd in certain very high-security areas,
p245
aVperhaps civic drones would snare them
p246
aVand drag them off to a bomb disposal facility.
p247
aa(lp248
VBut notice, this is more an immune system
p249
aVthan a weapons system.
p250
aVIt would allow us to avail ourselves of the use
p251
aVof autonomous vehicles and drones
p252
aVwhile still preserving our open, civil society.
p253
aa(lp254
VWe must ban the deployment and development
p255
aVof killer robots.
p256
aVLet's not succumb to the temptation to automate war.
p257
aVAutocratic governments and criminal organizations
p258
aVundoubtedly will, but let's not join them.
p259
aVAutonomous robotic weapons
p260
aVwould concentrate too much power
p261
aVin too few unseen hands,
p262
aVand that would be corrosive to representative government.
p263
aVLet's make sure, for democracies at least,
p264
aVkiller robots remain fiction.
p265
aa(lp266
VThank you.
p267
aa(lp268
V(Applause)
p269
aVThank you. (Applause)
p270
aasS'transcript_micsec'
p271
(lp272
I11000
aI28000
aI47000
aI113000
aI161000
aI188000
aI223000
aI272000
aI320000
aI363000
aI409000
aI466000
aI575000
aI606000
aI657000
aI679000
aI690000
aI695000
aI738000
aI751000
aI782000
aI783000
asS'talk_meta'
p273
(dp274
S'ratings'
p275
(dp276
S'ingenious'
p277
I16
sS'funny'
p278
I2
sS'inspiring'
p279
I37
sS'ok'
p280
I9
sS'fascinating'
p281
I81
sS'total_count'
p282
I678
sS'persuasive'
p283
I195
sS'longwinded'
p284
I4
sS'informative'
p285
I191
sS'beautiful'
p286
I7
sS'jaw-dropping'
p287
I59
sS'obnoxious'
p288
I10
sS'confusing'
p289
I5
sS'courageous'
p290
I34
sS'unconvincing'
p291
I28
ssS'author'
p292
VDaniel_Suarez;
p293
sS'url'
p294
S'https://www.ted.com/talks/daniel_suarez_the_kill_decision_shouldn_t_belong_to_a_robot'
p295
sS'vidlen'
p296
I800
sS'totalviews'
p297
I1910087
sS'title'
p298
VThe kill decision shouldn't belong to a robot
p299
sS'downloadlink'
p300
Vhttps://download.ted.com/talks/DanielSuarez_2013G.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22
p301
sS'datepublished'
p302
cdatetime
datetime
p303
(S'\x07\xdd\x06\r\x060\x10\x00\x00\x00'
tRp304
sS'datefilmed'
p305
g303
(S'\x07\xdd\x06\r\x060\x10\x00\x00\x00'
tRp306
sS'alldata_JSON'
p307
S'{"viewed_count": 1910087, "speakers": [{"description": "Sci-fi author", "firstname": "Daniel", "title": "", "lastname": "Suarez", "middleinitial": "", "whylisten": "<p>While working as a software developer, Daniel Suarez self-published <a href=\\"http://geni.us/daemon\\" target=\\"_blank\\"><em>Daemon</em></a>, a cyber-thriller depicting a future where society is radically reshaped by disruptive technologies. It struck a chord -- and so did the sequel, <a href=\\"http://geni.us/freedom\\" target=\\"_blank\\"><em>Freedom (TM)</em></a>  -- rocketing Suarez into the pantheon of sci-fi prophets.<br /><br />In his 2012 novel <a href=\\"http://geni.us/killdecision\\" target=\\"_blank\\"><em>Kill Decision</em></a>, Suarez digs into the consequences of technology that&rsquo;s here to stay: autonomous bots and drones programmed to be lethal. Suarez argues that as we cede more control to software, we gamble with the very essence of democracy itself. How can we establish sane guidelines for technology that could easily outstrip our control?</p>", "slug": "daniel_suarez", "whotheyare": "Daniel Suarez concocts thrilling reads from terrifying (and not-so-farfetched) near-future scenarios.", "whatotherssay": "\'Kill Decision\' is an eyes-wide-open, eyebrows raised, head shaking warning. The book may have come to a satisfactory end ... but the real story is unfolding as you read this, with technologies both real and under development.", "id": 1571, "photo_url": "https://pe.tedcdn.com/images/ted/c98cabcd7e8a48854617ea560f7490b792fffcc9_254x191.jpg"}], "current_talk": 1766, "description": "As a novelist, Daniel Suarez spins dystopian tales of the future. But on the TEDGlobal stage, he talks us through a real-life scenario we all need to know more about: the rise of autonomous robotic weapons of war. Advanced drones, automated weapons and AI-powered intelligence-gathering tools, he suggests, could take the decision to make war out of the hands of humans.", "language": "en", "url": "https://www.ted.com/talks/daniel_suarez_the_kill_decision_shouldn_t_belong_to_a_robot", "media": {"internal": {"podcast-high-en": {"uri": "https://download.ted.com/talks/DanielSuarez_2013G-480p-en.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 93667174}, "podcast-low-en": {"uri": "https://download.ted.com/talks/DanielSuarez_2013G-low-en.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 18444473}, "podcast-high": {"uri": "https://download.ted.com/talks/DanielSuarez_2013G-480p.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 94067839}, "180k": {"uri": "https://download.ted.com/talks/DanielSuarez_2013G-180k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 18181960}, "64k": {"uri": "https://download.ted.com/talks/DanielSuarez_2013G-64k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 6570046}, "1500k": {"uri": "https://download.ted.com/talks/DanielSuarez_2013G-1500k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 145856713}, "450k": {"uri": "https://download.ted.com/talks/DanielSuarez_2013G-450k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 45373854}, "podcast-regular": {"uri": "https://download.ted.com/talks/DanielSuarez_2013G.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 45661517}, "950k": {"uri": "https://download.ted.com/talks/DanielSuarez_2013G-950k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 93656662}, "audio-podcast": {"uri": "https://download.ted.com/talks/DanielSuarez_2013G.mp3?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "audio/mp3", "filesize_bytes": 8214518}, "podcast-light": {"uri": "https://download.ted.com/talks/DanielSuarez_2013G-light.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 6707517}, "320k": {"uri": "https://download.ted.com/talks/DanielSuarez_2013G-320k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 32230829}, "600k": {"uri": "https://download.ted.com/talks/DanielSuarez_2013G-600k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 60702621}}}, "comments": {"count": 154, "id": 20690, "talk_id": 1766}, "slug": "daniel_suarez_the_kill_decision_shouldn_t_belong_to_a_robot", "threadId": 20690, "talks": [{"event": "TEDGlobal 2013", "player_talks": [{"event": "TEDGlobal 2013", "slug": "daniel_suarez_the_kill_decision_shouldn_t_belong_to_a_robot", "filmed": 1370908800, "targeting": {"event": "TEDGlobal 2013", "tag": "drones,entertainment,robots,technology,war,writing", "id": 1766, "talk": "daniel_suarez_the_kill_decision_shouldn_t_belong_to_a_robot", "year": "2013"}, "adDuration": "3.33", "external": null, "title": "The kill decision shouldn\'t belong to a robot", "postAdDuration": "0.83", "published": 1371120496, "thumb": "https://pi.tedcdn.com/r/pe.tedcdn.com/images/ted/b15f33c6694783ada082bb6afc53b762cd014d2f_1600x1200.jpg?quality=89&w=600", "name": "Daniel Suarez: The kill decision shouldn\'t belong to a robot", "languages": [{"languageCode": "ar", "endonym": "\\u0627\\u0644\\u0639\\u0631\\u0628\\u064a\\u0629", "isRtl": true, "ianaCode": "ar", "languageName": "Arabic"}, {"languageCode": "zh-cn", "endonym": "\\u4e2d\\u6587 (\\u7b80\\u4f53)", "isRtl": false, "ianaCode": "zh-Hans", "languageName": "Chinese, Simplified"}, {"languageCode": "zh-tw", "endonym": "\\u4e2d\\u6587 (\\u7e41\\u9ad4)", "isRtl": false, "ianaCode": "zh-Hant", "languageName": "Chinese, Traditional"}, {"languageCode": "cs", "endonym": "\\u010ce\\u0161tina", "isRtl": false, "ianaCode": "cs", "languageName": "Czech"}, {"languageCode": "nl", "endonym": "Nederlands", "isRtl": false, "ianaCode": "nl", "languageName": "Dutch"}, {"languageCode": "en", "endonym": "English", "isRtl": false, "ianaCode": "en", "languageName": "English"}, {"languageCode": "fr", "endonym": "Fran\\u00e7ais", "isRtl": false, "ianaCode": "fr", "languageName": "French"}, {"languageCode": "de", "endonym": "Deutsch", "isRtl": false, "ianaCode": "de", "languageName": "German"}, {"languageCode": "el", "endonym": "\\u0395\\u03bb\\u03bb\\u03b7\\u03bd\\u03b9\\u03ba\\u03ac", "isRtl": false, "ianaCode": "el", "languageName": "Greek"}, {"languageCode": "he", "endonym": "\\u05e2\\u05d1\\u05e8\\u05d9\\u05ea", "isRtl": true, "ianaCode": "he", "languageName": "Hebrew"}, {"languageCode": "hu", "endonym": "Magyar", "isRtl": false, "ianaCode": "hu", "languageName": "Hungarian"}, {"languageCode": "it", "endonym": "Italiano", "isRtl": false, "ianaCode": "it", "languageName": "Italian"}, {"languageCode": "ja", "endonym": "\\u65e5\\u672c\\u8a9e", "isRtl": false, "ianaCode": "ja", "languageName": "Japanese"}, {"languageCode": "ko", "endonym": "\\ud55c\\uad6d\\uc5b4", "isRtl": false, "ianaCode": "ko", "languageName": "Korean"}, {"languageCode": "fa", "endonym": "\\u0641\\u0627\\u0631\\u0633\\u0649", "isRtl": true, "ianaCode": "fa", "languageName": "Persian"}, {"languageCode": "pl", "endonym": "Polski", "isRtl": false, "ianaCode": "pl", "languageName": "Polish"}, {"languageCode": "pt", "endonym": "Portugu\\u00eas de Portugal", "isRtl": false, "ianaCode": "pt", "languageName": "Portuguese"}, {"languageCode": "pt-br", "endonym": "Portugu\\u00eas brasileiro", "isRtl": false, "ianaCode": "pt-BR", "languageName": "Portuguese, Brazilian"}, {"languageCode": "ro", "endonym": "Rom\\u00e2n\\u0103", "isRtl": false, "ianaCode": "ro", "languageName": "Romanian"}, {"languageCode": "ru", "endonym": "\\u0420\\u0443\\u0441\\u0441\\u043a\\u0438\\u0439", "isRtl": false, "ianaCode": "ru", "languageName": "Russian"}, {"languageCode": "sr", "endonym": "\\u0421\\u0440\\u043f\\u0441\\u043a\\u0438, Srpski", "isRtl": false, "ianaCode": "sr", "languageName": "Serbian"}, {"languageCode": "es", "endonym": "Espa\\u00f1ol", "isRtl": false, "ianaCode": "es", "languageName": "Spanish"}, {"languageCode": "sv", "endonym": "Svenska", "isRtl": false, "ianaCode": "sv", "languageName": "Swedish"}, {"languageCode": "th", "endonym": "\\u0e20\\u0e32\\u0e29\\u0e32\\u0e44\\u0e17\\u0e22", "isRtl": false, "ianaCode": "th", "languageName": "Thai"}, {"languageCode": "tr", "endonym": "T\\u00fcrk\\u00e7e", "isRtl": false, "ianaCode": "tr", "languageName": "Turkish"}, {"languageCode": "uk", "endonym": "\\u0423\\u043a\\u0440\\u0430\\u0457\\u043d\\u0441\\u044c\\u043a\\u0430", "isRtl": false, "ianaCode": "uk", "languageName": "Ukrainian"}, {"languageCode": "vi", "endonym": "Ti\\u1ebfng Vi\\u1ec7t", "isRtl": false, "ianaCode": "vi", "languageName": "Vietnamese"}], "nativeLanguage": "en", "tags": ["drones", "entertainment", "robots", "technology", "war", "writing"], "speaker": "Daniel Suarez", "isSubtitleRequired": false, "introDuration": 11.82, "duration": 800, "id": 1766, "resources": {"h264": [{"bitrate": 320, "file": "https://download.ted.com/talks/DanielSuarez_2013G-320k.mp4?dnt"}], "hls": {"maiTargeting": {"event": "TEDGlobal 2013", "tag": "drones,entertainment,robots,technology,war,writing", "id": 1766, "talk": "daniel_suarez_the_kill_decision_shouldn_t_belong_to_a_robot", "year": "2013"}, "metadata": "https://hls.ted.com/talks/1766.json", "stream": "https://hls.ted.com/talks/1766.m3u8", "adUrl": "https://pubads.g.doubleclick.net/gampad/ads?ciu_szs=300x250%2C512x288%2C120x60%2C320x50%2C6x7%2C6x8&correlator=%5Bcorrelator%5D&cust_params=event%3DTEDGlobal%2B2013%26id%3D1766%26tag%3Ddrones%2Centertainment%2Crobots%2Ctechnology%2Cwar%2Cwriting%26talk%3Ddaniel_suarez_the_kill_decision_shouldn_t_belong_to_a_robot%26year%3D2013&env=vp&gdfp_req=1&impl=s&iu=%2F5641%2Fmobile%2Fios%2Fweb&output=xml_vast2&sz=640x360&unviewed_position_start=1&url=%5Breferrer%5D"}}, "canonical": "https://www.ted.com/talks/daniel_suarez_the_kill_decision_shouldn_t_belong_to_a_robot"}], "hero_load": "https://pi.tedcdn.com/r/pe.tedcdn.com/images/ted/b15f33c6694783ada082bb6afc53b762cd014d2f_1600x1200.jpg?q=50&w=15", "duration": 800, "id": 1766, "ratings": [{"count": 81, "id": 22, "name": "Fascinating"}, {"count": 191, "id": 8, "name": "Informative"}, {"count": 195, "id": 24, "name": "Persuasive"}, {"count": 34, "id": 3, "name": "Courageous"}, {"count": 59, "id": 23, "name": "Jaw-dropping"}, {"count": 37, "id": 10, "name": "Inspiring"}, {"count": 4, "id": 11, "name": "Longwinded"}, {"count": 10, "id": 26, "name": "Obnoxious"}, {"count": 28, "id": 21, "name": "Unconvincing"}, {"count": 9, "id": 25, "name": "OK"}, {"count": 16, "id": 9, "name": "Ingenious"}, {"count": 5, "id": 2, "name": "Confusing"}, {"count": 2, "id": 7, "name": "Funny"}, {"count": 7, "id": 1, "name": "Beautiful"}], "speakers": [{"description": "Sci-fi author", "firstname": "Daniel", "title": "", "lastname": "Suarez", "middleinitial": "", "whylisten": "<p>While working as a software developer, Daniel Suarez self-published <a href=\\"http://geni.us/daemon\\" target=\\"_blank\\"><em>Daemon</em></a>, a cyber-thriller depicting a future where society is radically reshaped by disruptive technologies. It struck a chord -- and so did the sequel, <a href=\\"http://geni.us/freedom\\" target=\\"_blank\\"><em>Freedom (TM)</em></a>  -- rocketing Suarez into the pantheon of sci-fi prophets.<br /><br />In his 2012 novel <a href=\\"http://geni.us/killdecision\\" target=\\"_blank\\"><em>Kill Decision</em></a>, Suarez digs into the consequences of technology that&rsquo;s here to stay: autonomous bots and drones programmed to be lethal. Suarez argues that as we cede more control to software, we gamble with the very essence of democracy itself. How can we establish sane guidelines for technology that could easily outstrip our control?</p>", "slug": "daniel_suarez", "whotheyare": "Daniel Suarez concocts thrilling reads from terrifying (and not-so-farfetched) near-future scenarios.", "whatotherssay": "\'Kill Decision\' is an eyes-wide-open, eyebrows raised, head shaking warning. The book may have come to a satisfactory end ... but the real story is unfolding as you read this, with technologies both real and under development.", "id": 1571, "photo_url": "https://pe.tedcdn.com/images/ted/c98cabcd7e8a48854617ea560f7490b792fffcc9_254x191.jpg"}], "title": "The kill decision shouldn\'t belong to a robot", "take_action": [], "comments": 20690, "more_resources": [{"status": "approved", "publisher": "Signet", "start_at": null, "author": "Daniel Suarez", "headline": "*Kill Decision*", "link_url": "http://www.amazon.com/Kill-Decision-Daniel-Suarez/dp/0451417704/ref=as_li_tf_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=0520271440&linkCode=as2&tag=teco06-20", "published": true, "eyebrow": null, "end_at": null, "image_url": "http://images.ted.com/images/ted/15114b606209a3794251f4cb5d72ef942b9f1f29_620x936.jpg", "year": "2013", "type": "book", "blurb": null}, {"status": "approved", "start_at": null, "headline": "Why drones make us nervous", "link_url": "http://ideas.ted.com/2013/11/18/the-automation-age-by-daniel-suarez/", "eyebrow": null, "end_at": null, "image_url": "", "published": true, "visible_url": "", "type": "from_the_blog", "blurb": "The sci-fi author paints a dystopian portrait of the future \\u2014 and the present \\u2014 that captures why drones ought to have us worried."}, {"status": "approved", "start_at": null, "headline": "\\u201cThese stupid little bots outperformed any system I\\u2019ve ever seen\\"", "link_url": "http://ideas.ted.com/an-excerpt-from-daniel-suarezs-thriller-kill-decision/", "eyebrow": null, "end_at": null, "image_url": "", "published": true, "visible_url": "", "type": "from_the_blog", "blurb": "Read an excerpt from Daniel Suarez\'s book *Kill Decision*."}], "hero": "https://pe.tedcdn.com/images/ted/b15f33c6694783ada082bb6afc53b762cd014d2f_1600x1200.jpg", "description": "As a novelist, Daniel Suarez spins dystopian tales of the future. But on the TEDGlobal stage, he talks us through a real-life scenario we all need to know more about: the rise of autonomous robotic weapons of war. Advanced drones, automated weapons and AI-powered intelligence-gathering tools, he suggests, could take the decision to make war out of the hands of humans.", "tags": ["drones", "entertainment", "robots", "technology", "war", "writing"], "downloads": {"languages": [{"languageCode": "ar", "endonym": "\\u0627\\u0644\\u0639\\u0631\\u0628\\u064a\\u0629", "isRtl": true, "ianaCode": "ar", "languageName": "Arabic"}, {"languageCode": "zh-cn", "endonym": "\\u4e2d\\u6587 (\\u7b80\\u4f53)", "isRtl": false, "ianaCode": "zh-Hans", "languageName": "Chinese, Simplified"}, {"languageCode": "zh-tw", "endonym": "\\u4e2d\\u6587 (\\u7e41\\u9ad4)", "isRtl": false, "ianaCode": "zh-Hant", "languageName": "Chinese, Traditional"}, {"languageCode": "cs", "endonym": "\\u010ce\\u0161tina", "isRtl": false, "ianaCode": "cs", "languageName": "Czech"}, {"languageCode": "nl", "endonym": "Nederlands", "isRtl": false, "ianaCode": "nl", "languageName": "Dutch"}, {"languageCode": "en", "endonym": "English", "isRtl": false, "ianaCode": "en", "languageName": "English"}, {"languageCode": "fr", "endonym": "Fran\\u00e7ais", "isRtl": false, "ianaCode": "fr", "languageName": "French"}, {"languageCode": "de", "endonym": "Deutsch", "isRtl": false, "ianaCode": "de", "languageName": "German"}, {"languageCode": "el", "endonym": "\\u0395\\u03bb\\u03bb\\u03b7\\u03bd\\u03b9\\u03ba\\u03ac", "isRtl": false, "ianaCode": "el", "languageName": "Greek"}, {"languageCode": "he", "endonym": "\\u05e2\\u05d1\\u05e8\\u05d9\\u05ea", "isRtl": true, "ianaCode": "he", "languageName": "Hebrew"}, {"languageCode": "hu", "endonym": "Magyar", "isRtl": false, "ianaCode": "hu", "languageName": "Hungarian"}, {"languageCode": "it", "endonym": "Italiano", "isRtl": false, "ianaCode": "it", "languageName": "Italian"}, {"languageCode": "ja", "endonym": "\\u65e5\\u672c\\u8a9e", "isRtl": false, "ianaCode": "ja", "languageName": "Japanese"}, {"languageCode": "ko", "endonym": "\\ud55c\\uad6d\\uc5b4", "isRtl": false, "ianaCode": "ko", "languageName": "Korean"}, {"languageCode": "fa", "endonym": "\\u0641\\u0627\\u0631\\u0633\\u0649", "isRtl": true, "ianaCode": "fa", "languageName": "Persian"}, {"languageCode": "pl", "endonym": "Polski", "isRtl": false, "ianaCode": "pl", "languageName": "Polish"}, {"languageCode": "pt", "endonym": "Portugu\\u00eas de Portugal", "isRtl": false, "ianaCode": "pt", "languageName": "Portuguese"}, {"languageCode": "pt-br", "endonym": "Portugu\\u00eas brasileiro", "isRtl": false, "ianaCode": "pt-BR", "languageName": "Portuguese, Brazilian"}, {"languageCode": "ro", "endonym": "Rom\\u00e2n\\u0103", "isRtl": false, "ianaCode": "ro", "languageName": "Romanian"}, {"languageCode": "ru", "endonym": "\\u0420\\u0443\\u0441\\u0441\\u043a\\u0438\\u0439", "isRtl": false, "ianaCode": "ru", "languageName": "Russian"}, {"languageCode": "sr", "endonym": "\\u0421\\u0440\\u043f\\u0441\\u043a\\u0438, Srpski", "isRtl": false, "ianaCode": "sr", "languageName": "Serbian"}, {"languageCode": "es", "endonym": "Espa\\u00f1ol", "isRtl": false, "ianaCode": "es", "languageName": "Spanish"}, {"languageCode": "sv", "endonym": "Svenska", "isRtl": false, "ianaCode": "sv", "languageName": "Swedish"}, {"languageCode": "th", "endonym": "\\u0e20\\u0e32\\u0e29\\u0e32\\u0e44\\u0e17\\u0e22", "isRtl": false, "ianaCode": "th", "languageName": "Thai"}, {"languageCode": "tr", "endonym": "T\\u00fcrk\\u00e7e", "isRtl": false, "ianaCode": "tr", "languageName": "Turkish"}, {"languageCode": "uk", "endonym": "\\u0423\\u043a\\u0440\\u0430\\u0457\\u043d\\u0441\\u044c\\u043a\\u0430", "isRtl": false, "ianaCode": "uk", "languageName": "Ukrainian"}, {"languageCode": "vi", "endonym": "Ti\\u1ebfng Vi\\u1ec7t", "isRtl": false, "ianaCode": "vi", "languageName": "Vietnamese"}], "subtitledDownloads": {"el": {"high": "https://download.ted.com/talks/DanielSuarez_2013G-480p-el.mp4", "name": "Greek", "low": "https://download.ted.com/talks/DanielSuarez_2013G-low-el.mp4"}, "en": {"high": "https://download.ted.com/talks/DanielSuarez_2013G-480p-en.mp4", "name": "English", "low": "https://download.ted.com/talks/DanielSuarez_2013G-low-en.mp4"}, "vi": {"high": "https://download.ted.com/talks/DanielSuarez_2013G-480p-vi.mp4", "name": "Vietnamese", "low": "https://download.ted.com/talks/DanielSuarez_2013G-low-vi.mp4"}, "it": {"high": "https://download.ted.com/talks/DanielSuarez_2013G-480p-it.mp4", "name": "Italian", "low": "https://download.ted.com/talks/DanielSuarez_2013G-low-it.mp4"}, "ar": {"high": "https://download.ted.com/talks/DanielSuarez_2013G-480p-ar.mp4", "name": "Arabic", "low": "https://download.ted.com/talks/DanielSuarez_2013G-low-ar.mp4"}, "pt-br": {"high": "https://download.ted.com/talks/DanielSuarez_2013G-480p-pt-br.mp4", "name": "Portuguese, Brazilian", "low": "https://download.ted.com/talks/DanielSuarez_2013G-low-pt-br.mp4"}, "cs": {"high": "https://download.ted.com/talks/DanielSuarez_2013G-480p-cs.mp4", "name": "Czech", "low": "https://download.ted.com/talks/DanielSuarez_2013G-low-cs.mp4"}, "es": {"high": "https://download.ted.com/talks/DanielSuarez_2013G-480p-es.mp4", "name": "Spanish", "low": "https://download.ted.com/talks/DanielSuarez_2013G-low-es.mp4"}, "ru": {"high": "https://download.ted.com/talks/DanielSuarez_2013G-480p-ru.mp4", "name": "Russian", "low": "https://download.ted.com/talks/DanielSuarez_2013G-low-ru.mp4"}, "nl": {"high": "https://download.ted.com/talks/DanielSuarez_2013G-480p-nl.mp4", "name": "Dutch", "low": "https://download.ted.com/talks/DanielSuarez_2013G-low-nl.mp4"}, "pt": {"high": "https://download.ted.com/talks/DanielSuarez_2013G-480p-pt.mp4", "name": "Portuguese", "low": "https://download.ted.com/talks/DanielSuarez_2013G-low-pt.mp4"}, "zh-tw": {"high": "https://download.ted.com/talks/DanielSuarez_2013G-480p-zh-tw.mp4", "name": "Chinese, Traditional", "low": "https://download.ted.com/talks/DanielSuarez_2013G-low-zh-tw.mp4"}, "tr": {"high": "https://download.ted.com/talks/DanielSuarez_2013G-480p-tr.mp4", "name": "Turkish", "low": "https://download.ted.com/talks/DanielSuarez_2013G-low-tr.mp4"}, "zh-cn": {"high": "https://download.ted.com/talks/DanielSuarez_2013G-480p-zh-cn.mp4", "name": "Chinese, Simplified", "low": "https://download.ted.com/talks/DanielSuarez_2013G-low-zh-cn.mp4"}, "th": {"high": "https://download.ted.com/talks/DanielSuarez_2013G-480p-th.mp4", "name": "Thai", "low": "https://download.ted.com/talks/DanielSuarez_2013G-low-th.mp4"}, "ro": {"high": "https://download.ted.com/talks/DanielSuarez_2013G-480p-ro.mp4", "name": "Romanian", "low": "https://download.ted.com/talks/DanielSuarez_2013G-low-ro.mp4"}, "pl": {"high": "https://download.ted.com/talks/DanielSuarez_2013G-480p-pl.mp4", "name": "Polish", "low": "https://download.ted.com/talks/DanielSuarez_2013G-low-pl.mp4"}, "fr": {"high": "https://download.ted.com/talks/DanielSuarez_2013G-480p-fr.mp4", "name": "French", "low": "https://download.ted.com/talks/DanielSuarez_2013G-low-fr.mp4"}, "de": {"high": "https://download.ted.com/talks/DanielSuarez_2013G-480p-de.mp4", "name": "German", "low": "https://download.ted.com/talks/DanielSuarez_2013G-low-de.mp4"}, "hu": {"high": "https://download.ted.com/talks/DanielSuarez_2013G-480p-hu.mp4", "name": "Hungarian", "low": "https://download.ted.com/talks/DanielSuarez_2013G-low-hu.mp4"}, "fa": {"high": "https://download.ted.com/talks/DanielSuarez_2013G-480p-fa.mp4", "name": "Persian", "low": "https://download.ted.com/talks/DanielSuarez_2013G-low-fa.mp4"}, "ja": {"high": "https://download.ted.com/talks/DanielSuarez_2013G-480p-ja.mp4", "name": "Japanese", "low": "https://download.ted.com/talks/DanielSuarez_2013G-low-ja.mp4"}, "he": {"high": "https://download.ted.com/talks/DanielSuarez_2013G-480p-he.mp4", "name": "Hebrew", "low": "https://download.ted.com/talks/DanielSuarez_2013G-low-he.mp4"}, "sr": {"high": "https://download.ted.com/talks/DanielSuarez_2013G-480p-sr.mp4", "name": "Serbian", "low": "https://download.ted.com/talks/DanielSuarez_2013G-low-sr.mp4"}, "ko": {"high": "https://download.ted.com/talks/DanielSuarez_2013G-480p-ko.mp4", "name": "Korean", "low": "https://download.ted.com/talks/DanielSuarez_2013G-low-ko.mp4"}, "sv": {"high": "https://download.ted.com/talks/DanielSuarez_2013G-480p-sv.mp4", "name": "Swedish", "low": "https://download.ted.com/talks/DanielSuarez_2013G-low-sv.mp4"}, "uk": {"high": "https://download.ted.com/talks/DanielSuarez_2013G-480p-uk.mp4", "name": "Ukrainian", "low": "https://download.ted.com/talks/DanielSuarez_2013G-low-uk.mp4"}}, "nativeDownloads": {"high": "https://download.ted.com/talks/DanielSuarez_2013G-480p.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "medium": "https://download.ted.com/talks/DanielSuarez_2013G.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "low": "https://download.ted.com/talks/DanielSuarez_2013G-light.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22"}, "id": 1766, "audioDownload": "https://download.ted.com/talks/DanielSuarez_2013G.mp3?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22"}, "related_talks": [{"viewed_count": 1464512, "hero": "https://pe.tedcdn.com/images/ted/81787_800x600.jpg", "title": "Military robots and the future of war", "id": 504, "speaker": "P.W. Singer", "duration": 965, "slug": "pw_singer_on_robots_of_war"}, {"viewed_count": 10319614, "hero": "https://pe.tedcdn.com/images/ted/e15213155418fc82875680062821e32eccd30a5f_1600x1200.jpg", "title": "The astounding athletic power of quadcopters", "id": 1764, "speaker": "Raffaello D\'Andrea", "duration": 968, "slug": "raffaello_d_andrea_the_astounding_athletic_power_of_quadcopters"}, {"viewed_count": 1354388, "hero": "https://pe.tedcdn.com/images/ted/262a2bfc91f472ffd30afc8f2dec594b0670233f_800x600.jpg", "title": "Cracking Stuxnet, a 21st-century cyber weapon", "id": 1107, "speaker": "Ralph Langner", "duration": 640, "slug": "ralph_langner_cracking_stuxnet_a_21st_century_cyberweapon"}, {"viewed_count": 601054, "hero": "https://pe.tedcdn.com/images/ted/28a78879a36a4905f74535526fd11c0177d8ca61_1600x1200.jpg", "title": "A drone\'s-eye view of conservation", "id": 1872, "speaker": "Lian Pin Koh", "duration": 810, "slug": "lian_pin_koh_a_drone_s_eye_view_of_conservation"}, {"viewed_count": 1206027, "hero": "https://pe.tedcdn.com/images/ted/606ddad42a977bc81fcc3f2ba033bc4706e584ca_1600x1200.jpg", "title": "Meet the robots for humanity", "id": 1875, "speaker": "Henry Evans and Chad Jenkins", "duration": 621, "slug": "henry_evans_and_chad_jenkins_meet_the_robots_for_humanity"}, {"viewed_count": 474406, "hero": "https://pe.tedcdn.com/images/ted/936b0ce34f35ad688995ebb3211275fc8744d7b8_800x600.jpg", "title": "How cyberattacks threaten real-world peace", "id": 1250, "speaker": "Guy-Philippe Goldstein", "duration": 564, "slug": "guy_philippe_goldstein_how_cyberattacks_threaten_real_world_peace"}], "recorded_at": "2013-06-11T00:00:00.000+00:00", "slug": "daniel_suarez_the_kill_decision_shouldn_t_belong_to_a_robot", "speaker_name": "Daniel Suarez", "viewed_count": 1910087, "event_badge": null, "event_blurb": "This talk was presented at an official TED conference, and was featured by our editors on the home page.", "recommendations": null, "corrections": []}], "event": "TEDGlobal 2013", "name": "Daniel Suarez: The kill decision shouldn\'t belong to a robot"}'
p308
sS'keywords'
p309
(lp310
Vdrones
p311
aVentertainment
p312
aVrobots
p313
aVtechnology
p314
aVwar
p315
aVwriting
p316
asS'datecrawled'
p317
g303
(S'\x07\xe1\n\x17\x01\x1c2\x00\x01\x01'
tRp318
sS'id'
p319
I1766
ss.