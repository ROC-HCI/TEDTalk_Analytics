(dp1
S'talk_transcript'
p2
(lp3
(lp4
VRoy Price is a man that most of you have probably never heard about,
p5
aVeven though he may have been responsible
p6
aVfor 22 somewhat mediocre  minutes of your life on April 19, 2013.
p7
aVHe may have also been responsible for 22 very entertaining minutes,
p8
aVbut not very many of you.
p9
aVAnd all of that goes back to a decision
p10
aVthat Roy had to make about three years ago.
p11
aa(lp12
VSo you see, Roy Price is a senior executive with Amazon Studios.
p13
aVThat's the TV production company of Amazon.
p14
aVHe's 47 years old, slim, spiky hair,
p15
aVdescribes himself on Twitter as "movies, TV, technology, tacos."
p16
aVAnd Roy Price has a very responsible job, because it's his responsibility
p17
aVto pick the shows, the original content that Amazon is going to make.
p18
aVAnd of course that's a highly competitive space.
p19
aVI mean, there are so many TV shows already out there,
p20
aVthat Roy can't just choose any show.
p21
aVHe has to find shows that are really, really great.
p22
aVSo in other words, he has to find shows
p23
aVthat are on the very right end of this curve here.
p24
aa(lp25
VSo this curve here is the rating distribution
p26
aVof about 2,500 TV shows on the website IMDB,
p27
aVand the rating goes from one to 10,
p28
aVand the height here shows you how many shows get that rating.
p29
aVSo if your show gets a rating of nine points or higher, that's a winner.
p30
aVThen you have a top two percent show.
p31
aVThat's shows like "Breaking Bad," "Game of Thrones," "The Wire,"
p32
aVso all of these shows that are addictive,
p33
aVwhereafter you've watched a season, your brain is basically like,
p34
aV"Where can I get more of these episodes?"
p35
aVThat kind of show.
p36
aVOn the left side, just for clarity, here on that end,
p37
aVyou have a show called "Toddlers and Tiaras" \u2014
p38
aa(lp39
V(Laughter)
p40
aa(lp41
V\u2014 which should tell you enough
p42
aVabout what's going on on that end of the curve.
p43
aa(lp44
VNow, Roy Price is not worried about getting on the left end of the curve,
p45
aVbecause I think you would have to have some serious brainpower
p46
aVto undercut "Toddlers and Tiaras."
p47
aVSo what he's worried about is this middle bulge here,
p48
aVthe bulge of average TV,
p49
aVyou know, those shows that aren't really good or really bad,
p50
aVthey don't really get you excited.
p51
aVSo he needs to make sure that he's really on the right end of this.
p52
aa(lp53
VSo the pressure is on,
p54
aVand of course it's also the first time
p55
aVthat Amazon is even doing something like this,
p56
aVso Roy Price does not want to take any chances.
p57
aVHe wants to engineer success.
p58
aVHe needs a guaranteed success,
p59
aVand so what he does is, he holds a competition.
p60
aa(lp61
VSo he takes a bunch of ideas for TV shows,
p62
aVand from those ideas, through an evaluation,
p63
aVthey select eight candidates for TV shows,
p64
aVand then he just makes the first episode of each one of these shows
p65
aVand puts them online for free for everyone to watch.
p66
aVAnd so when Amazon is giving out free stuff,
p67
aVyou're going to take it, right?
p68
aVSo millions of viewers are watching those episodes.
p69
aa(lp70
VWhat they don't realize is that, while they're watching their shows,
p71
aVactually, they are being watched.
p72
aVThey are being watched by Roy Price and his team,
p73
aVwho record everything.
p74
aVThey record when somebody presses play, when somebody presses pause,
p75
aVwhat parts they skip, what parts they watch again.
p76
aVSo they collect millions of data points,
p77
aVbecause they want to have those data points
p78
aVto then decide which show they should make.
p79
aVAnd sure enough, so they collect all the data,
p80
aVthey do all the data crunching, and an answer emerges,
p81
aVand the answer is,
p82
aV"Amazon should do a sitcom about four Republican US Senators."
p83
aVThey did that show.
p84
aa(lp85
VSo does anyone know the name of the show?
p86
aV(Audience: "Alpha House.")
p87
aVYes, "Alpha House,"
p88
aVbut it seems like not too many of you here remember that show, actually,
p89
aVbecause it didn't turn out that great.
p90
aVIt's actually just an average show,
p91
aVactually \u2014 literally, in fact, because the average of this curve here is at 7.4,
p92
aVand "Alpha House" lands at 7.5,
p93
aVso a slightly above average show,
p94
aVbut certainly not what Roy Price and his team were aiming for.
p95
aVMeanwhile, however, at about the same time,
p96
aVat another company,
p97
aVanother executive did manage to land a top show using data analysis,
p98
aVand his name is Ted,
p99
aVTed Sarandos, who is the Chief Content Officer of Netflix,
p100
aVand just like Roy, he's on a constant mission
p101
aVto find that great TV show,
p102
aVand he uses data as well to do that,
p103
aVexcept he does it a little bit differently.
p104
aVSo instead of holding a competition, what he did \u2014 and his team of course \u2014
p105
aVwas they looked at all the data they already had about Netflix viewers,
p106
aVyou know, the ratings they give their shows,
p107
aVthe viewing histories, what shows people like, and so on.
p108
aVAnd then they use that data to discover
p109
aVall of these little bits and pieces about the audience:
p110
aVwhat kinds of shows they like,
p111
aVwhat kind of producers, what kind of actors.
p112
aVAnd once they had all of these pieces together,
p113
aVthey took a leap of faith,
p114
aVand they decided to license
p115
aVnot a sitcom about four Senators
p116
aVbut a drama series about a single Senator.
p117
aVYou guys know the show?
p118
aa(lp119
V(Laughter)
p120
aa(lp121
VYes, "House of Cards," and Netflix of course, nailed it with that show,
p122
aVat least for the first two seasons.
p123
aa(lp124
V(Laughter) (Applause)
p125
aa(lp126
V"House of Cards" gets a 9.1 rating on this curve,
p127
aVso it's exactly where they wanted it to be.
p128
aa(lp129
VNow, the question of course is, what happened here?
p130
aVSo you have two very competitive, data-savvy companies.
p131
aVThey connect all of these millions of data points,
p132
aVand then it works beautifully for one of them,
p133
aVand it doesn't work for the other one.
p134
aVSo why?
p135
aVBecause logic kind of tells you that this should be working all the time.
p136
aVI mean, if you're collecting millions of data points
p137
aVon a decision you're going to make,
p138
aVthen you should be able to make a pretty good decision.
p139
aVYou have 200 years of statistics to rely on.
p140
aVYou're amplifying it with very powerful computers.
p141
aVThe least you could expect is good TV, right?
p142
aa(lp143
VAnd if data analysis does not work that way,
p144
aVthen it actually gets a little scary,
p145
aVbecause we live in a time where we're turning to data more and more
p146
aVto make very serious decisions that go far beyond TV.
p147
aVDoes anyone here know the company Multi-Health Systems?
p148
aVNo one. OK, that's good actually.
p149
aVOK, so Multi-Health Systems is a software company,
p150
aVand I hope that nobody here in this room
p151
aVever comes into contact with that software,
p152
aVbecause if you do, it means you're in prison.
p153
aa(lp154
V(Laughter)
p155
aa(lp156
VIf someone here in the US is in prison, and they apply for parole,
p157
aVthen it's very likely that data analysis software from that company
p158
aVwill be used in determining whether to grant that parole.
p159
aVSo it's the same principle as Amazon and Netflix,
p160
aVbut now instead of deciding whether a TV show is going to be good or bad,
p161
aVyou're deciding whether a person is going to be good or bad.
p162
aVAnd mediocre TV, 22 minutes, that can be pretty bad,
p163
aVbut more years in prison, I guess, even worse.
p164
aa(lp165
VAnd unfortunately, there is actually some evidence that this data analysis,
p166
aVdespite having lots of data, does not always produce optimum results.
p167
aVAnd that's not because a company like Multi-Health Systems
p168
aVdoesn't know what to do with data.
p169
aVEven the most data-savvy companies get it wrong.
p170
aVYes, even Google gets it wrong sometimes.
p171
aa(lp172
VIn 2009, Google announced that they were able, with data analysis,
p173
aVto predict outbreaks of influenza, the nasty kind of flu,
p174
aVby doing data analysis on their Google searches.
p175
aVAnd it worked beautifully, and it made a big splash in the news,
p176
aVincluding the pinnacle of scientific success:
p177
aVa publication in the journal "Nature."
p178
aVIt worked beautifully for year after year after year,
p179
aVuntil one year it failed.
p180
aVAnd nobody could even tell exactly why.
p181
aVIt just didn't work that year,
p182
aVand of course that again made big news,
p183
aVincluding now a retraction
p184
aVof a publication from the journal "Nature."
p185
aVSo even the most data-savvy companies, Amazon and Google,
p186
aVthey sometimes get it wrong.
p187
aVAnd despite all those failures,
p188
aVdata is moving rapidly into real-life decision-making \u2014
p189
aVinto the workplace,
p190
aVlaw enforcement,
p191
aVmedicine.
p192
aVSo we should better make sure that data is helping.
p193
aa(lp194
VNow, personally I've seen a lot of this struggle with data myself,
p195
aVbecause I work in computational genetics,
p196
aVwhich is also a field where lots of very smart people
p197
aVare using unimaginable amounts of data to make pretty serious decisions
p198
aVlike deciding on a cancer therapy or developing a drug.
p199
aVAnd over the years, I've noticed a sort of pattern
p200
aVor kind of rule, if you will, about the difference
p201
aVbetween successful decision-making with data
p202
aVand unsuccessful decision-making,
p203
aVand I find this a pattern worth sharing, and it goes something like this.
p204
aa(lp205
VSo whenever you're solving a complex problem,
p206
aVyou're doing essentially two things.
p207
aVThe first one is, you take that problem apart into its bits and pieces
p208
aVso that you can deeply analyze those bits and pieces,
p209
aVand then of course you do the second part.
p210
aVYou put all of these bits and pieces back together again
p211
aVto come to your conclusion.
p212
aVAnd sometimes you have to do it over again,
p213
aVbut it's always those two things:
p214
aVtaking apart and putting back together again.
p215
aa(lp216
VAnd now the crucial thing is
p217
aVthat data and data analysis
p218
aVis only good for the first part.
p219
aVData and data analysis, no matter how powerful,
p220
aVcan only help you taking a problem apart and understanding its pieces.
p221
aVIt's not suited to put those pieces back together again
p222
aVand then to come to a conclusion.
p223
aVThere's another tool that can do that, and we all have it,
p224
aVand that tool is the brain.
p225
aVIf there's one thing a brain is good at,
p226
aVit's taking bits and pieces back together again,
p227
aVeven when you have incomplete information,
p228
aVand coming to a good conclusion,
p229
aVespecially if it's the brain of an expert.
p230
aa(lp231
VAnd that's why I believe that Netflix was so successful,
p232
aVbecause they used data and brains where they belong in the process.
p233
aVThey use data to first understand lots of pieces about their audience
p234
aVthat they otherwise wouldn't have been able to understand at that depth,
p235
aVbut then the decision to take all these bits and pieces
p236
aVand put them back together again and make a show like "House of Cards,"
p237
aVthat was nowhere in the data.
p238
aVTed Sarandos and his team made that decision to license that show,
p239
aVwhich also meant, by the way, that they were taking
p240
aVa pretty big personal risk with that decision.
p241
aVAnd Amazon, on the other hand, they did it the wrong way around.
p242
aVThey used data all the way to drive their decision-making,
p243
aVfirst when they held their competition of TV ideas,
p244
aVthen when they selected "Alpha House" to make as a show.
p245
aVWhich of course was a very safe decision for them,
p246
aVbecause they could always point at the data, saying,
p247
aV"This is what the data tells us."
p248
aVBut it didn't lead to the exceptional results that they were hoping for.
p249
aa(lp250
VSo data is of course a massively useful tool to make better decisions,
p251
aVbut I believe that things go wrong
p252
aVwhen data is starting to drive those decisions.
p253
aVNo matter how powerful, data is just a tool,
p254
aVand to keep that in mind, I find this device here quite useful.
p255
aVMany of you will ...
p256
aa(lp257
V(Laughter)
p258
aa(lp259
VBefore there was data,
p260
aVthis was the decision-making device to use.
p261
aa(lp262
V(Laughter)
p263
aa(lp264
VMany of you will know this.
p265
aVThis toy here is called the Magic 8 Ball,
p266
aVand it's really amazing,
p267
aVbecause if you have a decision to make, a yes or no question,
p268
aVall you have to do is you shake the ball, and then you get an answer \u2014
p269
aV"Most Likely" \u2014 right here in this window in real time.
p270
aVI'll have it out later for tech demos.
p271
aa(lp272
V(Laughter)
p273
aa(lp274
VNow, the thing is, of course \u2014 so I've made some decisions in my life
p275
aVwhere, in hindsight, I should have just listened to the ball.
p276
aVBut, you know, of course, if you have the data available,
p277
aVyou want to replace this with something much more sophisticated,
p278
aVlike data analysis to come to a better decision.
p279
aVBut that does not change the basic setup.
p280
aVSo the ball may get smarter and smarter and smarter,
p281
aVbut I believe it's still on us to make the decisions
p282
aVif we want to achieve something extraordinary,
p283
aVon the right end of the curve.
p284
aVAnd I find that a very encouraging message, in fact,
p285
aVthat even in the face of huge amounts of data,
p286
aVit still pays off to make decisions,
p287
aVto be an expert in what you're doing
p288
aVand take risks.
p289
aVBecause in the end, it's not data,
p290
aVit's risks that will land you on the right end of the curve.
p291
aa(lp292
VThank you.
p293
aa(lp294
V(Applause)
p295
aasS'transcript_micsec'
p296
(lp297
I11000
aI34000
aI76000
aI115000
aI118000
aI122000
aI146000
aI162000
aI187000
aI222000
aI305000
aI306000
aI312000
aI316000
aI323000
aI356000
aI389000
aI390000
aI421000
aI439000
aI498000
aI529000
aI553000
aI587000
aI641000
aI659000
aI660000
aI664000
aI666000
aI682000
aI683000
aI738000
aI740000
asS'talk_meta'
p298
(dp299
S'ratings'
p300
(dp301
S'beautiful'
p302
I31
sS'funny'
p303
I87
sS'inspiring'
p304
I151
sS'ok'
p305
I97
sS'fascinating'
p306
I197
sS'total_count'
p307
I1310
sS'persuasive'
p308
I114
sS'longwinded'
p309
I29
sS'informative'
p310
I473
sS'jaw-dropping'
p311
I8
sS'ingenious'
p312
I35
sS'obnoxious'
p313
I4
sS'confusing'
p314
I15
sS'courageous'
p315
I21
sS'unconvincing'
p316
I48
ssS'author'
p317
VSebastian_Wernicke;
p318
sS'url'
p319
S'https://www.ted.com/talks/sebastian_wernicke_how_to_use_data_to_make_a_hit_tv_show'
p320
sS'vidlen'
p321
I745
sS'totalviews'
p322
I1473501
sS'title'
p323
VHow to use data to make a hit TV show
p324
sS'downloadlink'
p325
Vhttps://download.ted.com/talks/SebastianWernicke_2015X.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22
p326
sS'datepublished'
p327
cdatetime
datetime
p328
(S'\x07\xe0\x01\x05\x0b\x00:\x00\x00\x00'
tRp329
sS'datefilmed'
p330
g328
(S'\x07\xe0\x01\x05\x0b\x00:\x00\x00\x00'
tRp331
sS'alldata_JSON'
p332
S'{"viewed_count": 1473501, "speakers": [{"description": "Data scientist", "firstname": "Sebastian", "title": "", "lastname": "Wernicke", "middleinitial": "", "whylisten": "<p>Dr. Sebastian Wernicke is the Chief Data Scientist of ONE LOGIC, a data science boutique that supports organizations across industries to make sense of their vast data collections to improve operations and gain strategic advantages. Wernicke originally studied bioinformatics and previously led the strategy and growth of Seven Bridges Genomics, a Cambridge-based startup that builds platforms for genetic analysis. </p><p>Before his career in statistics began, Wernicke worked stints as both a paramedic and successful short animated filmmaker. He&#39;s also the author of the <a href=\\"http://get-tedpad.com/\\" target=\\"_blank\\">TEDPad</a>  app, an irreverent tool for creating an infinite number of &quot;amazing and really bad&quot; and mostly completely meaningless talks. He&#39;s the author of the statistically authoritative and yet completely ridiculous &quot;<a href=\\"http://www.businessweek.com/magazine/how-to-give-the-perfect-ted-talk-09222011.html\\" target=\\"_blank\\">How to Give the Perfect TEDTalk.</a>&quot;</p>", "slug": "sebastian_wernicke", "whotheyare": "After making a splash in the field of bioinformatics, Sebastian Wernicke moved on to the corporate sphere, where he motivates and manages multidimensional projects.", "whatotherssay": "Genius and hilarious ...", "id": 702, "photo_url": "https://pe.tedcdn.com/images/ted/b701b0306f1618d5a4a768b3fce1832adaac4ec4_254x191.jpg"}], "current_talk": 2403, "description": "Does collecting more data lead to better decision-making? Competitive, data-savvy companies like Amazon, Google and Netflix have learned that data analysis alone doesn\'t always produce optimum results. In this talk, data scientist Sebastian Wernicke breaks down what goes wrong when we make decisions based purely on data -- and suggests a brainier way to use it.", "language": "en", "url": "https://www.ted.com/talks/sebastian_wernicke_how_to_use_data_to_make_a_hit_tv_show", "media": {"internal": {"podcast-high-en": {"uri": "https://download.ted.com/talks/SebastianWernicke_2015X-480p-en.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 86984316}, "podcast-low-en": {"uri": "https://download.ted.com/talks/SebastianWernicke_2015X-low-en.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 17235961}, "podcast-high": {"uri": "https://download.ted.com/talks/SebastianWernicke_2015X-480p.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 86978222}, "180k": {"uri": "https://download.ted.com/talks/SebastianWernicke_2015X-180k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 17010903}, "64k": {"uri": "https://download.ted.com/talks/SebastianWernicke_2015X-64k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 6137750}, "1500k": {"uri": "https://download.ted.com/talks/SebastianWernicke_2015X-1500k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 135191589}, "450k": {"uri": "https://download.ted.com/talks/SebastianWernicke_2015X-450k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 42324334}, "podcast-regular": {"uri": "https://download.ted.com/talks/SebastianWernicke_2015X.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 42733712}, "950k": {"uri": "https://download.ted.com/talks/SebastianWernicke_2015X-950k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 86996885}, "audio-podcast": {"uri": "https://download.ted.com/talks/SebastianWernicke_2015X.mp3?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "audio/mp3", "filesize_bytes": 7785068}, "podcast-light": {"uri": "https://download.ted.com/talks/SebastianWernicke_2015X-light.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 6270179}, "320k": {"uri": "https://download.ted.com/talks/SebastianWernicke_2015X-320k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 30103689}, "600k": {"uri": "https://download.ted.com/talks/SebastianWernicke_2015X-600k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 56466309}}}, "comments": {"count": 45, "id": 27023, "talk_id": 2403}, "slug": "sebastian_wernicke_how_to_use_data_to_make_a_hit_tv_show", "threadId": 27023, "talks": [{"event": "TEDxCambridge", "player_talks": [{"event": "TEDxCambridge", "slug": "sebastian_wernicke_how_to_use_data_to_make_a_hit_tv_show", "filmed": 1434585600, "targeting": {"event": "TEDxCambridge", "tag": "TEDx,algorithm,brain,data,decision-making,intelligence,media,technology", "id": 2403, "talk": "sebastian_wernicke_how_to_use_data_to_make_a_hit_tv_show", "year": "2015"}, "adDuration": "3.33", "external": null, "title": "How to use data to make a hit TV show", "postAdDuration": "0.83", "published": 1452009658, "thumb": "https://pi.tedcdn.com/r/pe.tedcdn.com/images/ted/9447af46e476fc16f72c2b583db397f73f82a803_2880x1620.jpg?quality=89&w=600", "name": "Sebastian Wernicke: How to use data to make a hit TV show", "languages": [{"languageCode": "ar", "endonym": "\\u0627\\u0644\\u0639\\u0631\\u0628\\u064a\\u0629", "isRtl": true, "ianaCode": "ar", "languageName": "Arabic"}, {"languageCode": "zh-cn", "endonym": "\\u4e2d\\u6587 (\\u7b80\\u4f53)", "isRtl": false, "ianaCode": "zh-Hans", "languageName": "Chinese, Simplified"}, {"languageCode": "zh-tw", "endonym": "\\u4e2d\\u6587 (\\u7e41\\u9ad4)", "isRtl": false, "ianaCode": "zh-Hant", "languageName": "Chinese, Traditional"}, {"languageCode": "cs", "endonym": "\\u010ce\\u0161tina", "isRtl": false, "ianaCode": "cs", "languageName": "Czech"}, {"languageCode": "da", "endonym": "Dansk", "isRtl": false, "ianaCode": "da", "languageName": "Danish"}, {"languageCode": "nl", "endonym": "Nederlands", "isRtl": false, "ianaCode": "nl", "languageName": "Dutch"}, {"languageCode": "en", "endonym": "English", "isRtl": false, "ianaCode": "en", "languageName": "English"}, {"languageCode": "fr", "endonym": "Fran\\u00e7ais", "isRtl": false, "ianaCode": "fr", "languageName": "French"}, {"languageCode": "de", "endonym": "Deutsch", "isRtl": false, "ianaCode": "de", "languageName": "German"}, {"languageCode": "he", "endonym": "\\u05e2\\u05d1\\u05e8\\u05d9\\u05ea", "isRtl": true, "ianaCode": "he", "languageName": "Hebrew"}, {"languageCode": "hu", "endonym": "Magyar", "isRtl": false, "ianaCode": "hu", "languageName": "Hungarian"}, {"languageCode": "it", "endonym": "Italiano", "isRtl": false, "ianaCode": "it", "languageName": "Italian"}, {"languageCode": "ja", "endonym": "\\u65e5\\u672c\\u8a9e", "isRtl": false, "ianaCode": "ja", "languageName": "Japanese"}, {"languageCode": "ko", "endonym": "\\ud55c\\uad6d\\uc5b4", "isRtl": false, "ianaCode": "ko", "languageName": "Korean"}, {"languageCode": "lt", "endonym": "Lietuvi\\u0173 kalba", "isRtl": false, "ianaCode": "lt", "languageName": "Lithuanian"}, {"languageCode": "fa", "endonym": "\\u0641\\u0627\\u0631\\u0633\\u0649", "isRtl": true, "ianaCode": "fa", "languageName": "Persian"}, {"languageCode": "pt", "endonym": "Portugu\\u00eas de Portugal", "isRtl": false, "ianaCode": "pt", "languageName": "Portuguese"}, {"languageCode": "pt-br", "endonym": "Portugu\\u00eas brasileiro", "isRtl": false, "ianaCode": "pt-BR", "languageName": "Portuguese, Brazilian"}, {"languageCode": "ro", "endonym": "Rom\\u00e2n\\u0103", "isRtl": false, "ianaCode": "ro", "languageName": "Romanian"}, {"languageCode": "ru", "endonym": "\\u0420\\u0443\\u0441\\u0441\\u043a\\u0438\\u0439", "isRtl": false, "ianaCode": "ru", "languageName": "Russian"}, {"languageCode": "sr", "endonym": "\\u0421\\u0440\\u043f\\u0441\\u043a\\u0438, Srpski", "isRtl": false, "ianaCode": "sr", "languageName": "Serbian"}, {"languageCode": "es", "endonym": "Espa\\u00f1ol", "isRtl": false, "ianaCode": "es", "languageName": "Spanish"}, {"languageCode": "sv", "endonym": "Svenska", "isRtl": false, "ianaCode": "sv", "languageName": "Swedish"}, {"languageCode": "tr", "endonym": "T\\u00fcrk\\u00e7e", "isRtl": false, "ianaCode": "tr", "languageName": "Turkish"}, {"languageCode": "vi", "endonym": "Ti\\u1ebfng Vi\\u1ec7t", "isRtl": false, "ianaCode": "vi", "languageName": "Vietnamese"}], "nativeLanguage": "en", "tags": ["TEDx", "algorithm", "brain", "data", "decision-making", "intelligence", "media", "technology"], "speaker": "Sebastian Wernicke", "isSubtitleRequired": false, "introDuration": 11.82, "duration": 745, "id": 2403, "resources": {"h264": [{"bitrate": 320, "file": "https://download.ted.com/talks/SebastianWernicke_2015X-320k.mp4?dnt"}], "hls": {"maiTargeting": {"event": "TEDxCambridge", "tag": "TEDx,algorithm,brain,data,decision-making,intelligence,media,technology", "id": 2403, "talk": "sebastian_wernicke_how_to_use_data_to_make_a_hit_tv_show", "year": "2015"}, "metadata": "https://hls.ted.com/talks/2403.json", "stream": "https://hls.ted.com/talks/2403.m3u8", "adUrl": "https://pubads.g.doubleclick.net/gampad/ads?ciu_szs=300x250%2C512x288%2C120x60%2C320x50%2C6x7%2C6x8&correlator=%5Bcorrelator%5D&cust_params=event%3DTEDxCambridge%26id%3D2403%26tag%3DTEDx%2Calgorithm%2Cbrain%2Cdata%2Cdecision-making%2Cintelligence%2Cmedia%2Ctechnology%26talk%3Dsebastian_wernicke_how_to_use_data_to_make_a_hit_tv_show%26year%3D2015&env=vp&gdfp_req=1&impl=s&iu=%2F5641%2Fmobile%2Fios%2Fweb&output=xml_vast2&sz=640x360&unviewed_position_start=1&url=%5Breferrer%5D"}}, "canonical": "https://www.ted.com/talks/sebastian_wernicke_how_to_use_data_to_make_a_hit_tv_show"}], "hero_load": "https://pi.tedcdn.com/r/pe.tedcdn.com/images/ted/9447af46e476fc16f72c2b583db397f73f82a803_2880x1620.jpg?q=50&w=15", "duration": 745, "id": 2403, "ratings": [{"count": 87, "id": 7, "name": "Funny"}, {"count": 473, "id": 8, "name": "Informative"}, {"count": 197, "id": 22, "name": "Fascinating"}, {"count": 48, "id": 21, "name": "Unconvincing"}, {"count": 31, "id": 1, "name": "Beautiful"}, {"count": 97, "id": 25, "name": "OK"}, {"count": 114, "id": 24, "name": "Persuasive"}, {"count": 151, "id": 10, "name": "Inspiring"}, {"count": 15, "id": 2, "name": "Confusing"}, {"count": 29, "id": 11, "name": "Longwinded"}, {"count": 21, "id": 3, "name": "Courageous"}, {"count": 35, "id": 9, "name": "Ingenious"}, {"count": 8, "id": 23, "name": "Jaw-dropping"}, {"count": 4, "id": 26, "name": "Obnoxious"}], "speakers": [{"description": "Data scientist", "firstname": "Sebastian", "title": "", "lastname": "Wernicke", "middleinitial": "", "whylisten": "<p>Dr. Sebastian Wernicke is the Chief Data Scientist of ONE LOGIC, a data science boutique that supports organizations across industries to make sense of their vast data collections to improve operations and gain strategic advantages. Wernicke originally studied bioinformatics and previously led the strategy and growth of Seven Bridges Genomics, a Cambridge-based startup that builds platforms for genetic analysis. </p><p>Before his career in statistics began, Wernicke worked stints as both a paramedic and successful short animated filmmaker. He&#39;s also the author of the <a href=\\"http://get-tedpad.com/\\" target=\\"_blank\\">TEDPad</a>  app, an irreverent tool for creating an infinite number of &quot;amazing and really bad&quot; and mostly completely meaningless talks. He&#39;s the author of the statistically authoritative and yet completely ridiculous &quot;<a href=\\"http://www.businessweek.com/magazine/how-to-give-the-perfect-ted-talk-09222011.html\\" target=\\"_blank\\">How to Give the Perfect TEDTalk.</a>&quot;</p>", "slug": "sebastian_wernicke", "whotheyare": "After making a splash in the field of bioinformatics, Sebastian Wernicke moved on to the corporate sphere, where he motivates and manages multidimensional projects.", "whatotherssay": "Genius and hilarious ...", "id": 702, "photo_url": "https://pe.tedcdn.com/images/ted/b701b0306f1618d5a4a768b3fce1832adaac4ec4_254x191.jpg"}], "title": "How to use data to make a hit TV show", "take_action": null, "comments": 27023, "more_resources": null, "hero": "https://pe.tedcdn.com/images/ted/9447af46e476fc16f72c2b583db397f73f82a803_2880x1620.jpg", "description": "Does collecting more data lead to better decision-making? Competitive, data-savvy companies like Amazon, Google and Netflix have learned that data analysis alone doesn\'t always produce optimum results. In this talk, data scientist Sebastian Wernicke breaks down what goes wrong when we make decisions based purely on data -- and suggests a brainier way to use it.", "tags": ["TEDx", "algorithm", "brain", "data", "decision-making", "intelligence", "media", "technology"], "downloads": {"languages": [{"languageCode": "ar", "endonym": "\\u0627\\u0644\\u0639\\u0631\\u0628\\u064a\\u0629", "isRtl": true, "ianaCode": "ar", "languageName": "Arabic"}, {"languageCode": "zh-cn", "endonym": "\\u4e2d\\u6587 (\\u7b80\\u4f53)", "isRtl": false, "ianaCode": "zh-Hans", "languageName": "Chinese, Simplified"}, {"languageCode": "zh-tw", "endonym": "\\u4e2d\\u6587 (\\u7e41\\u9ad4)", "isRtl": false, "ianaCode": "zh-Hant", "languageName": "Chinese, Traditional"}, {"languageCode": "cs", "endonym": "\\u010ce\\u0161tina", "isRtl": false, "ianaCode": "cs", "languageName": "Czech"}, {"languageCode": "da", "endonym": "Dansk", "isRtl": false, "ianaCode": "da", "languageName": "Danish"}, {"languageCode": "nl", "endonym": "Nederlands", "isRtl": false, "ianaCode": "nl", "languageName": "Dutch"}, {"languageCode": "en", "endonym": "English", "isRtl": false, "ianaCode": "en", "languageName": "English"}, {"languageCode": "fr", "endonym": "Fran\\u00e7ais", "isRtl": false, "ianaCode": "fr", "languageName": "French"}, {"languageCode": "de", "endonym": "Deutsch", "isRtl": false, "ianaCode": "de", "languageName": "German"}, {"languageCode": "he", "endonym": "\\u05e2\\u05d1\\u05e8\\u05d9\\u05ea", "isRtl": true, "ianaCode": "he", "languageName": "Hebrew"}, {"languageCode": "hu", "endonym": "Magyar", "isRtl": false, "ianaCode": "hu", "languageName": "Hungarian"}, {"languageCode": "it", "endonym": "Italiano", "isRtl": false, "ianaCode": "it", "languageName": "Italian"}, {"languageCode": "ja", "endonym": "\\u65e5\\u672c\\u8a9e", "isRtl": false, "ianaCode": "ja", "languageName": "Japanese"}, {"languageCode": "ko", "endonym": "\\ud55c\\uad6d\\uc5b4", "isRtl": false, "ianaCode": "ko", "languageName": "Korean"}, {"languageCode": "lt", "endonym": "Lietuvi\\u0173 kalba", "isRtl": false, "ianaCode": "lt", "languageName": "Lithuanian"}, {"languageCode": "fa", "endonym": "\\u0641\\u0627\\u0631\\u0633\\u0649", "isRtl": true, "ianaCode": "fa", "languageName": "Persian"}, {"languageCode": "pt", "endonym": "Portugu\\u00eas de Portugal", "isRtl": false, "ianaCode": "pt", "languageName": "Portuguese"}, {"languageCode": "pt-br", "endonym": "Portugu\\u00eas brasileiro", "isRtl": false, "ianaCode": "pt-BR", "languageName": "Portuguese, Brazilian"}, {"languageCode": "ro", "endonym": "Rom\\u00e2n\\u0103", "isRtl": false, "ianaCode": "ro", "languageName": "Romanian"}, {"languageCode": "ru", "endonym": "\\u0420\\u0443\\u0441\\u0441\\u043a\\u0438\\u0439", "isRtl": false, "ianaCode": "ru", "languageName": "Russian"}, {"languageCode": "sr", "endonym": "\\u0421\\u0440\\u043f\\u0441\\u043a\\u0438, Srpski", "isRtl": false, "ianaCode": "sr", "languageName": "Serbian"}, {"languageCode": "es", "endonym": "Espa\\u00f1ol", "isRtl": false, "ianaCode": "es", "languageName": "Spanish"}, {"languageCode": "sv", "endonym": "Svenska", "isRtl": false, "ianaCode": "sv", "languageName": "Swedish"}, {"languageCode": "tr", "endonym": "T\\u00fcrk\\u00e7e", "isRtl": false, "ianaCode": "tr", "languageName": "Turkish"}, {"languageCode": "vi", "endonym": "Ti\\u1ebfng Vi\\u1ec7t", "isRtl": false, "ianaCode": "vi", "languageName": "Vietnamese"}], "subtitledDownloads": {"en": {"high": "https://download.ted.com/talks/SebastianWernicke_2015X-480p-en.mp4", "name": "English", "low": "https://download.ted.com/talks/SebastianWernicke_2015X-low-en.mp4"}, "vi": {"high": "https://download.ted.com/talks/SebastianWernicke_2015X-480p-vi.mp4", "name": "Vietnamese", "low": "https://download.ted.com/talks/SebastianWernicke_2015X-low-vi.mp4"}, "it": {"high": "https://download.ted.com/talks/SebastianWernicke_2015X-480p-it.mp4", "name": "Italian", "low": "https://download.ted.com/talks/SebastianWernicke_2015X-low-it.mp4"}, "ar": {"high": "https://download.ted.com/talks/SebastianWernicke_2015X-480p-ar.mp4", "name": "Arabic", "low": "https://download.ted.com/talks/SebastianWernicke_2015X-low-ar.mp4"}, "pt-br": {"high": "https://download.ted.com/talks/SebastianWernicke_2015X-480p-pt-br.mp4", "name": "Portuguese, Brazilian", "low": "https://download.ted.com/talks/SebastianWernicke_2015X-low-pt-br.mp4"}, "cs": {"high": "https://download.ted.com/talks/SebastianWernicke_2015X-480p-cs.mp4", "name": "Czech", "low": "https://download.ted.com/talks/SebastianWernicke_2015X-low-cs.mp4"}, "es": {"high": "https://download.ted.com/talks/SebastianWernicke_2015X-480p-es.mp4", "name": "Spanish", "low": "https://download.ted.com/talks/SebastianWernicke_2015X-low-es.mp4"}, "ru": {"high": "https://download.ted.com/talks/SebastianWernicke_2015X-480p-ru.mp4", "name": "Russian", "low": "https://download.ted.com/talks/SebastianWernicke_2015X-low-ru.mp4"}, "nl": {"high": "https://download.ted.com/talks/SebastianWernicke_2015X-480p-nl.mp4", "name": "Dutch", "low": "https://download.ted.com/talks/SebastianWernicke_2015X-low-nl.mp4"}, "pt": {"high": "https://download.ted.com/talks/SebastianWernicke_2015X-480p-pt.mp4", "name": "Portuguese", "low": "https://download.ted.com/talks/SebastianWernicke_2015X-low-pt.mp4"}, "zh-tw": {"high": "https://download.ted.com/talks/SebastianWernicke_2015X-480p-zh-tw.mp4", "name": "Chinese, Traditional", "low": "https://download.ted.com/talks/SebastianWernicke_2015X-low-zh-tw.mp4"}, "tr": {"high": "https://download.ted.com/talks/SebastianWernicke_2015X-480p-tr.mp4", "name": "Turkish", "low": "https://download.ted.com/talks/SebastianWernicke_2015X-low-tr.mp4"}, "zh-cn": {"high": "https://download.ted.com/talks/SebastianWernicke_2015X-480p-zh-cn.mp4", "name": "Chinese, Simplified", "low": "https://download.ted.com/talks/SebastianWernicke_2015X-low-zh-cn.mp4"}, "lt": {"high": "https://download.ted.com/talks/SebastianWernicke_2015X-480p-lt.mp4", "name": "Lithuanian", "low": "https://download.ted.com/talks/SebastianWernicke_2015X-low-lt.mp4"}, "ro": {"high": "https://download.ted.com/talks/SebastianWernicke_2015X-480p-ro.mp4", "name": "Romanian", "low": "https://download.ted.com/talks/SebastianWernicke_2015X-low-ro.mp4"}, "fr": {"high": "https://download.ted.com/talks/SebastianWernicke_2015X-480p-fr.mp4", "name": "French", "low": "https://download.ted.com/talks/SebastianWernicke_2015X-low-fr.mp4"}, "de": {"high": "https://download.ted.com/talks/SebastianWernicke_2015X-480p-de.mp4", "name": "German", "low": "https://download.ted.com/talks/SebastianWernicke_2015X-low-de.mp4"}, "da": {"high": "https://download.ted.com/talks/SebastianWernicke_2015X-480p-da.mp4", "name": "Danish", "low": "https://download.ted.com/talks/SebastianWernicke_2015X-low-da.mp4"}, "fa": {"high": "https://download.ted.com/talks/SebastianWernicke_2015X-480p-fa.mp4", "name": "Persian", "low": "https://download.ted.com/talks/SebastianWernicke_2015X-low-fa.mp4"}, "hu": {"high": "https://download.ted.com/talks/SebastianWernicke_2015X-480p-hu.mp4", "name": "Hungarian", "low": "https://download.ted.com/talks/SebastianWernicke_2015X-low-hu.mp4"}, "ja": {"high": "https://download.ted.com/talks/SebastianWernicke_2015X-480p-ja.mp4", "name": "Japanese", "low": "https://download.ted.com/talks/SebastianWernicke_2015X-low-ja.mp4"}, "he": {"high": "https://download.ted.com/talks/SebastianWernicke_2015X-480p-he.mp4", "name": "Hebrew", "low": "https://download.ted.com/talks/SebastianWernicke_2015X-low-he.mp4"}, "sr": {"high": "https://download.ted.com/talks/SebastianWernicke_2015X-480p-sr.mp4", "name": "Serbian", "low": "https://download.ted.com/talks/SebastianWernicke_2015X-low-sr.mp4"}, "ko": {"high": "https://download.ted.com/talks/SebastianWernicke_2015X-480p-ko.mp4", "name": "Korean", "low": "https://download.ted.com/talks/SebastianWernicke_2015X-low-ko.mp4"}, "sv": {"high": "https://download.ted.com/talks/SebastianWernicke_2015X-480p-sv.mp4", "name": "Swedish", "low": "https://download.ted.com/talks/SebastianWernicke_2015X-low-sv.mp4"}}, "nativeDownloads": {"high": "https://download.ted.com/talks/SebastianWernicke_2015X-480p.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "medium": "https://download.ted.com/talks/SebastianWernicke_2015X.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "low": "https://download.ted.com/talks/SebastianWernicke_2015X-light.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22"}, "id": 2403, "audioDownload": "https://download.ted.com/talks/SebastianWernicke_2015X.mp3?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22"}, "related_talks": [{"viewed_count": 650273, "hero": "https://pe.tedcdn.com/images/ted/96e412ca73275c71b912f19e27d634aba1086e3a_800x600.jpg", "title": "The conscience of television", "id": 1224, "speaker": "Lauren Zalaznick", "duration": 792, "slug": "lauren_zalaznick"}, {"viewed_count": 3697518, "hero": "https://pe.tedcdn.com/images/ted/7c41d305ffe47c0f605eeef6974e98ed27de1390_800x600.jpg", "title": "How algorithms shape our world", "id": 1194, "speaker": "Kevin Slavin", "duration": 922, "slug": "kevin_slavin_how_algorithms_shape_our_world"}, {"viewed_count": 1215016, "hero": "https://pe.tedcdn.com/images/ted/af9d6067a02b5d76cdbf44ada9a1494b849a29d1_2880x1620.jpg", "title": "What do we do with all this big data? ", "id": 2112, "speaker": "Susan Etlinger", "duration": 743, "slug": "susan_etlinger_what_do_we_do_with_all_this_big_data"}, {"viewed_count": 1176241, "hero": "https://pe.tedcdn.com/images/ted/96044392dd7eea4410a92f4c5d499b888e607653_2880x1620.jpg", "title": "The human insights missing from big data", "id": 2818, "speaker": "Tricia Wang", "duration": 972, "slug": "tricia_wang_the_human_insights_missing_from_big_data"}, {"viewed_count": 1093227, "hero": "https://pe.tedcdn.com/images/ted/9ca3922cace721320cd2b5de1f5761f7a75b2010_2880x1620.jpg", "title": "How we can find ourselves in data", "id": 2727, "speaker": "Giorgia Lupi", "duration": 673, "slug": "giorgia_lupi_how_we_can_find_ourselves_in_data"}, {"viewed_count": 1360547, "hero": "https://pe.tedcdn.com/images/ted/77260_800x600.jpg", "title": "The next web", "id": 484, "speaker": "Tim Berners-Lee", "duration": 983, "slug": "tim_berners_lee_on_the_next_web"}], "recorded_at": "2015-06-18T00:00:00.000+00:00", "slug": "sebastian_wernicke_how_to_use_data_to_make_a_hit_tv_show", "speaker_name": "Sebastian Wernicke", "viewed_count": 1473501, "event_badge": null, "event_blurb": "This talk was presented to a local audience at TEDxCambridge, an independent event. TED editors featured it among our selections on the home page.", "recommendations": null, "corrections": null}], "event": "TEDxCambridge", "name": "Sebastian Wernicke: How to use data to make a hit TV show"}'
p333
sS'keywords'
p334
(lp335
VTEDx
p336
aValgorithm
p337
aVbrain
p338
aVdata
p339
aVdecision-making
p340
aVintelligence
p341
aVmedia
p342
aVtechnology
p343
asS'datecrawled'
p344
g328
(S'\x07\xe1\n\x17\x01.!\x04\xcd4'
tRp345
sS'id'
p346
I2403
ss.