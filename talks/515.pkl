(dp1
S'talk_transcript'
p2
(lp3
(lp4
VThe future of life, where the unraveling of our biology \u2014
p5
aVand bring up the lights a little bit. I don't have any slides.
p6
aVI'm just going to talk \u2014
p7
aVabout where that's likely to carry us.
p8
aa(lp9
VAnd you know, I saw all the visions
p10
aVof the first couple of sessions.
p11
aVIt almost made me feel a little bit guilty about having an uplifting talk
p12
aVabout the future.
p13
aVIt felt wrong to do that in some way.
p14
aVAnd yet, I don't really think it is
p15
aVbecause when it comes down to it,
p16
aVit's this larger trajectory that is really what is going to remain \u2014
p17
aVwhat people in the future are going to remember about this period.
p18
aa(lp19
VI want to talk to you a little bit about
p20
aVwhy the visions of Jeremy Rivkins,
p21
aVwho would like to ban these sorts of technologies,
p22
aVor of the Bill Joys who would like to relinquish them,
p23
aVare actually \u2014 to follow those paths would be such a tragedy for us.
p24
aVI'm focusing on biology,
p25
aVthe biological sciences.
p26
aVThe reason I'm doing that is because those are going to be
p27
aVthe areas that are the most significant to us.
p28
aVThe reason for that is really very simple.
p29
aVIt's because we're flesh and blood.
p30
aVWe're biological creatures.
p31
aVAnd what we can do with our biology
p32
aVis going to shape our future
p33
aVand that of our children and that of their children \u2014
p34
aVwhether we gain control over aging,
p35
aVwhether we learn to protect ourselves from Alzheimer's,
p36
aVand heart disease, and cancer.
p37
aa(lp38
VI think that Shakespeare really put it very nicely.
p39
aVAnd I'm actually going to use his words in the same order that he did.
p40
aV(Laughter)
p41
aVHe said, "And so from hour to hour
p42
aVwe ripe and ripe.
p43
aVAnd then from hour to hour we rot and rot.
p44
aVAnd thereby hangs a tale."
p45
aVLife is short, you know.
p46
aVAnd we need to think about planning a little bit.
p47
aVWe're all going to eventually, even in the developed world,
p48
aVgoing to have to lose everything that we love.
p49
aVWhen you're beginning to rot a little bit,
p50
aVall of the videos crammed into your head,
p51
aVall of the extensions that extend your various powers,
p52
aVare going to being to seem a little secondary.
p53
aVAnd you know, I'm getting a little bit gray \u2014 so is Ray Kurzweil,
p54
aVso is Eric Drexler.
p55
aa(lp56
VThis is where it's really central to our lives.
p57
aVNow I know there's been a whole lot of hype
p58
aVabout our power to control biology.
p59
aVYou just have to look at the Human Genome Project.
p60
aVIt wasn't two years ago
p61
aVthat everybody was talking about \u2014
p62
aVwe've found the Holy Grail of biology.
p63
aVWe're deciphering the code of codes.
p64
aVWe're reading the book of life.
p65
aVIt's a little bit reminiscent of 1969 when Neil Armstrong walked on the moon,
p66
aVand everybody was about to race out toward the stars.
p67
aVAnd we've all seen "2001: A Space Odyssey."
p68
aVYou know it's 2003, and there is no HAL.
p69
aVAnd there is no odyssey to our own moon, much less the moons of Jupiter.
p70
aVAnd we're still picking up pieces of the Challenger.
p71
aVSo it's not surprising that some people would wonder
p72
aVwhether maybe 30 or 40 years from now,
p73
aVwe'll look back at this instant in time,
p74
aVand all of the sort of talk about
p75
aVthe Human Genome Project,
p76
aVand what all this is going to mean to us \u2014
p77
aVwell, it will really mean precious little.
p78
aVAnd I just want to say that that is absolutely not going to be the case.
p79
aVBecause when we talk about our genetics and our biology,
p80
aVand modifying and altering and adjusting these things,
p81
aVwe're talking about changing ourselves.
p82
aVAnd this is very critical stuff.
p83
aa(lp84
VIf you have any doubts about how technology affects our lives,
p85
aVyou just have to go to any major city.
p86
aVThis is not the stomping ground
p87
aVof our Pleistocene ancestors.
p88
aVWhat's happening is we're taking this technology \u2014
p89
aVit's becoming more precise, more potent \u2014
p90
aVand we're turning it back upon ourselves.
p91
aVBefore it's all done
p92
aVwe are going to alter ourselves
p93
aVevery bit as much as we have changed the world around us.
p94
aVIt's going to happen a lot sooner
p95
aVthan people imagine.
p96
aVOn the way there it's going to
p97
aVcompletely revolutionize medicine and health care; that's obvious.
p98
aVIt's going to change the way we have children.
p99
aVIt's going to change the way we manage
p100
aVand alter our emotions.
p101
aVIt's going to probably change the human lifespan.
p102
aVIt will really make us question
p103
aVwhat it is to be a human being.
p104
aa(lp105
VThe larger context of this is that are
p106
aVtwo unprecedented revolutions that are going on today.
p107
aVThe first of them is the obvious one,
p108
aVthe silicon revolution,
p109
aVwhich you all are very, very familiar with.
p110
aVIt's changing our lives in so many ways,
p111
aVand it will continue to do that.
p112
aVWhat the essence of that is, is that we're taking
p113
aVthe sand at our feet, the inert silicon at our feet,
p114
aVand we're breathing a level of complexity into it
p115
aVthat rivals that of life itself,
p116
aVand may even surpass it.
p117
aVAs an outgrowth of that, as a child of that revolution,
p118
aVis the revolution in biology.
p119
aa(lp120
VThe genomics revolution,
p121
aVproteomics, metabolomics, all of these "omics"
p122
aVthat sound so terrific on grants and on business plans.
p123
aVWhat we're doing is we are
p124
aVseizing control of our evolutionary future.
p125
aVI mean we're essentially using technology
p126
aVto just jam evolution into fast-forward.
p127
aVIt's not at all clear where it's going to take us.
p128
aVBut in five to ten years we're going to start see
p129
aVsome very profound changes.
p130
aVThe most immediate changes that we'll see
p131
aVare things like in medicine.
p132
aVThere is going to be a big shift towards preventative medicine
p133
aVas we start to be able to identify
p134
aVall of the risk factors that we have as individuals.
p135
aVBut who is going to pay for all this?
p136
aVAnd how are we going to understand all this complex information?
p137
aVThat is going to be the IT challenge
p138
aVof the next generation, is communicating all this information.
p139
aa(lp140
VThere's pharmacogenomics, the combination of pharmacology
p141
aVand genetics:
p142
aVtailoring drugs to our individual constitutions
p143
aVthat Juan talked about a little bit earlier.
p144
aVThat's going to have amazing impacts.
p145
aVAnd it's going to be used for diet as well,
p146
aVand nutritional supplements and such.
p147
aVBut it's going to have a big impact because
p148
aVwe're going to have niche drugs.
p149
aVAnd we aren't going to be able to support
p150
aVthe kinds of expenses that we have to create blockbuster drugs today.
p151
aVThe approval process is going to fall apart, actually.
p152
aVIt's too slow.
p153
aVIt's too risk-averse.
p154
aVAnd it is really not suited for the future
p155
aVthat we're moving into.
p156
aa(lp157
VAnother thing is that we're just going to have to deal with this knowledge.
p158
aVIt's really wonderful when we hear,
p159
aV"Oh, 99.9 percent of the letters in the code are the same.
p160
aVWe're all identical to each other. Isn't it wonderful?"
p161
aVAnd look around you and know
p162
aVthat what we really care about is
p163
aVthat little bit of difference.
p164
aVWe look the same to a visitor from another planet, maybe,
p165
aVbut not to each other
p166
aVbecause we compete with each other all time.
p167
aVAnd we're going to have to come to grips with the fact
p168
aVthat there are differences between us as individuals that we will know about,
p169
aVand between subpopulations of humans as well.
p170
aVTo deny that that's the case is not a very good start on that.
p171
aa(lp172
VA generation or so away
p173
aVthere are going to be even more profound things that are going to happen.
p174
aVThat's when we're going to begin to use this knowledge to modify ourselves.
p175
aVNow I don't mean extra gills or something \u2014
p176
aVsomething we care about, like aging.
p177
aVWhat if we could unravel aging and understand it \u2014
p178
aVbegin to retard the process or even reverse it?
p179
aVIt would change absolutely everything.
p180
aVAnd it's obvious to anyone,
p181
aVthat if we can do this, we absolutely will do this,
p182
aVwhatever the consequences are.
p183
aa(lp184
VThe second is modifying our emotions.
p185
aVI mean Ritalin, Viagra,
p186
aVthings of that sort, Prozac.
p187
aVYou know, this is just clumsy little baby steps.
p188
aVWhat if you could take a little
p189
aVconcoction of pharmaceuticals
p190
aVthat would make you feel really contented,
p191
aVjust happy to be you.
p192
aVAre you going to be able to resist that if it doesn't have any overt side effects?
p193
aVProbably not.
p194
aVAnd if you don't, who are you going to be?
p195
aVWhy do you do what you do?
p196
aVWe're sort of circumventing evolutionary programs that guide our behavior.
p197
aVIt's going to be very challenging to deal with.
p198
aa(lp199
VThe third area is reproduction.
p200
aVThe idea that we're going to chose our children's genes,
p201
aVas we begin to understand what genes say about who we are.
p202
aVThat's the focus of my book "Redesigning Humans,"
p203
aVwhere I talk about the kinds of choices we'll make,
p204
aVand the challenges it's going to present to society.
p205
aVThere are three obvious ways of doing this.
p206
aVThe first is cloning.
p207
aVIt didn't happen.
p208
aVIt's a total media circus.
p209
aVIt will happen in five to 10 years.
p210
aVAnd when it does it's not going to be that big a deal.
p211
aVThe birth of a delayed identical twin
p212
aVis not going to shake western civilization.
p213
aa(lp214
VBut there are more important things that are already occurring:
p215
aVembryo screening.
p216
aVYou take a six to eight cell embryo,
p217
aVyou tease out one of the cells, you run a genetic test on that cell,
p218
aVand depending on the results of that test
p219
aVyou either implant that embryo or you discard it.
p220
aVIt's already done to avoid rare diseases today.
p221
aVAnd pretty soon it's going to be possible
p222
aVto avoid virtually all genetic diseases in that way.
p223
aVAs that becomes possible
p224
aVthis is going to move from something that is used by those who
p225
aVhave infertility problems and are already doing in vitro fertilization,
p226
aVto the wealthy who want to protect their children,
p227
aVto just about everybody else.
p228
aVAnd in that process that's going to morph
p229
aVfrom being just for diseases,
p230
aVto being for lesser vulnerabilities,
p231
aVlike risk of manic depression or something,
p232
aVto picking personalities,
p233
aVtemperaments, traits, these sorts of things.
p234
aVOf course there is going to be genetic engineering.
p235
aVDirectly going in \u2014 it's a little bit further away, but not that far away \u2014
p236
aVgoing in and altering the genes in the first cell in an embryo.
p237
aVThe way I suspect it will happen
p238
aVis using artificial chromosomes
p239
aVand extra chromosomes, so we go from 46
p240
aVto 47 or 48.
p241
aVAnd one that is not heritable
p242
aVbecause who would want to pass on to their children
p243
aVthe archaic enhancement modules
p244
aVthat they got 25 years earlier from their parents?
p245
aVIt's a joke; of course they wouldn't want to do that.
p246
aVThey'll want the new release.
p247
aa(lp248
VThose kinds of loose analogies with
p249
aV(Laughter)
p250
aVcomputers, and with programming,
p251
aVare actually much deeper than that.
p252
aVThey are really going to come to operate in this realm.
p253
aVNow not everything that can be done should be done.
p254
aVAnd it won't be done.
p255
aVBut when something is feasible in thousands of
p256
aVlaboratories all over the world,
p257
aVwhich is going to be the case with these technologies,
p258
aVwhen there are large numbers of people who see them as beneficial,
p259
aVwhich is already the case,
p260
aVand when they're almost impossible to police,
p261
aVit's not a question of if this is going to happen,
p262
aVit's when and where and how it's going to happen.
p263
aa(lp264
VHumanity is going to go down this path.
p265
aVAnd it's going to do so for two reasons.
p266
aVThe first is that all these technologies
p267
aVare just a spin-off of mainstream medical research
p268
aVthat everybody wants to see happen.
p269
aVIt is being funded very very \u2014
p270
aVin a big way.
p271
aVThe second is, we're human.
p272
aVThat's what we do.
p273
aVWe try and use our technology to
p274
aVimprove our lives in one way or another.
p275
aVTo imagine that we're not going to use these technologies
p276
aVwhen they become available,
p277
aVis as much a denial of who we are
p278
aVas to imagine
p279
aVthat we'll use these technologies and not fret
p280
aVand worry about it a great deal.
p281
aVThe lines are going to blur. And they already are
p282
aVbetween therapy and enhancement,
p283
aVbetween treatment and prevention,
p284
aVbetween need and desire.
p285
aVThat's really the central one, I believe.
p286
aa(lp287
VPeople can try and ban these things.
p288
aVThey undoubtedly will. They have.
p289
aVBut ultimately all this is going to do
p290
aVis just shift development elsewhere.
p291
aVIt's going to drive these things from view.
p292
aVIt's going to reserve the technology for the wealthy
p293
aVbecause they are in the best position
p294
aVto circumvent any of these sorts of laws.
p295
aVAnd it's going to deny us
p296
aVthe information that we need to make wise decisions
p297
aVabout how to use these technologies.
p298
aVSo, sure, we need to debate these things.
p299
aVAnd I think it's wonderful that we do.
p300
aVBut we shouldn't kid ourselves
p301
aVand think that we're going to reach a consensus about these things.
p302
aVThat is simply not going to happen.
p303
aVThey touch us too deeply.
p304
aVAnd they depend too much upon history, upon philosophy,
p305
aVupon religion, upon culture, upon politics.
p306
aVSome people are going to see this
p307
aVas an abomination,
p308
aVas the worst thing, as just awful.
p309
aVOther people are going to say, "This is great.
p310
aVThis is the flowering of human endeavor."
p311
aa(lp312
VThe one thing though that is really dangerous
p313
aVabout these sorts of technologies,
p314
aVis that it's easy to become seduced by them.
p315
aVAnd to focus too much on all
p316
aVthe high-technology possibilities that exist.
p317
aVAnd to lose touch
p318
aVwith the basic rhythms of our biology and our health.
p319
aVThere are too many people that think that high-technology medicine
p320
aVis going to keep them, save them,
p321
aVfrom overeating,
p322
aVfrom eating a lot of fast foods,
p323
aVfrom not getting any exercise.
p324
aVIt's not going to happen.
p325
aa(lp326
VIn the midst of all this amazing technology,
p327
aVand all these things that are occurring, it's really interesting
p328
aVbecause there is sort of a counter-revolution that is going on:
p329
aVa resurgence of interest in remedies from the past,
p330
aVin nutraceuticals, in all of these sorts of things
p331
aVthat some people, in the pharmaceutical industry particularly,
p332
aVlike to brand as non-science.
p333
aVBut this whole effort is generated,
p334
aVis driven, by IT as well
p335
aVbecause that is how we're gathering all this information,
p336
aVand linking it, and integrating it together.
p337
aVThere is a lot in this rich biota that is going to serve us well.
p338
aVAnd that's where about half of our drugs come.
p339
aVSo we shouldn't dismiss this
p340
aVbecause it's an enormous opportunity to use
p341
aVthese sorts of results,
p342
aVor these random loose trials from the last thousand years
p343
aVabout what has impacts on our health.
p344
aVAnd to use our advanced technologies
p345
aVto pull out what is beneficial from this
p346
aVsea of noise, basically.
p347
aa(lp348
VIn fact this isn't just abstract.
p349
aVI just formed a biotechnology company
p350
aVthat is using
p351
aVthis sort of an approach to develop
p352
aVtherapeutics for Alzheimer's and other diseases of aging,
p353
aVand we're making some real progress.
p354
aVSo here we are.
p355
aVIt's the beginning of a new millennium.
p356
aVIf you look forward,
p357
aVI mean future humans,
p358
aVfar before the end of this millennium,
p359
aVin a few hundred years, they are going to look back at this moment.
p360
aVAnd from the beginning of today's sessions
p361
aVyou'd think that they're going to see this as this horrible
p362
aVdifficult, painful period
p363
aVthat we struggled through.
p364
aVAnd I don't think that's what's going to happen.
p365
aVThey're going to do like everybody does. They are going to forget about all that stuff.
p366
aVAnd they are actually going to romanticize this moment in time.
p367
aVThey are going to think about it
p368
aVas this glorious instant
p369
aVwhen we laid down
p370
aVthe very foundations of their lives,
p371
aVof their society, of their future.
p372
aVYou know it's a little bit like a birth.
p373
aVWhere there is this bloody, awful mess happens.
p374
aVAnd then what comes out of it? New life.
p375
aVActually as was pointed out earlier,
p376
aVwe forget about all the struggle there was in getting there.
p377
aa(lp378
VSo to me,
p379
aVit's clear that one of the foundations of that future
p380
aVis going to be the reworking of our biology.
p381
aVIt's going to come gradually at first. It's going to pick up speed.
p382
aVWe're going to make lots of errors.
p383
aVThat's the way these things work.
p384
aVTo me it's an incredible privilege
p385
aVto be alive now
p386
aVand to be able to witness this thing.
p387
aVIt is something that is a unique instant
p388
aVin the history of all of life.
p389
aVIt will always be remembered.
p390
aVAnd what's extraordinary is that
p391
aVwe're not just observing this,
p392
aVwe are the architects of this.
p393
aVI think that we should be proud of it.
p394
aVWhat is so difficult and challenging
p395
aVis that we are also the objects of these changes.
p396
aVIt's our health, it's our lives, it's our future, it's our children.
p397
aVAnd that is why they are so very troubling to so many people
p398
aVwho would pull back in fear.
p399
aVI think that our choice
p400
aVin the choice of life,
p401
aVis not whether we're going to go down this path.
p402
aVWe are, definitely.
p403
aVIt's how we hold it in our hearts.
p404
aVIt's how we look at it.
p405
aVI think Thucydides really spoke to us very clearly
p406
aVin 430 B.C. He put it nicely.
p407
aVAgain, I'll use the words in the same order he did.
p408
aV"The bravest are surely those
p409
aVwho have the clearest vision of what is before them,
p410
aVboth glory and danger alike.
p411
aVAnd yet notwithstanding, they go out and they meet it."
p412
aa(lp413
VThank you.
p414
aV(Applause)
p415
aasS'transcript_micsec'
p416
(lp417
I11000
aI22000
aI47000
aI101000
aI151000
aI230000
aI279000
aI316000
aI370000
aI412000
aI452000
aI483000
aI520000
aI558000
aI650000
aI684000
aI737000
aI797000
aI830000
aI888000
aI964000
aI1058000
asS'talk_meta'
p418
(dp419
S'ratings'
p420
(dp421
S'beautiful'
p422
I24
sS'ingenious'
p423
I25
sS'inspiring'
p424
I131
sS'ok'
p425
I46
sS'fascinating'
p426
I128
sS'funny'
p427
I0
sS'total_count'
p428
I766
sS'persuasive'
p429
I98
sS'longwinded'
p430
I65
sS'informative'
p431
I87
sS'jaw-dropping'
p432
I38
sS'obnoxious'
p433
I13
sS'confusing'
p434
I17
sS'courageous'
p435
I48
sS'unconvincing'
p436
I46
ssS'author'
p437
VGregory_Stock;
p438
sS'url'
p439
S'https://www.ted.com/talks/gregory_stock_to_upgrade_is_human'
p440
sS'vidlen'
p441
I1071
sS'totalviews'
p442
I498844
sS'title'
p443
VTo upgrade is human
p444
sS'downloadlink'
p445
Vhttps://download.ted.com/talks/GregoryStock_2003.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22
p446
sS'datepublished'
p447
cdatetime
datetime
p448
(S'\x07\xd9\x04\r\x15\x00\x00\x00\x00\x00'
tRp449
sS'datefilmed'
p450
g448
(S'\x07\xd9\x04\r\x15\x00\x00\x00\x00\x00'
tRp451
sS'alldata_JSON'
p452
S'{"viewed_count": 498844, "speakers": [{"description": "Author, thinker", "firstname": "Gregory", "title": "", "lastname": "Stock", "middleinitial": "", "whylisten": "<p>Bestselling author and lecturer Gregory Stock examines the evolutionary significance of technological progress. His 1993 book, <em>Metaman</em>, looks (optimistically) toward a future where the symbiotic relationship between human culture and technology increasingly resembles a &quot;superorganism&quot; that can respond, as a whole, to crises like global warming. 2003&#39;s&nbsp;<a href=\\"http://geni.us/redesigninghumans\\" target=\\"_blank\\"><em>Redesigning Humans</em></a>&nbsp;poses the alluring -- and sometimes frightening -- possibility that human biology will soon become customizable: no mere question of availability, but a matter of personal choice.</p><p>Stock&#39;s other work includes&nbsp;<a href=\\"http://geni.us/humangermline\\" target=\\"_blank\\"><em>Engineering the Human Germline</em></a>, which looks at the implications of controlled evolution, and a set of perpetually-bestselling tabletop conversation-starters, the flagship of which is&nbsp;<a href=\\"http://geni.us/bookofquestions\\" target=\\"_blank\\"><em>The Book of Questions</em></a>. </p>", "slug": "gregory_stock", "whotheyare": "Dr. Gregory Stock\'s levelheaded look at the hotpoints where tech and ethics connect (or short circuit) have made him a popular guest on TV and radio. He directs the Program on Science, Technology, and Society at UCLA.", "whatotherssay": "Stock sees the cloning controversy as a distraction from issues of real importance, such as balancing offspring trait selection against eugenics. [He writes with] the clarity and precision of a philosopher.", "id": 432, "photo_url": "https://pe.tedcdn.com/images/ted/002b43e906bc28e73f30606420d9355c9ada1724_254x191.jpg"}], "current_talk": 515, "description": "In this prophetic 2003 talk -- just days before Dolly the sheep was stuffed -- biotech ethicist Gregory Stock looked forward to new, more meaningful (and controversial) technologies, like customizable babies, whose adoption might drive human evolution.", "language": "en", "url": "https://www.ted.com/talks/gregory_stock_to_upgrade_is_human", "media": {"internal": {"podcast-high-en": {"uri": "https://download.ted.com/talks/GregoryStock_2003-480p-en.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 124507452}, "podcast-low-en": {"uri": "https://download.ted.com/talks/GregoryStock_2003-low-en.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 24586972}, "podcast-high": {"uri": "https://download.ted.com/talks/GregoryStock_2003-480p.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 124524471}, "180k": {"uri": "https://download.ted.com/talks/GregoryStock_2003-180k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 24351433}, "64k": {"uri": "https://download.ted.com/talks/GregoryStock_2003-64k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 8783568}, "1500k": {"uri": "https://download.ted.com/talks/GregoryStock_2003-1500k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 194965091}, "450k": {"uri": "https://download.ted.com/talks/GregoryStock_2003-450k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 60530810}, "podcast-regular": {"uri": "https://download.ted.com/talks/GregoryStock_2003.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 60940234}, "950k": {"uri": "https://download.ted.com/talks/GregoryStock_2003-950k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 124543121}, "podcast-light": {"uri": "https://download.ted.com/talks/GregoryStock_2003-light.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 8916126}, "320k": {"uri": "https://download.ted.com/talks/GregoryStock_2003-320k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 43065951}, "600k": {"uri": "https://download.ted.com/talks/GregoryStock_2003-600k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 80717781}}}, "comments": {"count": 144, "id": 429, "talk_id": 515}, "slug": "gregory_stock_to_upgrade_is_human", "threadId": 429, "talks": [{"event": "TED2003", "player_talks": [{"event": "TED2003", "slug": "gregory_stock_to_upgrade_is_human", "filmed": 1044144000, "targeting": {"event": "TED2003", "tag": "biology,biotech,children,evolution,genetics,science,technology", "id": 515, "talk": "gregory_stock_to_upgrade_is_human", "year": "2003"}, "adDuration": "3.33", "external": null, "title": "To upgrade is human", "postAdDuration": "0.83", "published": 1239670800, "thumb": "https://pi.tedcdn.com/r/pe.tedcdn.com/images/ted/6fbafd80d79e2de8e034457ad118ea3fba0c6884_2880x1620.jpg?quality=89&w=600", "name": "Gregory Stock: To upgrade is human", "languages": [{"languageCode": "ar", "endonym": "\\u0627\\u0644\\u0639\\u0631\\u0628\\u064a\\u0629", "isRtl": true, "ianaCode": "ar", "languageName": "Arabic"}, {"languageCode": "bg", "endonym": "\\u0431\\u044a\\u043b\\u0433\\u0430\\u0440\\u0441\\u043a\\u0438", "isRtl": false, "ianaCode": "bg", "languageName": "Bulgarian"}, {"languageCode": "zh-cn", "endonym": "\\u4e2d\\u6587 (\\u7b80\\u4f53)", "isRtl": false, "ianaCode": "zh-Hans", "languageName": "Chinese, Simplified"}, {"languageCode": "zh-tw", "endonym": "\\u4e2d\\u6587 (\\u7e41\\u9ad4)", "isRtl": false, "ianaCode": "zh-Hant", "languageName": "Chinese, Traditional"}, {"languageCode": "nl", "endonym": "Nederlands", "isRtl": false, "ianaCode": "nl", "languageName": "Dutch"}, {"languageCode": "en", "endonym": "English", "isRtl": false, "ianaCode": "en", "languageName": "English"}, {"languageCode": "fr", "endonym": "Fran\\u00e7ais", "isRtl": false, "ianaCode": "fr", "languageName": "French"}, {"languageCode": "de", "endonym": "Deutsch", "isRtl": false, "ianaCode": "de", "languageName": "German"}, {"languageCode": "he", "endonym": "\\u05e2\\u05d1\\u05e8\\u05d9\\u05ea", "isRtl": true, "ianaCode": "he", "languageName": "Hebrew"}, {"languageCode": "it", "endonym": "Italiano", "isRtl": false, "ianaCode": "it", "languageName": "Italian"}, {"languageCode": "ja", "endonym": "\\u65e5\\u672c\\u8a9e", "isRtl": false, "ianaCode": "ja", "languageName": "Japanese"}, {"languageCode": "ko", "endonym": "\\ud55c\\uad6d\\uc5b4", "isRtl": false, "ianaCode": "ko", "languageName": "Korean"}, {"languageCode": "ku", "endonym": "\\u06a9\\u0648\\u0631\\u062f\\u06cc", "isRtl": true, "ianaCode": "ku", "languageName": "Kurdish"}, {"languageCode": "pl", "endonym": "Polski", "isRtl": false, "ianaCode": "pl", "languageName": "Polish"}, {"languageCode": "pt-br", "endonym": "Portugu\\u00eas brasileiro", "isRtl": false, "ianaCode": "pt-BR", "languageName": "Portuguese, Brazilian"}, {"languageCode": "ro", "endonym": "Rom\\u00e2n\\u0103", "isRtl": false, "ianaCode": "ro", "languageName": "Romanian"}, {"languageCode": "ru", "endonym": "\\u0420\\u0443\\u0441\\u0441\\u043a\\u0438\\u0439", "isRtl": false, "ianaCode": "ru", "languageName": "Russian"}, {"languageCode": "es", "endonym": "Espa\\u00f1ol", "isRtl": false, "ianaCode": "es", "languageName": "Spanish"}, {"languageCode": "vi", "endonym": "Ti\\u1ebfng Vi\\u1ec7t", "isRtl": false, "ianaCode": "vi", "languageName": "Vietnamese"}], "nativeLanguage": "en", "tags": ["biology", "biotech", "children", "evolution", "genetics", "science", "technology"], "speaker": "Gregory Stock", "isSubtitleRequired": false, "introDuration": 11.82, "duration": 1071, "id": 515, "resources": {"h264": [{"bitrate": 320, "file": "https://download.ted.com/talks/GregoryStock_2003-320k.mp4?dnt"}], "hls": {"maiTargeting": {"event": "TED2003", "tag": "biology,biotech,children,evolution,genetics,science,technology", "id": 515, "talk": "gregory_stock_to_upgrade_is_human", "year": "2003"}, "metadata": "https://hls.ted.com/talks/515.json", "stream": "https://hls.ted.com/talks/515.m3u8", "adUrl": "https://pubads.g.doubleclick.net/gampad/ads?ciu_szs=300x250%2C512x288%2C120x60%2C320x50%2C6x7%2C6x8&correlator=%5Bcorrelator%5D&cust_params=event%3DTED2003%26id%3D515%26tag%3Dbiology%2Cbiotech%2Cchildren%2Cevolution%2Cgenetics%2Cscience%2Ctechnology%26talk%3Dgregory_stock_to_upgrade_is_human%26year%3D2003&env=vp&gdfp_req=1&impl=s&iu=%2F5641%2Fmobile%2Fios%2Fweb&output=xml_vast2&sz=640x360&unviewed_position_start=1&url=%5Breferrer%5D"}}, "canonical": "https://www.ted.com/talks/gregory_stock_to_upgrade_is_human"}], "hero_load": "https://pi.tedcdn.com/r/pe.tedcdn.com/images/ted/6fbafd80d79e2de8e034457ad118ea3fba0c6884_2880x1620.jpg?q=50&w=15", "duration": 1071, "id": 515, "ratings": [{"count": 38, "id": 23, "name": "Jaw-dropping"}, {"count": 128, "id": 22, "name": "Fascinating"}, {"count": 87, "id": 8, "name": "Informative"}, {"count": 98, "id": 24, "name": "Persuasive"}, {"count": 131, "id": 10, "name": "Inspiring"}, {"count": 65, "id": 11, "name": "Longwinded"}, {"count": 13, "id": 26, "name": "Obnoxious"}, {"count": 46, "id": 21, "name": "Unconvincing"}, {"count": 48, "id": 3, "name": "Courageous"}, {"count": 46, "id": 25, "name": "OK"}, {"count": 24, "id": 1, "name": "Beautiful"}, {"count": 17, "id": 2, "name": "Confusing"}, {"count": 25, "id": 9, "name": "Ingenious"}, {"count": 0, "id": 7, "name": "Funny"}], "speakers": [{"description": "Author, thinker", "firstname": "Gregory", "title": "", "lastname": "Stock", "middleinitial": "", "whylisten": "<p>Bestselling author and lecturer Gregory Stock examines the evolutionary significance of technological progress. His 1993 book, <em>Metaman</em>, looks (optimistically) toward a future where the symbiotic relationship between human culture and technology increasingly resembles a &quot;superorganism&quot; that can respond, as a whole, to crises like global warming. 2003&#39;s&nbsp;<a href=\\"http://geni.us/redesigninghumans\\" target=\\"_blank\\"><em>Redesigning Humans</em></a>&nbsp;poses the alluring -- and sometimes frightening -- possibility that human biology will soon become customizable: no mere question of availability, but a matter of personal choice.</p><p>Stock&#39;s other work includes&nbsp;<a href=\\"http://geni.us/humangermline\\" target=\\"_blank\\"><em>Engineering the Human Germline</em></a>, which looks at the implications of controlled evolution, and a set of perpetually-bestselling tabletop conversation-starters, the flagship of which is&nbsp;<a href=\\"http://geni.us/bookofquestions\\" target=\\"_blank\\"><em>The Book of Questions</em></a>. </p>", "slug": "gregory_stock", "whotheyare": "Dr. Gregory Stock\'s levelheaded look at the hotpoints where tech and ethics connect (or short circuit) have made him a popular guest on TV and radio. He directs the Program on Science, Technology, and Society at UCLA.", "whatotherssay": "Stock sees the cloning controversy as a distraction from issues of real importance, such as balancing offspring trait selection against eugenics. [He writes with] the clarity and precision of a philosopher.", "id": 432, "photo_url": "https://pe.tedcdn.com/images/ted/002b43e906bc28e73f30606420d9355c9ada1724_254x191.jpg"}], "title": "To upgrade is human", "take_action": null, "comments": 429, "more_resources": null, "hero": "https://pe.tedcdn.com/images/ted/6fbafd80d79e2de8e034457ad118ea3fba0c6884_2880x1620.jpg", "description": "In this prophetic 2003 talk -- just days before Dolly the sheep was stuffed -- biotech ethicist Gregory Stock looked forward to new, more meaningful (and controversial) technologies, like customizable babies, whose adoption might drive human evolution.", "tags": ["biology", "biotech", "children", "evolution", "genetics", "science", "technology"], "downloads": {"languages": [{"languageCode": "ar", "endonym": "\\u0627\\u0644\\u0639\\u0631\\u0628\\u064a\\u0629", "isRtl": true, "ianaCode": "ar", "languageName": "Arabic"}, {"languageCode": "bg", "endonym": "\\u0431\\u044a\\u043b\\u0433\\u0430\\u0440\\u0441\\u043a\\u0438", "isRtl": false, "ianaCode": "bg", "languageName": "Bulgarian"}, {"languageCode": "zh-cn", "endonym": "\\u4e2d\\u6587 (\\u7b80\\u4f53)", "isRtl": false, "ianaCode": "zh-Hans", "languageName": "Chinese, Simplified"}, {"languageCode": "zh-tw", "endonym": "\\u4e2d\\u6587 (\\u7e41\\u9ad4)", "isRtl": false, "ianaCode": "zh-Hant", "languageName": "Chinese, Traditional"}, {"languageCode": "nl", "endonym": "Nederlands", "isRtl": false, "ianaCode": "nl", "languageName": "Dutch"}, {"languageCode": "en", "endonym": "English", "isRtl": false, "ianaCode": "en", "languageName": "English"}, {"languageCode": "fr", "endonym": "Fran\\u00e7ais", "isRtl": false, "ianaCode": "fr", "languageName": "French"}, {"languageCode": "de", "endonym": "Deutsch", "isRtl": false, "ianaCode": "de", "languageName": "German"}, {"languageCode": "he", "endonym": "\\u05e2\\u05d1\\u05e8\\u05d9\\u05ea", "isRtl": true, "ianaCode": "he", "languageName": "Hebrew"}, {"languageCode": "it", "endonym": "Italiano", "isRtl": false, "ianaCode": "it", "languageName": "Italian"}, {"languageCode": "ja", "endonym": "\\u65e5\\u672c\\u8a9e", "isRtl": false, "ianaCode": "ja", "languageName": "Japanese"}, {"languageCode": "ko", "endonym": "\\ud55c\\uad6d\\uc5b4", "isRtl": false, "ianaCode": "ko", "languageName": "Korean"}, {"languageCode": "ku", "endonym": "\\u06a9\\u0648\\u0631\\u062f\\u06cc", "isRtl": true, "ianaCode": "ku", "languageName": "Kurdish"}, {"languageCode": "pl", "endonym": "Polski", "isRtl": false, "ianaCode": "pl", "languageName": "Polish"}, {"languageCode": "pt-br", "endonym": "Portugu\\u00eas brasileiro", "isRtl": false, "ianaCode": "pt-BR", "languageName": "Portuguese, Brazilian"}, {"languageCode": "ro", "endonym": "Rom\\u00e2n\\u0103", "isRtl": false, "ianaCode": "ro", "languageName": "Romanian"}, {"languageCode": "ru", "endonym": "\\u0420\\u0443\\u0441\\u0441\\u043a\\u0438\\u0439", "isRtl": false, "ianaCode": "ru", "languageName": "Russian"}, {"languageCode": "es", "endonym": "Espa\\u00f1ol", "isRtl": false, "ianaCode": "es", "languageName": "Spanish"}, {"languageCode": "vi", "endonym": "Ti\\u1ebfng Vi\\u1ec7t", "isRtl": false, "ianaCode": "vi", "languageName": "Vietnamese"}], "subtitledDownloads": {"ru": {"high": "https://download.ted.com/talks/GregoryStock_2003-480p-ru.mp4", "name": "Russian", "low": "https://download.ted.com/talks/GregoryStock_2003-low-ru.mp4"}, "fr": {"high": "https://download.ted.com/talks/GregoryStock_2003-480p-fr.mp4", "name": "French", "low": "https://download.ted.com/talks/GregoryStock_2003-low-fr.mp4"}, "en": {"high": "https://download.ted.com/talks/GregoryStock_2003-480p-en.mp4", "name": "English", "low": "https://download.ted.com/talks/GregoryStock_2003-low-en.mp4"}, "nl": {"high": "https://download.ted.com/talks/GregoryStock_2003-480p-nl.mp4", "name": "Dutch", "low": "https://download.ted.com/talks/GregoryStock_2003-low-nl.mp4"}, "zh-tw": {"high": "https://download.ted.com/talks/GregoryStock_2003-480p-zh-tw.mp4", "name": "Chinese, Traditional", "low": "https://download.ted.com/talks/GregoryStock_2003-low-zh-tw.mp4"}, "de": {"high": "https://download.ted.com/talks/GregoryStock_2003-480p-de.mp4", "name": "German", "low": "https://download.ted.com/talks/GregoryStock_2003-low-de.mp4"}, "ko": {"high": "https://download.ted.com/talks/GregoryStock_2003-480p-ko.mp4", "name": "Korean", "low": "https://download.ted.com/talks/GregoryStock_2003-low-ko.mp4"}, "it": {"high": "https://download.ted.com/talks/GregoryStock_2003-480p-it.mp4", "name": "Italian", "low": "https://download.ted.com/talks/GregoryStock_2003-low-it.mp4"}, "zh-cn": {"high": "https://download.ted.com/talks/GregoryStock_2003-480p-zh-cn.mp4", "name": "Chinese, Simplified", "low": "https://download.ted.com/talks/GregoryStock_2003-low-zh-cn.mp4"}, "ar": {"high": "https://download.ted.com/talks/GregoryStock_2003-480p-ar.mp4", "name": "Arabic", "low": "https://download.ted.com/talks/GregoryStock_2003-low-ar.mp4"}, "pt-br": {"high": "https://download.ted.com/talks/GregoryStock_2003-480p-pt-br.mp4", "name": "Portuguese, Brazilian", "low": "https://download.ted.com/talks/GregoryStock_2003-low-pt-br.mp4"}, "es": {"high": "https://download.ted.com/talks/GregoryStock_2003-480p-es.mp4", "name": "Spanish", "low": "https://download.ted.com/talks/GregoryStock_2003-low-es.mp4"}, "bg": {"high": "https://download.ted.com/talks/GregoryStock_2003-480p-bg.mp4", "name": "Bulgarian", "low": "https://download.ted.com/talks/GregoryStock_2003-low-bg.mp4"}, "vi": {"high": "https://download.ted.com/talks/GregoryStock_2003-480p-vi.mp4", "name": "Vietnamese", "low": "https://download.ted.com/talks/GregoryStock_2003-low-vi.mp4"}, "ro": {"high": "https://download.ted.com/talks/GregoryStock_2003-480p-ro.mp4", "name": "Romanian", "low": "https://download.ted.com/talks/GregoryStock_2003-low-ro.mp4"}, "ja": {"high": "https://download.ted.com/talks/GregoryStock_2003-480p-ja.mp4", "name": "Japanese", "low": "https://download.ted.com/talks/GregoryStock_2003-low-ja.mp4"}, "pl": {"high": "https://download.ted.com/talks/GregoryStock_2003-480p-pl.mp4", "name": "Polish", "low": "https://download.ted.com/talks/GregoryStock_2003-low-pl.mp4"}, "he": {"high": "https://download.ted.com/talks/GregoryStock_2003-480p-he.mp4", "name": "Hebrew", "low": "https://download.ted.com/talks/GregoryStock_2003-low-he.mp4"}}, "nativeDownloads": {"high": "https://download.ted.com/talks/GregoryStock_2003-480p.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "medium": "https://download.ted.com/talks/GregoryStock_2003.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "low": "https://download.ted.com/talks/GregoryStock_2003-light.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22"}, "id": 515, "audioDownload": null}, "related_talks": [{"viewed_count": 2960496, "hero": "https://pe.tedcdn.com/images/ted/5ee3d58ad4d872a0ae350c2ec9f58d325dd95462_1600x1200.jpg", "title": "The next species of human", "id": 463, "speaker": "Juan Enriquez", "duration": 1130, "slug": "juan_enriquez_shares_mindboggling_new_science"}, {"viewed_count": 1007786, "hero": "https://pe.tedcdn.com/images/ted/32772_480x360.jpg", "title": "On the verge of creating synthetic life", "id": 227, "speaker": "Craig Venter", "duration": 954, "slug": "craig_venter_is_on_the_verge_of_creating_synthetic_life"}, {"viewed_count": 3298364, "hero": "https://pe.tedcdn.com/images/ted/71994797fda57ea0039fefb37e2f2ebe1adc00c6_2880x1620.jpg", "title": "A roadmap to end aging", "id": 39, "speaker": "Aubrey de Grey", "duration": 1365, "slug": "aubrey_de_grey_says_we_can_avoid_aging"}, {"viewed_count": 833265, "hero": "https://pe.tedcdn.com/images/ted/a3fea45a86df894b308f87246fb42039a7906458_2880x1620.jpg", "title": "How digital DNA could help you make better health choices", "id": 2871, "speaker": "Jun Wang", "duration": 894, "slug": "jun_wang_how_digital_dna_could_help_you_make_better_health_choices"}, {"viewed_count": 1023107, "hero": "https://pe.tedcdn.com/images/ted/25f5beb74f39d8d9cc710103ee3e81b23c90b8a9_800x600.jpg", "title": "Are we ready for neo-evolution?", "id": 1131, "speaker": "Harvey Fineberg", "duration": 1041, "slug": "harvey_fineberg_are_we_ready_for_neo_evolution"}, {"viewed_count": 1070754, "hero": "https://pe.tedcdn.com/images/ted/9414703afe03e50257e331ea4819356b3f08317d_2880x1620.jpg", "title": "Science didn\'t understand my kids\' rare disease until I decided to study it", "id": 2800, "speaker": "Sharon Terry", "duration": 902, "slug": "sharon_terry_science_didn_t_understand_my_kids_rare_disease_until_i_decided_to_study_it"}], "recorded_at": "2003-02-02T00:00:00.000+00:00", "slug": "gregory_stock_to_upgrade_is_human", "speaker_name": "Gregory Stock", "viewed_count": 498844, "event_badge": null, "event_blurb": "This talk was presented at an official TED conference, and was featured by our editors on the home page.", "recommendations": null, "corrections": null}], "event": "TED2003", "name": "Gregory Stock: To upgrade is human"}'
p453
sS'keywords'
p454
(lp455
Vbiology
p456
aVbiotech
p457
aVchildren
p458
aVevolution
p459
aVgenetics
p460
aVscience
p461
aVtechnology
p462
asS'datecrawled'
p463
g448
(S"\x07\xe1\n\x17\x00\x1c'\n\xe2\xac"
tRp464
sS'id'
p465
I515
ss.