(dp1
S'talk_transcript'
p2
(lp3
(lp4
VIf you ask people about what part of psychology do they think is hard,
p5
aVand you say, "Well, what about thinking and emotions?"
p6
aVMost people will say, "Emotions are terribly hard.
p7
aVThey're incredibly complex. They can't \u2014 I have no idea of how they work.
p8
aVBut thinking is really very straightforward:
p9
aVit's just sort of some kind of logical reasoning, or something.
p10
aVBut that's not the hard part."
p11
aa(lp12
VSo here's a list of problems that come up.
p13
aVOne nice problem is, what do we do about health?
p14
aVThe other day, I was reading something, and the person said
p15
aVprobably the largest single cause of disease is handshaking in the West.
p16
aVAnd there was a little study about people who don't handshake,
p17
aVand comparing them with ones who do handshake.
p18
aVAnd I haven't the foggiest idea of where you find the ones that don't handshake,
p19
aVbecause they must be hiding.
p20
aVAnd the people who avoid that
p21
aVhave 30 percent less infectious disease or something.
p22
aVOr maybe it was 31 and a quarter percent.
p23
aVSo if you really want to solve the problem of epidemics and so forth,
p24
aVlet's start with that. And since I got that idea,
p25
aVI've had to shake hundreds of hands.
p26
aVAnd I think the only way to avoid it
p27
aVis to have some horrible visible disease,
p28
aVand then you don't have to explain.
p29
aa(lp30
VEducation: how do we improve education?
p31
aVWell, the single best way is to get them to understand
p32
aVthat what they're being told is a whole lot of nonsense.
p33
aVAnd then, of course, you have to do something
p34
aVabout how to moderate that, so that anybody can \u2014 so they'll listen to you.
p35
aVPollution, energy shortage, environmental diversity, poverty.
p36
aVHow do we make stable societies? Longevity.
p37
aVOkay, there're lots of problems to worry about.
p38
aa(lp39
VAnyway, the question I think people should talk about \u2014
p40
aVand it's absolutely taboo \u2014 is, how many people should there be?
p41
aVAnd I think it should be about 100 million or maybe 500 million.
p42
aVAnd then notice that a great many of these problems disappear.
p43
aVIf you had 100 million people
p44
aVproperly spread out, then if there's some garbage,
p45
aVyou throw it away, preferably where you can't see it, and it will rot.
p46
aVOr you throw it into the ocean and some fish will benefit from it.
p47
aVThe problem is, how many people should there be?
p48
aVAnd it's a sort of choice we have to make.
p49
aa(lp50
VMost people are about 60 inches high or more,
p51
aVand there's these cube laws. So if you make them this big,
p52
aVby using nanotechnology, I suppose \u2014
p53
aV(Laughter)
p54
aV\u2014 then you could have a thousand times as many.
p55
aVThat would solve the problem, but I don't see anybody
p56
aVdoing any research on making people smaller.
p57
aVNow, it's nice to reduce the population, but a lot of people want to have children.
p58
aVAnd there's one solution that's probably only a few years off.
p59
aVYou know you have 46 chromosomes. If you're lucky, you've got 23
p60
aVfrom each parent. Sometimes you get an extra one or drop one out,
p61
aVbut \u2014 so you can skip the grandparent and great-grandparent stage
p62
aVand go right to the great-great-grandparent. And you have 46 people
p63
aVand you give them a scanner, or whatever you need,
p64
aVand they look at their chromosomes and each of them says
p65
aVwhich one he likes best, or she \u2014 no reason to have just two sexes
p66
aVany more, even. So each child has 46 parents,
p67
aVand I suppose you could let each group of 46 parents have 15 children.
p68
aVWouldn't that be enough? And then the children
p69
aVwould get plenty of support, and nurturing, and mentoring,
p70
aVand the world population would decline very rapidly
p71
aVand everybody would be totally happy.
p72
aa(lp73
VTimesharing is a little further off in the future.
p74
aVAnd there's this great novel that Arthur Clarke wrote twice,
p75
aVcalled "Against the Fall of Night" and "The City and the Stars."
p76
aVThey're both wonderful and largely the same,
p77
aVexcept that computers happened in between.
p78
aVAnd Arthur was looking at this old book, and he said, "Well, that was wrong.
p79
aVThe future must have some computers."
p80
aVSo in the second version of it, there are 100 billion
p81
aVor 1,000 billion people on Earth, but they're all stored on hard disks or floppies,
p82
aVor whatever they have in the future.
p83
aVAnd you let a few million of them out at a time.
p84
aVA person comes out, they live for a thousand years
p85
aVdoing whatever they do, and then, when it's time to go back
p86
aVfor a billion years \u2014 or a million, I forget, the numbers don't matter \u2014
p87
aVbut there really aren't very many people on Earth at a time.
p88
aVAnd you get to think about yourself and your memories,
p89
aVand before you go back into suspension, you edit your memories
p90
aVand you change your personality and so forth.
p91
aVThe plot of the book is that there's not enough diversity,
p92
aVso that the people who designed the city
p93
aVmake sure that every now and then an entirely new person is created.
p94
aVAnd in the novel, a particular one named Alvin is created. And he says,
p95
aVmaybe this isn't the best way, and wrecks the whole system.
p96
aa(lp97
VI don't think the solutions that I proposed
p98
aVare good enough or smart enough.
p99
aVI think the big problem is that we're not smart enough
p100
aVto understand which of the problems we're facing are good enough.
p101
aVTherefore, we have to build super intelligent machines like HAL.
p102
aVAs you remember, at some point in the book for "2001,"
p103
aVHAL realizes that the universe is too big, and grand, and profound
p104
aVfor those really stupid astronauts. If you contrast HAL's behavior
p105
aVwith the triviality of the people on the spaceship,
p106
aVyou can see what's written between the lines.
p107
aVWell, what are we going to do about that? We could get smarter.
p108
aVI think that we're pretty smart, as compared to chimpanzees,
p109
aVbut we're not smart enough to deal with the colossal problems that we face,
p110
aVeither in abstract mathematics
p111
aVor in figuring out economies, or balancing the world around.
p112
aVSo one thing we can do is live longer.
p113
aVAnd nobody knows how hard that is,
p114
aVbut we'll probably find out in a few years.
p115
aVYou see, there's two forks in the road. We know that people live
p116
aVtwice as long as chimpanzees almost,
p117
aVand nobody lives more than 120 years,
p118
aVfor reasons that aren't very well understood.
p119
aVBut lots of people now live to 90 or 100,
p120
aVunless they shake hands too much or something like that.
p121
aVAnd so maybe if we lived 200 years, we could accumulate enough skills
p122
aVand knowledge to solve some problems.
p123
aVSo that's one way of going about it.
p124
aVAnd as I said, we don't know how hard that is. It might be \u2014
p125
aVafter all, most other mammals live half as long as the chimpanzee,
p126
aVso we're sort of three and a half or four times, have four times
p127
aVthe longevity of most mammals. And in the case of the primates,
p128
aVwe have almost the same genes. We only differ from chimpanzees,
p129
aVin the present state of knowledge, which is absolute hogwash,
p130
aVmaybe by just a few hundred genes.
p131
aa(lp132
VWhat I think is that the gene counters don't know what they're doing yet.
p133
aVAnd whatever you do, don't read anything about genetics
p134
aVthat's published within your lifetime, or something.
p135
aV(Laughter)
p136
aVThe stuff has a very short half-life, same with brain science.
p137
aVAnd so it might be that if we just fix four or five genes,
p138
aVwe can live 200 years.
p139
aVOr it might be that it's just 30 or 40,
p140
aVand I doubt that it's several hundred.
p141
aVSo this is something that people will be discussing
p142
aVand lots of ethicists \u2014 you know, an ethicist is somebody
p143
aVwho sees something wrong with whatever you have in mind.
p144
aV(Laughter)
p145
aVAnd it's very hard to find an ethicist who considers any change
p146
aVworth making, because he says, what about the consequences?
p147
aVAnd, of course, we're not responsible for the consequences
p148
aVof what we're doing now, are we? Like all this complaint about clones.
p149
aVAnd yet two random people will mate and have this child,
p150
aVand both of them have some pretty rotten genes,
p151
aVand the child is likely to come out to be average.
p152
aVWhich, by chimpanzee standards, is very good indeed.
p153
aa(lp154
VIf we do have longevity, then we'll have to face the population growth
p155
aVproblem anyway. Because if people live 200 or 1,000 years,
p156
aVthen we can't let them have a child more than about once every 200 or 1,000 years.
p157
aVAnd so there won't be any workforce.
p158
aVAnd one of the things Laurie Garrett pointed out, and others have,
p159
aVis that a society that doesn't have people
p160
aVof working age is in real trouble. And things are going to get worse,
p161
aVbecause there's nobody to educate the children or to feed the old.
p162
aVAnd when I'm talking about a long lifetime, of course,
p163
aVI don't want somebody who's 200 years old to be like our image
p164
aVof what a 200-year-old is \u2014 which is dead, actually.
p165
aa(lp166
VYou know, there's about 400 different parts of the brain
p167
aVwhich seem to have different functions.
p168
aVNobody knows how most of them work in detail,
p169
aVbut we do know that there're lots of different things in there.
p170
aVAnd they don't always work together. I like Freud's theory
p171
aVthat most of them are cancelling each other out.
p172
aVAnd so if you think of yourself as a sort of city
p173
aVwith a hundred resources, then, when you're afraid, for example,
p174
aVyou may discard your long-range goals, but you may think deeply
p175
aVand focus on exactly how to achieve that particular goal.
p176
aVYou throw everything else away. You become a monomaniac \u2014
p177
aVall you care about is not stepping out on that platform.
p178
aVAnd when you're hungry, food becomes more attractive, and so forth.
p179
aVSo I see emotions as highly evolved subsets of your capability.
p180
aVEmotion is not something added to thought. An emotional state
p181
aVis what you get when you remove 100 or 200
p182
aVof your normally available resources.
p183
aa(lp184
VSo thinking of emotions as the opposite of \u2014 as something
p185
aVless than thinking is immensely productive. And I hope,
p186
aVin the next few years, to show that this will lead to smart machines.
p187
aVAnd I guess I better skip all the rest of this, which are some details
p188
aVon how we might make those smart machines and \u2014
p189
aV(Laughter)
p190
aV\u2014 and the main idea is in fact that the core of a really smart machine
p191
aVis one that recognizes that a certain kind of problem is facing you.
p192
aVThis is a problem of such and such a type,
p193
aVand therefore there's a certain way or ways of thinking
p194
aVthat are good for that problem.
p195
aVSo I think the future, main problem of psychology is to classify
p196
aVtypes of predicaments, types of situations, types of obstacles
p197
aVand also to classify available and possible ways to think and pair them up.
p198
aVSo you see, it's almost like a Pavlovian \u2014
p199
aVwe lost the first hundred years of psychology
p200
aVby really trivial theories, where you say,
p201
aVhow do people learn how to react to a situation? What I'm saying is,
p202
aVafter we go through a lot of levels, including designing
p203
aVa huge, messy system with thousands of ports,
p204
aVwe'll end up again with the central problem of psychology.
p205
aVSaying, not what are the situations,
p206
aVbut what are the kinds of problems
p207
aVand what are the kinds of strategies, how do you learn them,
p208
aVhow do you connect them up, how does a really creative person
p209
aVinvent a new way of thinking out of the available resources and so forth.
p210
aa(lp211
VSo, I think in the next 20 years,
p212
aVif we can get rid of all of the traditional approaches to artificial intelligence,
p213
aVlike neural nets and genetic algorithms
p214
aVand rule-based systems, and just turn our sights a little bit higher to say,
p215
aVcan we make a system that can use all those things
p216
aVfor the right kind of problem? Some problems are good for neural nets;
p217
aVwe know that others, neural nets are hopeless on them.
p218
aVGenetic algorithms are great for certain things;
p219
aVI suspect I know what they're bad at, and I won't tell you.
p220
aV(Laughter)
p221
aa(lp222
VThank you.
p223
aV(Applause)
p224
aasS'transcript_micsec'
p225
(lp226
I11000
aI38000
aI101000
aI130000
aI174000
aI254000
aI346000
aI476000
aI552000
aI598000
aI661000
aI761000
aI793000
asS'talk_meta'
p227
(dp228
S'ratings'
p229
(dp230
S'ingenious'
p231
I55
sS'funny'
p232
I106
sS'inspiring'
p233
I33
sS'ok'
p234
I55
sS'fascinating'
p235
I71
sS'total_count'
p236
I728
sS'persuasive'
p237
I17
sS'longwinded'
p238
I62
sS'unconvincing'
p239
I89
sS'informative'
p240
I63
sS'beautiful'
p241
I5
sS'jaw-dropping'
p242
I10
sS'obnoxious'
p243
I27
sS'courageous'
p244
I24
sS'confusing'
p245
I111
ssS'author'
p246
VMarvin_Minsky;
p247
sS'url'
p248
S'https://www.ted.com/talks/marvin_minsky_on_health_and_the_human_mind'
p249
sS'vidlen'
p250
I813
sS'totalviews'
p251
I515281
sS'title'
p252
VHealth and the human mind
p253
sS'downloadlink'
p254
Vhttps://download.ted.com/talks/MarvinMinsky_2003.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22
p255
sS'datepublished'
p256
cdatetime
datetime
p257
(S'\x07\xd8\t\x15\x15\x0c\x00\x00\x00\x00'
tRp258
sS'datefilmed'
p259
g257
(S'\x07\xd8\t\x15\x15\x0c\x00\x00\x00\x00'
tRp260
sS'alldata_JSON'
p261
S'{"viewed_count": 515281, "speakers": [{"description": "AI pioneer", "firstname": "Marvin", "title": "", "lastname": "Minsky", "middleinitial": "", "whylisten": "<p>Marvin Minsky is the superstar-elder of artificial intelligence, one of the most productive and important cognitive scientists of the century, and the leading proponent of the Society of Mind theory. Articulated in his 1985 book of the same name, Minsky&#39;s theory says<strong> intelligence is not born of any single mechanism, but from the interaction of many independent agents</strong>. The book&#39;s sequel,<a href=\\"http://geni.us/emotionmachine\\" target=\\"_blank\\"><em>The Emotion Machine</em></a>&nbsp;(2006), says similar activity also accounts for feelings, goals, emotions and conscious thoughts.</p><p>Minsky also <strong>pioneered advances in mathematics, computational linguistics, optics, robotics and telepresence</strong>. He built SNARC, the first neural network simulator, some of the first visual scanners, and the first LOGO &quot;turtle.&quot; From his headquarters at MIT&#39;s Media Lab and the AI Lab (which he helped found), he continues to work on, as he says, &quot;imparting to machines the human capacity for commonsense reasoning.&quot;</p>", "slug": "marvin_minsky", "whotheyare": "Marvin Minsky is one of the great pioneers of artificial intelligence -- and using computing metaphors to understand the human mind. His contributions to mathematics, robotics and computational linguistics are legendary and far-reaching.", "whatotherssay": "", "id": 285, "photo_url": "https://pe.tedcdn.com/images/ted/55211_254x191.jpg"}], "current_talk": 351, "description": "Listen closely -- Marvin Minsky\'s arch, eclectic, charmingly offhand talk on health, overpopulation and the human mind is packed with subtlety: wit, wisdom and just an ounce of wily, is-he-joking? advice.", "language": "en", "url": "https://www.ted.com/talks/marvin_minsky_on_health_and_the_human_mind", "media": {"internal": {"podcast-high-en": {"uri": "https://download.ted.com/talks/MarvinMinsky_2003-480p-en.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 94066436}, "podcast-low-en": {"uri": "https://download.ted.com/talks/MarvinMinsky_2003-low-en.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 18557579}, "podcast-high": {"uri": "https://download.ted.com/talks/MarvinMinsky_2003-480p.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 94022052}, "180k": {"uri": "https://download.ted.com/talks/MarvinMinsky_2003-180k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 18448408}, "64k": {"uri": "https://download.ted.com/talks/MarvinMinsky_2003-64k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 6649164}, "1500k": {"uri": "https://download.ted.com/talks/MarvinMinsky_2003-1500k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 147750623}, "450k": {"uri": "https://download.ted.com/talks/MarvinMinsky_2003-450k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 45747066}, "podcast-regular": {"uri": "https://download.ted.com/talks/MarvinMinsky_2003.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 46021669}, "950k": {"uri": "https://download.ted.com/talks/MarvinMinsky_2003-950k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 93768785}, "audio-podcast": {"uri": "https://download.ted.com/talks/MarvinMinsky_2003.mp3?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "audio/mp3", "filesize_bytes": 6018686}, "podcast-light": {"uri": "https://download.ted.com/talks/MarvinMinsky_2003-light.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 6748985}, "320k": {"uri": "https://download.ted.com/talks/MarvinMinsky_2003-320k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 32613370}, "600k": {"uri": "https://download.ted.com/talks/MarvinMinsky_2003-600k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 60854154}}}, "comments": {"count": 45, "id": 305, "talk_id": 351}, "slug": "marvin_minsky_on_health_and_the_human_mind", "threadId": 305, "talks": [{"event": "TED2003", "player_talks": [{"event": "TED2003", "slug": "marvin_minsky_on_health_and_the_human_mind", "filmed": 1044144000, "targeting": {"event": "TED2003", "tag": "brain,evolutionary psychology,health,humanity,humor,psychology,science,technology", "id": 351, "talk": "marvin_minsky_on_health_and_the_human_mind", "year": "2003"}, "adDuration": "3.33", "external": null, "title": "Health and the human mind", "postAdDuration": "0.83", "published": 1222045920, "thumb": "https://pi.tedcdn.com/r/pe.tedcdn.com/images/ted/708fb1016e05e4d0d86e99caaf1202f41c21687e_2880x1620.jpg?quality=89&w=600", "name": "Marvin Minsky: Health and the human mind", "languages": [{"languageCode": "ar", "endonym": "\\u0627\\u0644\\u0639\\u0631\\u0628\\u064a\\u0629", "isRtl": true, "ianaCode": "ar", "languageName": "Arabic"}, {"languageCode": "bg", "endonym": "\\u0431\\u044a\\u043b\\u0433\\u0430\\u0440\\u0441\\u043a\\u0438", "isRtl": false, "ianaCode": "bg", "languageName": "Bulgarian"}, {"languageCode": "zh-cn", "endonym": "\\u4e2d\\u6587 (\\u7b80\\u4f53)", "isRtl": false, "ianaCode": "zh-Hans", "languageName": "Chinese, Simplified"}, {"languageCode": "zh-tw", "endonym": "\\u4e2d\\u6587 (\\u7e41\\u9ad4)", "isRtl": false, "ianaCode": "zh-Hant", "languageName": "Chinese, Traditional"}, {"languageCode": "hr", "endonym": "Hrvatski", "isRtl": false, "ianaCode": "hr", "languageName": "Croatian"}, {"languageCode": "cs", "endonym": "\\u010ce\\u0161tina", "isRtl": false, "ianaCode": "cs", "languageName": "Czech"}, {"languageCode": "nl", "endonym": "Nederlands", "isRtl": false, "ianaCode": "nl", "languageName": "Dutch"}, {"languageCode": "en", "endonym": "English", "isRtl": false, "ianaCode": "en", "languageName": "English"}, {"languageCode": "fr", "endonym": "Fran\\u00e7ais", "isRtl": false, "ianaCode": "fr", "languageName": "French"}, {"languageCode": "de", "endonym": "Deutsch", "isRtl": false, "ianaCode": "de", "languageName": "German"}, {"languageCode": "he", "endonym": "\\u05e2\\u05d1\\u05e8\\u05d9\\u05ea", "isRtl": true, "ianaCode": "he", "languageName": "Hebrew"}, {"languageCode": "it", "endonym": "Italiano", "isRtl": false, "ianaCode": "it", "languageName": "Italian"}, {"languageCode": "ja", "endonym": "\\u65e5\\u672c\\u8a9e", "isRtl": false, "ianaCode": "ja", "languageName": "Japanese"}, {"languageCode": "ko", "endonym": "\\ud55c\\uad6d\\uc5b4", "isRtl": false, "ianaCode": "ko", "languageName": "Korean"}, {"languageCode": "pl", "endonym": "Polski", "isRtl": false, "ianaCode": "pl", "languageName": "Polish"}, {"languageCode": "pt", "endonym": "Portugu\\u00eas de Portugal", "isRtl": false, "ianaCode": "pt", "languageName": "Portuguese"}, {"languageCode": "pt-br", "endonym": "Portugu\\u00eas brasileiro", "isRtl": false, "ianaCode": "pt-BR", "languageName": "Portuguese, Brazilian"}, {"languageCode": "ro", "endonym": "Rom\\u00e2n\\u0103", "isRtl": false, "ianaCode": "ro", "languageName": "Romanian"}, {"languageCode": "ru", "endonym": "\\u0420\\u0443\\u0441\\u0441\\u043a\\u0438\\u0439", "isRtl": false, "ianaCode": "ru", "languageName": "Russian"}, {"languageCode": "es", "endonym": "Espa\\u00f1ol", "isRtl": false, "ianaCode": "es", "languageName": "Spanish"}, {"languageCode": "tr", "endonym": "T\\u00fcrk\\u00e7e", "isRtl": false, "ianaCode": "tr", "languageName": "Turkish"}, {"languageCode": "vi", "endonym": "Ti\\u1ebfng Vi\\u1ec7t", "isRtl": false, "ianaCode": "vi", "languageName": "Vietnamese"}], "nativeLanguage": "en", "tags": ["brain", "evolutionary psychology", "health", "humanity", "humor", "psychology", "science", "technology"], "speaker": "Marvin Minsky", "isSubtitleRequired": false, "introDuration": 11.82, "duration": 813, "id": 351, "resources": {"h264": [{"bitrate": 320, "file": "https://download.ted.com/talks/MarvinMinsky_2003-320k.mp4?dnt"}], "hls": {"maiTargeting": {"event": "TED2003", "tag": "brain,evolutionary psychology,health,humanity,humor,psychology,science,technology", "id": 351, "talk": "marvin_minsky_on_health_and_the_human_mind", "year": "2003"}, "metadata": "https://hls.ted.com/talks/351.json", "stream": "https://hls.ted.com/talks/351.m3u8", "adUrl": "https://pubads.g.doubleclick.net/gampad/ads?ciu_szs=300x250%2C512x288%2C120x60%2C320x50%2C6x7%2C6x8&correlator=%5Bcorrelator%5D&cust_params=event%3DTED2003%26id%3D351%26tag%3Dbrain%2Cevolutionary%2Bpsychology%2Chealth%2Chumanity%2Chumor%2Cpsychology%2Cscience%2Ctechnology%26talk%3Dmarvin_minsky_on_health_and_the_human_mind%26year%3D2003&env=vp&gdfp_req=1&impl=s&iu=%2F5641%2Fmobile%2Fios%2Fweb&output=xml_vast2&sz=640x360&unviewed_position_start=1&url=%5Breferrer%5D"}}, "canonical": "https://www.ted.com/talks/marvin_minsky_on_health_and_the_human_mind"}], "hero_load": "https://pi.tedcdn.com/r/pe.tedcdn.com/images/ted/708fb1016e05e4d0d86e99caaf1202f41c21687e_2880x1620.jpg?q=50&w=15", "duration": 813, "id": 351, "ratings": [{"count": 55, "id": 25, "name": "OK"}, {"count": 89, "id": 21, "name": "Unconvincing"}, {"count": 111, "id": 2, "name": "Confusing"}, {"count": 55, "id": 9, "name": "Ingenious"}, {"count": 71, "id": 22, "name": "Fascinating"}, {"count": 106, "id": 7, "name": "Funny"}, {"count": 62, "id": 11, "name": "Longwinded"}, {"count": 24, "id": 3, "name": "Courageous"}, {"count": 27, "id": 26, "name": "Obnoxious"}, {"count": 63, "id": 8, "name": "Informative"}, {"count": 33, "id": 10, "name": "Inspiring"}, {"count": 17, "id": 24, "name": "Persuasive"}, {"count": 10, "id": 23, "name": "Jaw-dropping"}, {"count": 5, "id": 1, "name": "Beautiful"}], "speakers": [{"description": "AI pioneer", "firstname": "Marvin", "title": "", "lastname": "Minsky", "middleinitial": "", "whylisten": "<p>Marvin Minsky is the superstar-elder of artificial intelligence, one of the most productive and important cognitive scientists of the century, and the leading proponent of the Society of Mind theory. Articulated in his 1985 book of the same name, Minsky&#39;s theory says<strong> intelligence is not born of any single mechanism, but from the interaction of many independent agents</strong>. The book&#39;s sequel,<a href=\\"http://geni.us/emotionmachine\\" target=\\"_blank\\"><em>The Emotion Machine</em></a>&nbsp;(2006), says similar activity also accounts for feelings, goals, emotions and conscious thoughts.</p><p>Minsky also <strong>pioneered advances in mathematics, computational linguistics, optics, robotics and telepresence</strong>. He built SNARC, the first neural network simulator, some of the first visual scanners, and the first LOGO &quot;turtle.&quot; From his headquarters at MIT&#39;s Media Lab and the AI Lab (which he helped found), he continues to work on, as he says, &quot;imparting to machines the human capacity for commonsense reasoning.&quot;</p>", "slug": "marvin_minsky", "whotheyare": "Marvin Minsky is one of the great pioneers of artificial intelligence -- and using computing metaphors to understand the human mind. His contributions to mathematics, robotics and computational linguistics are legendary and far-reaching.", "whatotherssay": "", "id": 285, "photo_url": "https://pe.tedcdn.com/images/ted/55211_254x191.jpg"}], "title": "Health and the human mind", "take_action": null, "comments": 305, "more_resources": null, "hero": "https://pe.tedcdn.com/images/ted/708fb1016e05e4d0d86e99caaf1202f41c21687e_2880x1620.jpg", "description": "Listen closely -- Marvin Minsky\'s arch, eclectic, charmingly offhand talk on health, overpopulation and the human mind is packed with subtlety: wit, wisdom and just an ounce of wily, is-he-joking? advice.", "tags": ["brain", "evolutionary psychology", "health", "humanity", "humor", "psychology", "science", "technology"], "downloads": {"languages": [{"languageCode": "ar", "endonym": "\\u0627\\u0644\\u0639\\u0631\\u0628\\u064a\\u0629", "isRtl": true, "ianaCode": "ar", "languageName": "Arabic"}, {"languageCode": "bg", "endonym": "\\u0431\\u044a\\u043b\\u0433\\u0430\\u0440\\u0441\\u043a\\u0438", "isRtl": false, "ianaCode": "bg", "languageName": "Bulgarian"}, {"languageCode": "zh-cn", "endonym": "\\u4e2d\\u6587 (\\u7b80\\u4f53)", "isRtl": false, "ianaCode": "zh-Hans", "languageName": "Chinese, Simplified"}, {"languageCode": "zh-tw", "endonym": "\\u4e2d\\u6587 (\\u7e41\\u9ad4)", "isRtl": false, "ianaCode": "zh-Hant", "languageName": "Chinese, Traditional"}, {"languageCode": "hr", "endonym": "Hrvatski", "isRtl": false, "ianaCode": "hr", "languageName": "Croatian"}, {"languageCode": "cs", "endonym": "\\u010ce\\u0161tina", "isRtl": false, "ianaCode": "cs", "languageName": "Czech"}, {"languageCode": "nl", "endonym": "Nederlands", "isRtl": false, "ianaCode": "nl", "languageName": "Dutch"}, {"languageCode": "en", "endonym": "English", "isRtl": false, "ianaCode": "en", "languageName": "English"}, {"languageCode": "fr", "endonym": "Fran\\u00e7ais", "isRtl": false, "ianaCode": "fr", "languageName": "French"}, {"languageCode": "de", "endonym": "Deutsch", "isRtl": false, "ianaCode": "de", "languageName": "German"}, {"languageCode": "he", "endonym": "\\u05e2\\u05d1\\u05e8\\u05d9\\u05ea", "isRtl": true, "ianaCode": "he", "languageName": "Hebrew"}, {"languageCode": "it", "endonym": "Italiano", "isRtl": false, "ianaCode": "it", "languageName": "Italian"}, {"languageCode": "ja", "endonym": "\\u65e5\\u672c\\u8a9e", "isRtl": false, "ianaCode": "ja", "languageName": "Japanese"}, {"languageCode": "ko", "endonym": "\\ud55c\\uad6d\\uc5b4", "isRtl": false, "ianaCode": "ko", "languageName": "Korean"}, {"languageCode": "pl", "endonym": "Polski", "isRtl": false, "ianaCode": "pl", "languageName": "Polish"}, {"languageCode": "pt", "endonym": "Portugu\\u00eas de Portugal", "isRtl": false, "ianaCode": "pt", "languageName": "Portuguese"}, {"languageCode": "pt-br", "endonym": "Portugu\\u00eas brasileiro", "isRtl": false, "ianaCode": "pt-BR", "languageName": "Portuguese, Brazilian"}, {"languageCode": "ro", "endonym": "Rom\\u00e2n\\u0103", "isRtl": false, "ianaCode": "ro", "languageName": "Romanian"}, {"languageCode": "ru", "endonym": "\\u0420\\u0443\\u0441\\u0441\\u043a\\u0438\\u0439", "isRtl": false, "ianaCode": "ru", "languageName": "Russian"}, {"languageCode": "es", "endonym": "Espa\\u00f1ol", "isRtl": false, "ianaCode": "es", "languageName": "Spanish"}, {"languageCode": "tr", "endonym": "T\\u00fcrk\\u00e7e", "isRtl": false, "ianaCode": "tr", "languageName": "Turkish"}, {"languageCode": "vi", "endonym": "Ti\\u1ebfng Vi\\u1ec7t", "isRtl": false, "ianaCode": "vi", "languageName": "Vietnamese"}], "subtitledDownloads": {"en": {"high": "https://download.ted.com/talks/MarvinMinsky_2003-480p-en.mp4", "name": "English", "low": "https://download.ted.com/talks/MarvinMinsky_2003-low-en.mp4"}, "vi": {"high": "https://download.ted.com/talks/MarvinMinsky_2003-480p-vi.mp4", "name": "Vietnamese", "low": "https://download.ted.com/talks/MarvinMinsky_2003-low-vi.mp4"}, "it": {"high": "https://download.ted.com/talks/MarvinMinsky_2003-480p-it.mp4", "name": "Italian", "low": "https://download.ted.com/talks/MarvinMinsky_2003-low-it.mp4"}, "ar": {"high": "https://download.ted.com/talks/MarvinMinsky_2003-480p-ar.mp4", "name": "Arabic", "low": "https://download.ted.com/talks/MarvinMinsky_2003-low-ar.mp4"}, "pt-br": {"high": "https://download.ted.com/talks/MarvinMinsky_2003-480p-pt-br.mp4", "name": "Portuguese, Brazilian", "low": "https://download.ted.com/talks/MarvinMinsky_2003-low-pt-br.mp4"}, "cs": {"high": "https://download.ted.com/talks/MarvinMinsky_2003-480p-cs.mp4", "name": "Czech", "low": "https://download.ted.com/talks/MarvinMinsky_2003-low-cs.mp4"}, "es": {"high": "https://download.ted.com/talks/MarvinMinsky_2003-480p-es.mp4", "name": "Spanish", "low": "https://download.ted.com/talks/MarvinMinsky_2003-low-es.mp4"}, "ru": {"high": "https://download.ted.com/talks/MarvinMinsky_2003-480p-ru.mp4", "name": "Russian", "low": "https://download.ted.com/talks/MarvinMinsky_2003-low-ru.mp4"}, "nl": {"high": "https://download.ted.com/talks/MarvinMinsky_2003-480p-nl.mp4", "name": "Dutch", "low": "https://download.ted.com/talks/MarvinMinsky_2003-low-nl.mp4"}, "pt": {"high": "https://download.ted.com/talks/MarvinMinsky_2003-480p-pt.mp4", "name": "Portuguese", "low": "https://download.ted.com/talks/MarvinMinsky_2003-low-pt.mp4"}, "zh-tw": {"high": "https://download.ted.com/talks/MarvinMinsky_2003-480p-zh-tw.mp4", "name": "Chinese, Traditional", "low": "https://download.ted.com/talks/MarvinMinsky_2003-low-zh-tw.mp4"}, "tr": {"high": "https://download.ted.com/talks/MarvinMinsky_2003-480p-tr.mp4", "name": "Turkish", "low": "https://download.ted.com/talks/MarvinMinsky_2003-low-tr.mp4"}, "zh-cn": {"high": "https://download.ted.com/talks/MarvinMinsky_2003-480p-zh-cn.mp4", "name": "Chinese, Simplified", "low": "https://download.ted.com/talks/MarvinMinsky_2003-low-zh-cn.mp4"}, "ro": {"high": "https://download.ted.com/talks/MarvinMinsky_2003-480p-ro.mp4", "name": "Romanian", "low": "https://download.ted.com/talks/MarvinMinsky_2003-low-ro.mp4"}, "pl": {"high": "https://download.ted.com/talks/MarvinMinsky_2003-480p-pl.mp4", "name": "Polish", "low": "https://download.ted.com/talks/MarvinMinsky_2003-low-pl.mp4"}, "fr": {"high": "https://download.ted.com/talks/MarvinMinsky_2003-480p-fr.mp4", "name": "French", "low": "https://download.ted.com/talks/MarvinMinsky_2003-low-fr.mp4"}, "bg": {"high": "https://download.ted.com/talks/MarvinMinsky_2003-480p-bg.mp4", "name": "Bulgarian", "low": "https://download.ted.com/talks/MarvinMinsky_2003-low-bg.mp4"}, "hr": {"high": "https://download.ted.com/talks/MarvinMinsky_2003-480p-hr.mp4", "name": "Croatian", "low": "https://download.ted.com/talks/MarvinMinsky_2003-low-hr.mp4"}, "de": {"high": "https://download.ted.com/talks/MarvinMinsky_2003-480p-de.mp4", "name": "German", "low": "https://download.ted.com/talks/MarvinMinsky_2003-low-de.mp4"}, "ja": {"high": "https://download.ted.com/talks/MarvinMinsky_2003-480p-ja.mp4", "name": "Japanese", "low": "https://download.ted.com/talks/MarvinMinsky_2003-low-ja.mp4"}, "he": {"high": "https://download.ted.com/talks/MarvinMinsky_2003-480p-he.mp4", "name": "Hebrew", "low": "https://download.ted.com/talks/MarvinMinsky_2003-low-he.mp4"}, "ko": {"high": "https://download.ted.com/talks/MarvinMinsky_2003-480p-ko.mp4", "name": "Korean", "low": "https://download.ted.com/talks/MarvinMinsky_2003-low-ko.mp4"}}, "nativeDownloads": {"high": "https://download.ted.com/talks/MarvinMinsky_2003-480p.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "medium": "https://download.ted.com/talks/MarvinMinsky_2003.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "low": "https://download.ted.com/talks/MarvinMinsky_2003-light.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22"}, "id": 351, "audioDownload": "https://download.ted.com/talks/MarvinMinsky_2003.mp3?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22"}, "related_talks": [{"viewed_count": 1379294, "hero": "https://pe.tedcdn.com/images/ted/dfc244d5b81ab35ce80a3c4f19877b23f8be7a27_2880x1620.jpg", "title": "How brain science will change computing", "id": 125, "speaker": "Jeff Hawkins", "duration": 1211, "slug": "jeff_hawkins_on_how_brain_science_will_change_computing"}, {"viewed_count": 583222, "hero": "https://pe.tedcdn.com/images/ted/49376_480x360.jpg", "title": "A computer that works like the brain", "id": 320, "speaker": "Kwabena Boahen", "duration": 982, "slug": "kwabena_boahen_on_a_computer_that_works_like_the_brain"}, {"viewed_count": 21351125, "hero": "https://pe.tedcdn.com/images/ted/eefe30d20338d800bdc70a09dc0f6007e7355a74_2880x1620.jpg", "title": "My stroke of insight", "id": 229, "speaker": "Jill Bolte Taylor", "duration": 1099, "slug": "jill_bolte_taylor_s_powerful_stroke_of_insight"}, {"viewed_count": 2897712, "hero": "https://pe.tedcdn.com/images/ted/a693e3148df55358b76a30436f1accb09d1e2616_2880x1620.jpg", "title": "What happens when our computers get smarter than we are?", "id": 2243, "speaker": "Nick Bostrom", "duration": 991, "slug": "nick_bostrom_what_happens_when_our_computers_get_smarter_than_we_are"}, {"viewed_count": 961147, "hero": "https://pe.tedcdn.com/images/ted/bad6d87ce767ae008c56bde103deec058846661e_2880x1620.jpg", "title": "What would happen if we upload our brains to computers?", "id": 2858, "speaker": "Robin Hanson", "duration": 736, "slug": "robin_hanson_what_would_happen_if_we_upload_our_brains_to_computers"}, {"viewed_count": 498847, "hero": "https://pe.tedcdn.com/images/ted/6fbafd80d79e2de8e034457ad118ea3fba0c6884_2880x1620.jpg", "title": "To upgrade is human", "id": 515, "speaker": "Gregory Stock", "duration": 1071, "slug": "gregory_stock_to_upgrade_is_human"}], "recorded_at": "2003-02-02T00:00:00.000+00:00", "slug": "marvin_minsky_on_health_and_the_human_mind", "speaker_name": "Marvin Minsky", "viewed_count": 515281, "event_badge": null, "event_blurb": "This talk was presented at an official TED conference, and was featured by our editors on the home page.", "recommendations": null, "corrections": null}], "event": "TED2003", "name": "Marvin Minsky: Health and the human mind"}'
p262
sS'keywords'
p263
(lp264
Vbrain
p265
aVevolutionary psychology
p266
aVhealth
p267
aVhumanity
p268
aVhumor
p269
aVpsychology
p270
aVscience
p271
aVtechnology
p272
asS'datecrawled'
p273
g257
(S'\x07\xe1\n\x17\x02\x0e\x13\x01\x92\xa5'
tRp274
sS'id'
p275
I351
ss.