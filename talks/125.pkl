(dp1
S'talk_transcript'
p2
(lp3
(lp4
VI do two things:
p5
aVI design mobile computers and I study brains.
p6
aVToday's talk is about brains and \u2014 (Audience member cheers)
p7
aVYay! I have a brain fan out there.
p8
aa(lp9
V(Laughter)
p10
aVIf I could have my first slide,
p11
aVyou'll see the title of my talk and my two affiliations.
p12
aVSo what I'm going to talk about is why we don't have a good brain theory,
p13
aVwhy it is important that we should develop one
p14
aVand what we can do about it.
p15
aVI'll try to do all that in 20 minutes.
p16
aVI have two affiliations.
p17
aVMost of you know me from my Palm and Handspring days,
p18
aVbut I also run a nonprofit scientific research institute
p19
aVcalled the Redwood Neuroscience Institute in Menlo Park.
p20
aVWe study theoretical neuroscience and how the neocortex works.
p21
aVI'm going to talk all about that.
p22
aa(lp23
VI have one slide on my other life, the computer life,
p24
aVand that's this slide here.
p25
aVThese are some of the products I've worked on over the last 20 years,
p26
aVstarting from the very original laptop
p27
aVto some of the first tablet computers
p28
aVand so on, ending up most recently with the Treo,
p29
aVand we're continuing to do this.
p30
aVI've done this because I believe mobile computing
p31
aVis the future of personal computing,
p32
aVand I'm trying to make the world a little bit better
p33
aVby working on these things.
p34
aVBut this was, I admit, all an accident.
p35
aVI really didn't want to do any of these products.
p36
aVVery early in my career
p37
aVI decided I was not going to be in the computer industry.
p38
aa(lp39
VBefore that, I just have to tell you
p40
aVabout this picture of Graffiti I picked off the web the other day.
p41
aVI was looking for a picture for Graffiti that'll text input language.
p42
aVI found a website dedicated to teachers who want to make script-writing things
p43
aVacross the top of their blackboard,
p44
aVand they had added Graffiti to it, and I'm sorry about that.
p45
aa(lp46
V(Laughter)
p47
aa(lp48
VSo what happened was,
p49
aVwhen I was young and got out of engineering school at Cornell in '79,
p50
aVI went to work for Intel and was in the computer industry,
p51
aVand three months into that, I fell in love with something else.
p52
aVI said, "I made the wrong career choice here,"
p53
aVand I fell in love with brains.
p54
aVThis is not a real brain.
p55
aVThis is a picture of one, a line drawing.
p56
aVAnd I don't remember exactly how it happened,
p57
aVbut I have one recollection, which was pretty strong in my mind.
p58
aVIn September of 1979,
p59
aVScientific American came out with a single-topic issue about the brain.
p60
aVIt was one of their best issues ever.
p61
aVThey talked about the neuron, development, disease, vision
p62
aVand all the things you might want to know about brains.
p63
aVIt was really quite impressive.
p64
aa(lp65
VOne might've had the impression we knew a lot about brains.
p66
aVBut the last article in that issue was written by Francis Crick of DNA fame.
p67
aVToday is, I think, the 50th anniversary of the discovery of DNA.
p68
aVAnd he wrote a story basically saying, this is all well and good,
p69
aVbut you know, we don't know diddly squat about brains,
p70
aVand no one has a clue how they work,
p71
aVso don't believe what anyone tells you.
p72
aVThis is a quote from that article, he says:
p73
aV"What is conspicuously lacking" \u2014 he's a very proper British gentleman \u2014
p74
aV"What is conspicuously lacking is a broad framework of ideas
p75
aVin which to interpret these different approaches."
p76
aVI thought the word "framework" was great.
p77
aVHe didn't say we didn't have a theory.
p78
aVHe says we don't even know how to begin to think about it.
p79
aVWe don't even have a framework.
p80
aVWe are in the pre-paradigm days, if you want to use Thomas Kuhn.
p81
aVSo I fell in love with this.
p82
aVI said, look: We have all this knowledge about brains \u2014 how hard can it be?
p83
aVIt's something we can work on in my lifetime; I could make a difference.
p84
aVSo I tried to get out of the computer business, into the brain business.
p85
aa(lp86
VFirst, I went to MIT, the AI lab was there.
p87
aVI said, I want to build intelligent machines too,
p88
aVbut I want to study how brains work first.
p89
aVAnd they said, "Oh, you don't need to do that.
p90
aVYou're just going to program computers, that's all.
p91
aVI said, you really ought to study brains.
p92
aVThey said, "No, you're wrong."
p93
aVI said, "No, you're wrong," and I didn't get in.
p94
aa(lp95
V(Laughter)
p96
aa(lp97
VI was a little disappointed \u2014 pretty young \u2014
p98
aVbut I went back again a few years later,
p99
aVthis time in California, and I went to Berkeley.
p100
aVAnd I said, I'll go in from the biological side.
p101
aVSo I got in the PhD program in biophysics.
p102
aVI was like, I'm studying brains now. Well, I want to study theory.
p103
aVThey said, "You can't study theory about brains.
p104
aVYou can't get funded for that.
p105
aVAnd as a graduate student, you can't do that."
p106
aVSo I said, oh my gosh.
p107
aVI was depressed; I said, but I can make a difference in this field.
p108
aVI went back in the computer industry
p109
aVand said, I'll have to work here for a while.
p110
aVThat's when I designed all those computer products.
p111
aa(lp112
V(Laughter)
p113
aa(lp114
VI said, I want to do this for four years, make some money,
p115
aVI was having a family, and I would mature a bit,
p116
aVand maybe the business of neuroscience would mature a bit.
p117
aVWell, it took longer than four years. It's been about 16 years.
p118
aVBut I'm doing it now, and I'm going to tell you about it.
p119
aVSo why should we have a good brain theory?
p120
aVWell, there's lots of reasons people do science.
p121
aVThe most basic one is, people like to know things.
p122
aVWe're curious, and we go out and get knowledge.
p123
aVWhy do we study ants? It's interesting.
p124
aVMaybe we'll learn something useful, but it's interesting and fascinating.
p125
aVBut sometimes a science has other attributes
p126
aVwhich makes it really interesting.
p127
aa(lp128
VSometimes a science will tell something about ourselves;
p129
aVit'll tell us who we are.
p130
aVEvolution did this and Copernicus did this,
p131
aVwhere we have a new understanding of who we are.
p132
aVAnd after all, we are our brains. My brain is talking to your brain.
p133
aVOur bodies are hanging along for the ride,
p134
aVbut my brain is talking to your brain.
p135
aVAnd if we want to understand who we are and how we feel and perceive,
p136
aVwe need to understand brains.
p137
aVAnother thing is sometimes science leads to big societal benefits, technologies,
p138
aVor businesses or whatever.
p139
aVThis is one, too, because when we understand how brains work,
p140
aVwe'll be able to build intelligent machines.
p141
aVThat's a good thing on the whole,
p142
aVwith tremendous benefits to society,
p143
aVjust like a fundamental technology.
p144
aa(lp145
VSo why don't we have a good theory of brains?
p146
aVPeople have been working on it for 100 years.
p147
aVLet's first take a look at what normal science looks like.
p148
aVThis is normal science.
p149
aVNormal science is a nice balance between theory and experimentalists.
p150
aVThe theorist guy says, "I think this is what's going on,"
p151
aVthe experimentalist says, "You're wrong."
p152
aVIt goes back and forth, this works in physics, this in geology.
p153
aVBut if this is normal science, what does neuroscience look like?
p154
aVThis is what neuroscience looks like.
p155
aVWe have this mountain of data,
p156
aVwhich is anatomy, physiology and behavior.
p157
aVYou can't imagine how much detail we know about brains.
p158
aVThere were 28,000 people who went to the neuroscience conference this year,
p159
aVand every one of them is doing research in brains.
p160
aVA lot of data, but no theory.
p161
aVThere's a little wimpy box on top there.
p162
aa(lp163
VAnd theory has not played a role in any sort of grand way
p164
aVin the neurosciences.
p165
aVAnd it's a real shame.
p166
aVNow, why has this come about?
p167
aVIf you ask neuroscientists why is this the state of affairs,
p168
aVfirst, they'll admit it.
p169
aVBut if you ask them, they say,
p170
aVthere's various reasons we don't have a good brain theory.
p171
aVSome say we still don't have enough data,
p172
aVwe need more information, there's all these things we don't know.
p173
aVWell, I just told you there's data coming out of your ears.
p174
aVWe have so much information, we don't even know how to organize it.
p175
aVWhat good is more going to do?
p176
aVMaybe we'll be lucky and discover some magic thing, but I don't think so.
p177
aVThis is a symptom of the fact that we just don't have a theory.
p178
aVWe don't need more data, we need a good theory.
p179
aa(lp180
VAnother one is sometimes people say,
p181
aV"Brains are so complex, it'll take another 50 years."
p182
aVI even think Chris said something like this yesterday, something like,
p183
aVit's one of the most complicated things in the universe.
p184
aVThat's not true \u2014 you're more complicated than your brain.
p185
aVYou've got a brain.
p186
aVAnd although the brain looks very complicated,
p187
aVthings look complicated until you understand them.
p188
aVThat's always been the case.
p189
aVSo we can say, my neocortex, the part of the brain I'm interested in,
p190
aVhas 30 billion cells.
p191
aVBut, you know what? It's very, very regular.
p192
aVIn fact, it looks like it's the same thing repeated over and over again.
p193
aVIt's not as complex as it looks. That's not the issue.
p194
aa(lp195
VSome people say, brains can't understand brains.
p196
aVVery Zen-like. Woo.
p197
aa(lp198
V(Laughter)
p199
aa(lp200
VYou know, it sounds good, but why? I mean, what's the point?
p201
aVIt's just a bunch of cells. You understand your liver.
p202
aVIt's got a lot of cells in it too, right?
p203
aVSo, you know, I don't think there's anything to that.
p204
aVAnd finally, some people say,
p205
aV"I don't feel like a bunch of cells \u2014 I'm conscious.
p206
aVI've got this experience, I'm in the world.
p207
aVI can't be just a bunch of cells."
p208
aVWell, people used to believe there was a life force to be living,
p209
aVand we now know that's really not true at all.
p210
aVAnd there's really no evidence,
p211
aVother than that people just disbelieve that cells can do what they do.
p212
aVSo some people have fallen into the pit of metaphysical dualism,
p213
aVsome really smart people, too, but we can reject all that.
p214
aa(lp215
V(Laughter)
p216
aa(lp217
VNo, there's something else,
p218
aVsomething really fundamental, and it is:
p219
aVanother reason why we don't have a good brain theory
p220
aVis because we have an intuitive, strongly held but incorrect assumption
p221
aVthat has prevented us from seeing the answer.
p222
aVThere's something we believe that just, it's obvious, but it's wrong.
p223
aVNow, there's a history of this in science and before I tell you what it is,
p224
aVI'll tell you about the history of it in science.
p225
aVLook at other scientific revolutions \u2014
p226
aVthe solar system, that's Copernicus,
p227
aVDarwin's evolution, and tectonic plates, that's Wegener.
p228
aVThey all have a lot in common with brain science.
p229
aa(lp230
VFirst, they had a lot of unexplained data. A lot of it.
p231
aVBut it got more manageable once they had a theory.
p232
aVThe best minds were stumped \u2014 really smart people.
p233
aVWe're not smarter now than they were then;
p234
aVit just turns out it's really hard to think of things,
p235
aVbut once you've thought of them, it's easy to understand.
p236
aVMy daughters understood these three theories,
p237
aVin their basic framework, in kindergarten.
p238
aVIt's not that hard \u2014 here's the apple, here's the orange,
p239
aVthe Earth goes around, that kind of stuff.
p240
aa(lp241
VAnother thing is the answer was there all along,
p242
aVbut we kind of ignored it because of this obvious thing.
p243
aVIt was an intuitive, strongly held belief that was wrong.
p244
aVIn the case of the solar system,
p245
aVthe idea that the Earth is spinning,
p246
aVthe surface is going a thousand miles an hour,
p247
aVand it's going through the solar system at a million miles an hour \u2014
p248
aVthis is lunacy; we all know the Earth isn't moving.
p249
aVDo you feel like you're moving a thousand miles an hour?
p250
aVIf you said Earth was spinning around in space and was huge \u2014
p251
aVthey would lock you up, that's what they did back then.
p252
aVSo it was intuitive and obvious. Now, what about evolution?
p253
aa(lp254
VEvolution, same thing.
p255
aVWe taught our kids the Bible says God created all these species,
p256
aVcats are cats; dogs are dogs; people are people; plants are plants;
p257
aVthey don't change.
p258
aVNoah put them on the ark in that order, blah, blah.
p259
aVThe fact is, if you believe in evolution, we all have a common ancestor.
p260
aVWe all have a common ancestor with the plant in the lobby!
p261
aVThis is what evolution tells us. And it's true. It's kind of unbelievable.
p262
aVAnd the same thing about tectonic plates.
p263
aVAll the mountains and the continents
p264
aVare kind of floating around on top of the Earth.
p265
aVIt doesn't make any sense.
p266
aa(lp267
VSo what is the intuitive, but incorrect assumption,
p268
aVthat's kept us from understanding brains?
p269
aVI'll tell you. It'll seem obvious that it's correct. That's the point.
p270
aVThen I'll make an argument why you're incorrect on the other assumption.
p271
aVThe intuitive but obvious thing is:
p272
aVsomehow, intelligence is defined by behavior;
p273
aVwe're intelligent because of how we do things
p274
aVand how we behave intelligently.
p275
aVAnd I'm going to tell you that's wrong.
p276
aVIntelligence is defined by prediction.
p277
aa(lp278
VI'm going to work you through this in a few slides,
p279
aVand give you an example of what this means.
p280
aVHere's a system.
p281
aVEngineers and scientists like to look at systems like this.
p282
aVThey say, we have a thing in a box. We have its inputs and outputs.
p283
aVThe AI people said, the thing in the box is a programmable computer,
p284
aVbecause it's equivalent to a brain.
p285
aVWe'll feed it some inputs and get it to do something, have some behavior.
p286
aVAlan Turing defined the Turing test, which essentially says,
p287
aVwe'll know if something's intelligent if it behaves identical to a human \u2014
p288
aVa behavioral metric of what intelligence is
p289
aVthat has stuck in our minds for a long time.
p290
aa(lp291
VReality, though \u2014 I call it real intelligence.
p292
aVReal intelligence is built on something else.
p293
aVWe experience the world through a sequence of patterns,
p294
aVand we store them, and we recall them.
p295
aVWhen we recall them, we match them up against reality,
p296
aVand we're making predictions all the time.
p297
aVIt's an internal metric; there's an internal metric about us,
p298
aVsaying, do we understand the world, am I making predictions, and so on.
p299
aVYou're all being intelligent now, but you're not doing anything.
p300
aVMaybe you're scratching yourself, but you're not doing anything.
p301
aVBut you're being intelligent; you're understanding what I'm saying.
p302
aVBecause you're intelligent and you speak English,
p303
aVyou know the word at the end of this
p304
aVsentence.
p305
aa(lp306
VThe word came to you; you make these predictions all the time.
p307
aVWhat I'm saying is,
p308
aVthe internal prediction is the output in the neocortex,
p309
aVand somehow, prediction leads to intelligent behavior.
p310
aVHere's how that happens:
p311
aVLet's start with a non-intelligent brain.
p312
aVI'll argue a non-intelligent brain, we'll call it an old brain.
p313
aVAnd we'll say it's a non-mammal, like a reptile,
p314
aVsay, an alligator; we have an alligator.
p315
aVAnd the alligator has some very sophisticated senses.
p316
aVIt's got good eyes and ears and touch senses and so on,
p317
aVa mouth and a nose.
p318
aVIt has very complex behavior.
p319
aVIt can run and hide. It has fears and emotions. It can eat you.
p320
aVIt can attack. It can do all kinds of stuff.
p321
aVBut we don't consider the alligator very intelligent,
p322
aVnot in a human sort of way.
p323
aa(lp324
VBut it has all this complex behavior already.
p325
aVNow in evolution, what happened?
p326
aVFirst thing that happened in evolution with mammals
p327
aVis we started to develop a thing called the neocortex.
p328
aVI'm going to represent the neocortex by this box on top of the old brain.
p329
aVNeocortex means "new layer." It's a new layer on top of your brain.
p330
aVIt's the wrinkly thing on the top of your head
p331
aVthat got wrinkly because it got shoved in there and doesn't fit.
p332
aa(lp333
V(Laughter)
p334
aa(lp335
VLiterally, it's about the size of a table napkin
p336
aVand doesn't fit, so it's wrinkly.
p337
aVNow, look at how I've drawn this.
p338
aVThe old brain is still there.
p339
aVYou still have that alligator brain. You do. It's your emotional brain.
p340
aVIt's all those gut reactions you have.
p341
aVOn top of it, we have this memory system called the neocortex.
p342
aVAnd the memory system is sitting over the sensory part of the brain.
p343
aVSo as the sensory input comes in and feeds from the old brain,
p344
aVit also goes up into the neocortex.
p345
aVAnd the neocortex is just memorizing.
p346
aVIt's sitting there saying, I'm going to memorize all the things going on:
p347
aVwhere I've been, people I've seen, things I've heard, and so on.
p348
aVAnd in the future, when it sees something similar to that again,
p349
aVin a similar environment, or the exact same environment,
p350
aVit'll start playing it back: "Oh, I've been here before,"
p351
aVand when you were here before, this happened next.
p352
aVIt allows you to predict the future.
p353
aVIt literally feeds back the signals into your brain;
p354
aVthey'll let you see what's going to happen next,
p355
aVwill let you hear the word "sentence" before I said it.
p356
aVAnd it's this feeding back into the old brain
p357
aVthat will allow you to make more intelligent decisions.
p358
aa(lp359
VThis is the most important slide of my talk, so I'll dwell on it a little.
p360
aVAnd all the time you say, "Oh, I can predict things,"
p361
aVso if you're a rat and you go through a maze, and you learn the maze,
p362
aVnext time you're in one, you have the same behavior.
p363
aVBut suddenly, you're smarter; you say, "I recognize this maze,
p364
aVI know which way to go; I've been here before; I can envision the future."
p365
aVThat's what it's doing.
p366
aVThis is true for all mammals \u2014
p367
aVin humans, it got a lot worse.
p368
aVHumans actually developed the front of the neocortex,
p369
aVcalled the anterior part of the neocortex.
p370
aVAnd nature did a little trick.
p371
aVIt copied the posterior, the back part, which is sensory,
p372
aVand put it in the front.
p373
aVHumans uniquely have the same mechanism on the front,
p374
aVbut we use it for motor control.
p375
aa(lp376
VSo we're now able to do very sophisticated motor planning, things like that.
p377
aVI don't have time to explain, but to understand how a brain works,
p378
aVyou have to understand how the first part of the mammalian neocortex works,
p379
aVhow it is we store patterns and make predictions.
p380
aVLet me give you a few examples of predictions.
p381
aVI already said the word "sentence."
p382
aVIn music, if you've heard a song before,
p383
aVwhen you hear it, the next note pops into your head already \u2014
p384
aVyou anticipate it.
p385
aVWith an album, at the end of a song, the next song pops into your head.
p386
aVIt happens all the time, you make predictions.
p387
aa(lp388
VI have this thing called the "altered door" thought experiment.
p389
aVIt says, you have a door at home;
p390
aVwhen you're here, I'm changing it \u2014
p391
aVI've got a guy back at your house right now, moving the door around,
p392
aVmoving your doorknob over two inches.
p393
aVWhen you go home tonight, you'll put your hand out, reach for the doorknob,
p394
aVnotice it's in the wrong spot
p395
aVand go, "Whoa, something happened."
p396
aVIt may take a second, but something happened.
p397
aVI can change your doorknob in other ways \u2014
p398
aVmake it larger, smaller, change its brass to silver, make it a lever,
p399
aVI can change the door; put colors on, put windows in.
p400
aVI can change a thousand things about your door
p401
aVand in the two seconds you take to open it,
p402
aVyou'll notice something has changed.
p403
aa(lp404
VNow, the engineering approach, the AI approach to this,
p405
aVis to build a door database with all the door attributes.
p406
aVAnd as you go up to the door, we check them off one at time:
p407
aVdoor, door, color ...
p408
aVWe don't do that. Your brain doesn't do that.
p409
aVYour brain is making constant predictions all the time
p410
aVabout what will happen in your environment.
p411
aVAs I put my hand on this table, I expect to feel it stop.
p412
aVWhen I walk, every step, if I missed it by an eighth of an inch,
p413
aVI'll know something has changed.
p414
aVYou're constantly making predictions about your environment.
p415
aVI'll talk about vision, briefly.
p416
aVThis is a picture of a woman.
p417
aVWhen we look at people, our eyes saccade over two to three times a second.
p418
aVWe're not aware of it, but our eyes are always moving.
p419
aVWhen we look at a face, we typically go from eye to eye to nose to mouth.
p420
aVWhen your eye moves from eye to eye,
p421
aVif there was something else there like a nose,
p422
aVyou'd see a nose where an eye is supposed to be and go, "Oh, shit!"
p423
aa(lp424
V(Laughter)
p425
aa(lp426
V"There's something wrong about this person."
p427
aVThat's because you're making a prediction.
p428
aVIt's not like you just look over and say, "What am I seeing? A nose? OK."
p429
aVNo, you have an expectation of what you're going to see.
p430
aa(lp431
VEvery single moment.
p432
aVAnd finally, let's think about how we test intelligence.
p433
aVWe test it by prediction: What is the next word in this ...?
p434
aVThis is to this as this is to this. What is the next number in this sentence?
p435
aVHere's three visions of an object. What's the fourth one?
p436
aVThat's how we test it. It's all about prediction.
p437
aa(lp438
VSo what is the recipe for brain theory?
p439
aVFirst of all, we have to have the right framework.
p440
aVAnd the framework is a memory framework,
p441
aVnot a computational or behavior framework,
p442
aVit's a memory framework.
p443
aVHow do you store and recall these sequences of patterns?
p444
aVIt's spatiotemporal patterns.
p445
aa(lp446
VThen, if in that framework, you take a bunch of theoreticians \u2014
p447
aVbiologists generally are not good theoreticians.
p448
aVNot always, but generally, there's not a good history of theory in biology.
p449
aVI've found the best people to work with are physicists,
p450
aVengineers and mathematicians,
p451
aVwho tend to think algorithmically.
p452
aVThen they have to learn the anatomy and the physiology.
p453
aVYou have to make these theories very realistic in anatomical terms.
p454
aVAnyone who tells you their theory about how the brain works
p455
aVand doesn't tell you exactly how it's working
p456
aVand how the wiring works \u2014
p457
aVit's not a theory.
p458
aa(lp459
VAnd that's what we do at the Redwood Neuroscience Institute.
p460
aVI'd love to tell you we're making fantastic progress in this thing,
p461
aVand I expect to be back on this stage sometime in the not too distant future,
p462
aVto tell you about it.
p463
aVI'm really excited; this is not going to take 50 years.
p464
aa(lp465
VWhat will brain theory look like?
p466
aVFirst of all, it's going to be about memory.
p467
aVNot like computer memory \u2014 not at all like computer memory.
p468
aVIt's very different.
p469
aVIt's a memory of very high-dimensional patterns,
p470
aVlike the things that come from your eyes.
p471
aVIt's also memory of sequences:
p472
aVyou cannot learn or recall anything outside of a sequence.
p473
aVA song must be heard in sequence over time,
p474
aVand you must play it back in sequence over time.
p475
aVAnd these sequences are auto-associatively recalled,
p476
aVso if I see something, I hear something, it reminds me of it,
p477
aVand it plays back automatically.
p478
aVIt's an automatic playback.
p479
aVAnd prediction of future inputs is the desired output.
p480
aVAnd as I said, the theory must be biologically accurate,
p481
aVit must be testable and you must be able to build it.
p482
aVIf you don't build it, you don't understand it.
p483
aa(lp484
VOne more slide.
p485
aVWhat is this going to result in?
p486
aVAre we going to really build intelligent machines?
p487
aVAbsolutely. And it's going to be different than people think.
p488
aVNo doubt that it's going to happen, in my mind.
p489
aVFirst of all, we're going to build this stuff out of silicon.
p490
aVThe same techniques we use to build silicon computer memories,
p491
aVwe can use here.
p492
aVBut they're very different types of memories.
p493
aVAnd we'll attach these memories to sensors,
p494
aVand the sensors will experience real-live, real-world data,
p495
aVand learn about their environment.
p496
aa(lp497
VNow, it's very unlikely the first things you'll see are like robots.
p498
aVNot that robots aren't useful; people can build robots.
p499
aVBut the robotics part is the hardest part. That's old brain. That's really hard.
p500
aVThe new brain is easier than the old brain.
p501
aVSo first we'll do things that don't require a lot of robotics.
p502
aVSo you're not going to see C-3PO.
p503
aVYou're going to see things more like intelligent cars
p504
aVthat really understand what traffic is, what driving is
p505
aVand have learned that cars with the blinkers on for half a minute
p506
aVprobably aren't going to turn.
p507
aa(lp508
V(Laughter)
p509
aa(lp510
VWe can also do intelligent security systems.
p511
aVAnytime we're basically using our brain but not doing a lot of mechanics \u2014
p512
aVthose are the things that will happen first.
p513
aVBut ultimately, the world's the limit.
p514
aVI don't know how this will turn out.
p515
aVI know a lot of people who invented the microprocessor.
p516
aVAnd if you talk to them,
p517
aVthey knew what they were doing was really significant,
p518
aVbut they didn't really know what was going to happen.
p519
aVThey couldn't anticipate cell phones and the Internet
p520
aVand all this kind of stuff.
p521
aVThey just knew like, "We're going to build calculators
p522
aVand traffic-light controllers.
p523
aVBut it's going to be big!"
p524
aVIn the same way, brain science and these memories
p525
aVare going to be a very fundamental technology,
p526
aVand it will lead to unbelievable changes in the next 100 years.
p527
aVAnd I'm most excited about how we're going to use them in science.
p528
aVSo I think that's all my time \u2014 I'm over,
p529
aVand I'm going to end my talk right there.
p530
aasS'transcript_micsec'
p531
(lp532
I11000
aI19000
aI50000
aI81000
aI98000
aI100000
aI142000
aI197000
aI214000
aI215000
aI248000
aI250000
aI285000
aI322000
aI364000
aI402000
aI435000
aI440000
aI442000
aI478000
aI481000
aI514000
aI540000
aI571000
aI601000
aI626000
aI658000
aI693000
aI737000
aI759000
aI761000
aI823000
aI863000
aI893000
aI928000
aI975000
aI976000
aI987000
aI1003000
aI1017000
aI1047000
aI1061000
aI1101000
aI1129000
aI1157000
aI1158000
asS'talk_meta'
p533
(dp534
S'ratings'
p535
(dp536
S'ingenious'
p537
I377
sS'funny'
p538
I258
sS'inspiring'
p539
I556
sS'ok'
p540
I43
sS'fascinating'
p541
I752
sS'total_count'
p542
I3288
sS'persuasive'
p543
I268
sS'longwinded'
p544
I37
sS'informative'
p545
I637
sS'beautiful'
p546
I40
sS'jaw-dropping'
p547
I151
sS'obnoxious'
p548
I28
sS'confusing'
p549
I22
sS'courageous'
p550
I75
sS'unconvincing'
p551
I44
ssS'author'
p552
VJeff_Hawkins;
p553
sS'url'
p554
S'https://www.ted.com/talks/jeff_hawkins_on_how_brain_science_will_change_computing'
p555
sS'vidlen'
p556
I1211
sS'totalviews'
p557
I1379286
sS'title'
p558
VHow brain science will change computing
p559
sS'downloadlink'
p560
Vhttps://download.ted.com/talks/JeffHawkins_2003.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22
p561
sS'datepublished'
p562
cdatetime
datetime
p563
(S'\x07\xd7\x05\x15\x0b\x08\x00\x00\x00\x00'
tRp564
sS'datefilmed'
p565
g563
(S'\x07\xd7\x05\x15\x0b\x08\x00\x00\x00\x00'
tRp566
sS'alldata_JSON'
p567
S'{"viewed_count": 1379286, "speakers": [{"description": "Computer designer, brain researcher", "firstname": "Jeff", "title": "", "lastname": "Hawkins", "middleinitial": "", "whylisten": "<p>Jeff Hawkins&#39; <a href=\\"http://www.palm.com\\" target=\\"_blank\\">Palm</a>  PDA became such a widely used productivity tool during the 1990s that some fanatical users claimed it replaced their brains. But Hawkins&#39; deepest interest was in the brain itself. So after the success of the Palm and Treo, which he brought to market at Handspring, <strong>Hawkins delved into brain research</strong> at the <a href=\\"http://redwood.berkeley.edu/\\" target=\\"_blank\\">Redwood Center for Theoretical Neuroscience</a>  in Berkeley, Calif., and a new company called <a href=\\"http://www.numenta.com/\\" target=\\"_blank\\">Numenta</a>. </p><p>Hawkins&#39; dual goal is to achieve an understanding of how the human brain actually works -- and then develop software to mimic its functionality, <strong>delivering true artificial intelligence</strong>. In his book <em><a href=\\"http://www.onintelligence.org/\\" target=\\"_blank\\">On Intelligence</a></em> (2004) he lays out his compelling, controversial theory: Contrary to popular AI wisdom, the human neocortex doesn&#39;t work like a processor; rather, it relies on <strong>a memory system that stores and plays back experiences to help us predict, intelligently, what will happen next</strong>. He thinks that &quot;hierarchical temporal memory&quot; computer platforms, which mimic this functionality (and which Numenta might pioneer), could enable groundbreaking new applications that could powerfully extend human intelligence.</p>", "slug": "jeff_hawkins", "whotheyare": "Jeff Hawkins pioneered the development of PDAs such as the Palm and Treo. Now he\'s trying to understand how the human brain really works, and adapt its method -- which he describes as a deep system for storing memory -- to create new kinds of computers and tools.", "whatotherssay": "Even if Hawkins finds only a small sliver of the Holy Grail he seeks [in brain research], he\'ll add yet another industry-moving startup to his resume.", "id": 112, "photo_url": "https://pe.tedcdn.com/images/ted/8623_254x191.jpg"}], "current_talk": 125, "description": "Treo creator Jeff Hawkins urges us to take a new look at the brain -- to see it not as a fast processor, but as a memory system that stores and plays back experiences to help us predict, intelligently, what will happen next.", "language": "en", "url": "https://www.ted.com/talks/jeff_hawkins_on_how_brain_science_will_change_computing", "media": {"internal": {"podcast-high-en": {"uri": "https://download.ted.com/talks/JeffHawkins_2003-480p-en.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 140877715}, "podcast-low-en": {"uri": "https://download.ted.com/talks/JeffHawkins_2003-low-en.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 27799452}, "podcast-high": {"uri": "https://download.ted.com/talks/JeffHawkins_2003-480p.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 140871735}, "180k": {"uri": "https://download.ted.com/talks/JeffHawkins_2003-180k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 27681362}, "64k": {"uri": "https://download.ted.com/talks/JeffHawkins_2003-64k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 9954981}, "1500k": {"uri": "https://download.ted.com/talks/JeffHawkins_2003-1500k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 221597075}, "450k": {"uri": "https://download.ted.com/talks/JeffHawkins_2003-450k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 68629681}, "podcast-regular": {"uri": "https://download.ted.com/talks/JeffHawkins_2003.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 68904283}, "950k": {"uri": "https://download.ted.com/talks/JeffHawkins_2003-950k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 140618469}, "podcast-light": {"uri": "https://download.ted.com/talks/JeffHawkins_2003-light.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 10054801}, "320k": {"uri": "https://download.ted.com/talks/JeffHawkins_2003-320k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 48933099}, "600k": {"uri": "https://download.ted.com/talks/JeffHawkins_2003-600k.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "mime_type": "video/mp4", "filesize_bytes": 91356784}}}, "comments": {"count": 230, "id": 117, "talk_id": 125}, "slug": "jeff_hawkins_on_how_brain_science_will_change_computing", "threadId": 117, "talks": [{"event": "TED2003", "player_talks": [{"event": "TED2003", "slug": "jeff_hawkins_on_how_brain_science_will_change_computing", "filmed": 1044144000, "targeting": {"event": "TED2003", "tag": "AI,brain,cognitive science,computers,intelligence,memory,science,technology", "id": 125, "talk": "jeff_hawkins_on_how_brain_science_will_change_computing", "year": "2003"}, "adDuration": "3.33", "external": null, "title": "How brain science will change computing", "postAdDuration": "0.83", "published": 1179760080, "thumb": "https://pi.tedcdn.com/r/pe.tedcdn.com/images/ted/dfc244d5b81ab35ce80a3c4f19877b23f8be7a27_2880x1620.jpg?quality=89&w=600", "name": "Jeff Hawkins: How brain science will change computing", "languages": [{"languageCode": "ar", "endonym": "\\u0627\\u0644\\u0639\\u0631\\u0628\\u064a\\u0629", "isRtl": true, "ianaCode": "ar", "languageName": "Arabic"}, {"languageCode": "bg", "endonym": "\\u0431\\u044a\\u043b\\u0433\\u0430\\u0440\\u0441\\u043a\\u0438", "isRtl": false, "ianaCode": "bg", "languageName": "Bulgarian"}, {"languageCode": "zh-cn", "endonym": "\\u4e2d\\u6587 (\\u7b80\\u4f53)", "isRtl": false, "ianaCode": "zh-Hans", "languageName": "Chinese, Simplified"}, {"languageCode": "zh-tw", "endonym": "\\u4e2d\\u6587 (\\u7e41\\u9ad4)", "isRtl": false, "ianaCode": "zh-Hant", "languageName": "Chinese, Traditional"}, {"languageCode": "hr", "endonym": "Hrvatski", "isRtl": false, "ianaCode": "hr", "languageName": "Croatian"}, {"languageCode": "da", "endonym": "Dansk", "isRtl": false, "ianaCode": "da", "languageName": "Danish"}, {"languageCode": "nl", "endonym": "Nederlands", "isRtl": false, "ianaCode": "nl", "languageName": "Dutch"}, {"languageCode": "en", "endonym": "English", "isRtl": false, "ianaCode": "en", "languageName": "English"}, {"languageCode": "fi", "endonym": "Suomi", "isRtl": false, "ianaCode": "fi", "languageName": "Finnish"}, {"languageCode": "fr", "endonym": "Fran\\u00e7ais", "isRtl": false, "ianaCode": "fr", "languageName": "French"}, {"languageCode": "ka", "endonym": "\\u10e5\\u10d0\\u10e0\\u10d7\\u10e3\\u10da\\u10d8", "isRtl": false, "ianaCode": "ka", "languageName": "Georgian"}, {"languageCode": "de", "endonym": "Deutsch", "isRtl": false, "ianaCode": "de", "languageName": "German"}, {"languageCode": "el", "endonym": "\\u0395\\u03bb\\u03bb\\u03b7\\u03bd\\u03b9\\u03ba\\u03ac", "isRtl": false, "ianaCode": "el", "languageName": "Greek"}, {"languageCode": "he", "endonym": "\\u05e2\\u05d1\\u05e8\\u05d9\\u05ea", "isRtl": true, "ianaCode": "he", "languageName": "Hebrew"}, {"languageCode": "hu", "endonym": "Magyar", "isRtl": false, "ianaCode": "hu", "languageName": "Hungarian"}, {"languageCode": "it", "endonym": "Italiano", "isRtl": false, "ianaCode": "it", "languageName": "Italian"}, {"languageCode": "ja", "endonym": "\\u65e5\\u672c\\u8a9e", "isRtl": false, "ianaCode": "ja", "languageName": "Japanese"}, {"languageCode": "ko", "endonym": "\\ud55c\\uad6d\\uc5b4", "isRtl": false, "ianaCode": "ko", "languageName": "Korean"}, {"languageCode": "mk", "endonym": "\\u043c\\u0430\\u043a\\u0435\\u0434\\u043e\\u043d\\u0441\\u043a\\u0438", "isRtl": false, "ianaCode": "mk", "languageName": "Macedonian"}, {"languageCode": "nb", "endonym": "Norsk bokm\\u00e5l", "isRtl": false, "ianaCode": "nb", "languageName": "Norwegian Bokmal"}, {"languageCode": "fa", "endonym": "\\u0641\\u0627\\u0631\\u0633\\u0649", "isRtl": true, "ianaCode": "fa", "languageName": "Persian"}, {"languageCode": "pl", "endonym": "Polski", "isRtl": false, "ianaCode": "pl", "languageName": "Polish"}, {"languageCode": "pt", "endonym": "Portugu\\u00eas de Portugal", "isRtl": false, "ianaCode": "pt", "languageName": "Portuguese"}, {"languageCode": "pt-br", "endonym": "Portugu\\u00eas brasileiro", "isRtl": false, "ianaCode": "pt-BR", "languageName": "Portuguese, Brazilian"}, {"languageCode": "ro", "endonym": "Rom\\u00e2n\\u0103", "isRtl": false, "ianaCode": "ro", "languageName": "Romanian"}, {"languageCode": "ru", "endonym": "\\u0420\\u0443\\u0441\\u0441\\u043a\\u0438\\u0439", "isRtl": false, "ianaCode": "ru", "languageName": "Russian"}, {"languageCode": "es", "endonym": "Espa\\u00f1ol", "isRtl": false, "ianaCode": "es", "languageName": "Spanish"}, {"languageCode": "tr", "endonym": "T\\u00fcrk\\u00e7e", "isRtl": false, "ianaCode": "tr", "languageName": "Turkish"}, {"languageCode": "vi", "endonym": "Ti\\u1ebfng Vi\\u1ec7t", "isRtl": false, "ianaCode": "vi", "languageName": "Vietnamese"}], "nativeLanguage": "en", "tags": ["AI", "brain", "cognitive science", "computers", "intelligence", "memory", "science", "technology"], "speaker": "Jeff Hawkins", "isSubtitleRequired": false, "introDuration": 11.82, "duration": 1211, "id": 125, "resources": {"h264": [{"bitrate": 320, "file": "https://download.ted.com/talks/JeffHawkins_2003-320k.mp4?dnt"}], "hls": {"maiTargeting": {"event": "TED2003", "tag": "AI,brain,cognitive science,computers,intelligence,memory,science,technology", "id": 125, "talk": "jeff_hawkins_on_how_brain_science_will_change_computing", "year": "2003"}, "metadata": "https://hls.ted.com/talks/125.json", "stream": "https://hls.ted.com/talks/125.m3u8", "adUrl": "https://pubads.g.doubleclick.net/gampad/ads?ciu_szs=300x250%2C512x288%2C120x60%2C320x50%2C6x7%2C6x8&correlator=%5Bcorrelator%5D&cust_params=event%3DTED2003%26id%3D125%26tag%3DAI%2Cbrain%2Ccognitive%2Bscience%2Ccomputers%2Cintelligence%2Cmemory%2Cscience%2Ctechnology%26talk%3Djeff_hawkins_on_how_brain_science_will_change_computing%26year%3D2003&env=vp&gdfp_req=1&impl=s&iu=%2F5641%2Fmobile%2Fios%2Fweb&output=xml_vast2&sz=640x360&unviewed_position_start=1&url=%5Breferrer%5D"}}, "canonical": "https://www.ted.com/talks/jeff_hawkins_on_how_brain_science_will_change_computing"}], "hero_load": "https://pi.tedcdn.com/r/pe.tedcdn.com/images/ted/dfc244d5b81ab35ce80a3c4f19877b23f8be7a27_2880x1620.jpg?q=50&w=15", "duration": 1211, "id": 125, "ratings": [{"count": 75, "id": 3, "name": "Courageous"}, {"count": 377, "id": 9, "name": "Ingenious"}, {"count": 258, "id": 7, "name": "Funny"}, {"count": 40, "id": 1, "name": "Beautiful"}, {"count": 44, "id": 21, "name": "Unconvincing"}, {"count": 37, "id": 11, "name": "Longwinded"}, {"count": 556, "id": 10, "name": "Inspiring"}, {"count": 637, "id": 8, "name": "Informative"}, {"count": 752, "id": 22, "name": "Fascinating"}, {"count": 22, "id": 2, "name": "Confusing"}, {"count": 268, "id": 24, "name": "Persuasive"}, {"count": 151, "id": 23, "name": "Jaw-dropping"}, {"count": 28, "id": 26, "name": "Obnoxious"}, {"count": 43, "id": 25, "name": "OK"}], "speakers": [{"description": "Computer designer, brain researcher", "firstname": "Jeff", "title": "", "lastname": "Hawkins", "middleinitial": "", "whylisten": "<p>Jeff Hawkins&#39; <a href=\\"http://www.palm.com\\" target=\\"_blank\\">Palm</a>  PDA became such a widely used productivity tool during the 1990s that some fanatical users claimed it replaced their brains. But Hawkins&#39; deepest interest was in the brain itself. So after the success of the Palm and Treo, which he brought to market at Handspring, <strong>Hawkins delved into brain research</strong> at the <a href=\\"http://redwood.berkeley.edu/\\" target=\\"_blank\\">Redwood Center for Theoretical Neuroscience</a>  in Berkeley, Calif., and a new company called <a href=\\"http://www.numenta.com/\\" target=\\"_blank\\">Numenta</a>. </p><p>Hawkins&#39; dual goal is to achieve an understanding of how the human brain actually works -- and then develop software to mimic its functionality, <strong>delivering true artificial intelligence</strong>. In his book <em><a href=\\"http://www.onintelligence.org/\\" target=\\"_blank\\">On Intelligence</a></em> (2004) he lays out his compelling, controversial theory: Contrary to popular AI wisdom, the human neocortex doesn&#39;t work like a processor; rather, it relies on <strong>a memory system that stores and plays back experiences to help us predict, intelligently, what will happen next</strong>. He thinks that &quot;hierarchical temporal memory&quot; computer platforms, which mimic this functionality (and which Numenta might pioneer), could enable groundbreaking new applications that could powerfully extend human intelligence.</p>", "slug": "jeff_hawkins", "whotheyare": "Jeff Hawkins pioneered the development of PDAs such as the Palm and Treo. Now he\'s trying to understand how the human brain really works, and adapt its method -- which he describes as a deep system for storing memory -- to create new kinds of computers and tools.", "whatotherssay": "Even if Hawkins finds only a small sliver of the Holy Grail he seeks [in brain research], he\'ll add yet another industry-moving startup to his resume.", "id": 112, "photo_url": "https://pe.tedcdn.com/images/ted/8623_254x191.jpg"}], "title": "How brain science will change computing", "take_action": null, "comments": 117, "more_resources": null, "hero": "https://pe.tedcdn.com/images/ted/dfc244d5b81ab35ce80a3c4f19877b23f8be7a27_2880x1620.jpg", "description": "Treo creator Jeff Hawkins urges us to take a new look at the brain -- to see it not as a fast processor, but as a memory system that stores and plays back experiences to help us predict, intelligently, what will happen next.", "tags": ["AI", "brain", "cognitive science", "computers", "intelligence", "memory", "science", "technology"], "downloads": {"languages": [{"languageCode": "ar", "endonym": "\\u0627\\u0644\\u0639\\u0631\\u0628\\u064a\\u0629", "isRtl": true, "ianaCode": "ar", "languageName": "Arabic"}, {"languageCode": "bg", "endonym": "\\u0431\\u044a\\u043b\\u0433\\u0430\\u0440\\u0441\\u043a\\u0438", "isRtl": false, "ianaCode": "bg", "languageName": "Bulgarian"}, {"languageCode": "zh-cn", "endonym": "\\u4e2d\\u6587 (\\u7b80\\u4f53)", "isRtl": false, "ianaCode": "zh-Hans", "languageName": "Chinese, Simplified"}, {"languageCode": "zh-tw", "endonym": "\\u4e2d\\u6587 (\\u7e41\\u9ad4)", "isRtl": false, "ianaCode": "zh-Hant", "languageName": "Chinese, Traditional"}, {"languageCode": "hr", "endonym": "Hrvatski", "isRtl": false, "ianaCode": "hr", "languageName": "Croatian"}, {"languageCode": "da", "endonym": "Dansk", "isRtl": false, "ianaCode": "da", "languageName": "Danish"}, {"languageCode": "nl", "endonym": "Nederlands", "isRtl": false, "ianaCode": "nl", "languageName": "Dutch"}, {"languageCode": "en", "endonym": "English", "isRtl": false, "ianaCode": "en", "languageName": "English"}, {"languageCode": "fi", "endonym": "Suomi", "isRtl": false, "ianaCode": "fi", "languageName": "Finnish"}, {"languageCode": "fr", "endonym": "Fran\\u00e7ais", "isRtl": false, "ianaCode": "fr", "languageName": "French"}, {"languageCode": "ka", "endonym": "\\u10e5\\u10d0\\u10e0\\u10d7\\u10e3\\u10da\\u10d8", "isRtl": false, "ianaCode": "ka", "languageName": "Georgian"}, {"languageCode": "de", "endonym": "Deutsch", "isRtl": false, "ianaCode": "de", "languageName": "German"}, {"languageCode": "el", "endonym": "\\u0395\\u03bb\\u03bb\\u03b7\\u03bd\\u03b9\\u03ba\\u03ac", "isRtl": false, "ianaCode": "el", "languageName": "Greek"}, {"languageCode": "he", "endonym": "\\u05e2\\u05d1\\u05e8\\u05d9\\u05ea", "isRtl": true, "ianaCode": "he", "languageName": "Hebrew"}, {"languageCode": "hu", "endonym": "Magyar", "isRtl": false, "ianaCode": "hu", "languageName": "Hungarian"}, {"languageCode": "it", "endonym": "Italiano", "isRtl": false, "ianaCode": "it", "languageName": "Italian"}, {"languageCode": "ja", "endonym": "\\u65e5\\u672c\\u8a9e", "isRtl": false, "ianaCode": "ja", "languageName": "Japanese"}, {"languageCode": "ko", "endonym": "\\ud55c\\uad6d\\uc5b4", "isRtl": false, "ianaCode": "ko", "languageName": "Korean"}, {"languageCode": "mk", "endonym": "\\u043c\\u0430\\u043a\\u0435\\u0434\\u043e\\u043d\\u0441\\u043a\\u0438", "isRtl": false, "ianaCode": "mk", "languageName": "Macedonian"}, {"languageCode": "nb", "endonym": "Norsk bokm\\u00e5l", "isRtl": false, "ianaCode": "nb", "languageName": "Norwegian Bokmal"}, {"languageCode": "fa", "endonym": "\\u0641\\u0627\\u0631\\u0633\\u0649", "isRtl": true, "ianaCode": "fa", "languageName": "Persian"}, {"languageCode": "pl", "endonym": "Polski", "isRtl": false, "ianaCode": "pl", "languageName": "Polish"}, {"languageCode": "pt", "endonym": "Portugu\\u00eas de Portugal", "isRtl": false, "ianaCode": "pt", "languageName": "Portuguese"}, {"languageCode": "pt-br", "endonym": "Portugu\\u00eas brasileiro", "isRtl": false, "ianaCode": "pt-BR", "languageName": "Portuguese, Brazilian"}, {"languageCode": "ro", "endonym": "Rom\\u00e2n\\u0103", "isRtl": false, "ianaCode": "ro", "languageName": "Romanian"}, {"languageCode": "ru", "endonym": "\\u0420\\u0443\\u0441\\u0441\\u043a\\u0438\\u0439", "isRtl": false, "ianaCode": "ru", "languageName": "Russian"}, {"languageCode": "es", "endonym": "Espa\\u00f1ol", "isRtl": false, "ianaCode": "es", "languageName": "Spanish"}, {"languageCode": "tr", "endonym": "T\\u00fcrk\\u00e7e", "isRtl": false, "ianaCode": "tr", "languageName": "Turkish"}, {"languageCode": "vi", "endonym": "Ti\\u1ebfng Vi\\u1ec7t", "isRtl": false, "ianaCode": "vi", "languageName": "Vietnamese"}], "subtitledDownloads": {"el": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-el.mp4", "name": "Greek", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-el.mp4"}, "en": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-en.mp4", "name": "English", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-en.mp4"}, "vi": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-vi.mp4", "name": "Vietnamese", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-vi.mp4"}, "it": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-it.mp4", "name": "Italian", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-it.mp4"}, "ar": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-ar.mp4", "name": "Arabic", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-ar.mp4"}, "pt-br": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-pt-br.mp4", "name": "Portuguese, Brazilian", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-pt-br.mp4"}, "es": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-es.mp4", "name": "Spanish", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-es.mp4"}, "ru": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-ru.mp4", "name": "Russian", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-ru.mp4"}, "nl": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-nl.mp4", "name": "Dutch", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-nl.mp4"}, "pt": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-pt.mp4", "name": "Portuguese", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-pt.mp4"}, "zh-tw": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-zh-tw.mp4", "name": "Chinese, Traditional", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-zh-tw.mp4"}, "nb": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-nb.mp4", "name": "Norwegian Bokmal", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-nb.mp4"}, "tr": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-tr.mp4", "name": "Turkish", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-tr.mp4"}, "zh-cn": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-zh-cn.mp4", "name": "Chinese, Simplified", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-zh-cn.mp4"}, "ro": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-ro.mp4", "name": "Romanian", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-ro.mp4"}, "pl": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-pl.mp4", "name": "Polish", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-pl.mp4"}, "fr": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-fr.mp4", "name": "French", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-fr.mp4"}, "bg": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-bg.mp4", "name": "Bulgarian", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-bg.mp4"}, "hr": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-hr.mp4", "name": "Croatian", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-hr.mp4"}, "de": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-de.mp4", "name": "German", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-de.mp4"}, "da": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-da.mp4", "name": "Danish", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-da.mp4"}, "fa": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-fa.mp4", "name": "Persian", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-fa.mp4"}, "fi": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-fi.mp4", "name": "Finnish", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-fi.mp4"}, "hu": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-hu.mp4", "name": "Hungarian", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-hu.mp4"}, "ja": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-ja.mp4", "name": "Japanese", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-ja.mp4"}, "he": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-he.mp4", "name": "Hebrew", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-he.mp4"}, "ka": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-ka.mp4", "name": "Georgian", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-ka.mp4"}, "ko": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-ko.mp4", "name": "Korean", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-ko.mp4"}, "mk": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p-mk.mp4", "name": "Macedonian", "low": "https://download.ted.com/talks/JeffHawkins_2003-low-mk.mp4"}}, "nativeDownloads": {"high": "https://download.ted.com/talks/JeffHawkins_2003-480p.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "medium": "https://download.ted.com/talks/JeffHawkins_2003.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22", "low": "https://download.ted.com/talks/JeffHawkins_2003-light.mp4?apikey=489b859150fc58263f17110eeb44ed5fba4a3b22"}, "id": 125, "audioDownload": null}, "related_talks": [{"viewed_count": 3969100, "hero": "https://pe.tedcdn.com/images/ted/ca8d90c65e9e596127b720b648a07dfd2ea45e7d_2880x1620.jpg", "title": "3 clues to understanding your brain", "id": 184, "speaker": "VS Ramachandran", "duration": 1414, "slug": "vilayanur_ramachandran_on_your_mind"}, {"viewed_count": 1504649, "hero": "https://pe.tedcdn.com/images/ted/35408_480x360.jpg", "title": "A look inside the brain in real time", "id": 236, "speaker": "Christopher deCharms", "duration": 242, "slug": "christopher_decharms_scans_the_brain_in_real_time"}, {"viewed_count": 583221, "hero": "https://pe.tedcdn.com/images/ted/49376_480x360.jpg", "title": "A computer that works like the brain", "id": 320, "speaker": "Kwabena Boahen", "duration": 982, "slug": "kwabena_boahen_on_a_computer_that_works_like_the_brain"}, {"viewed_count": 1921916, "hero": "https://pe.tedcdn.com/images/ted/b4b4b1887a890ba5efc98b4d4fe20d6b55fe6dbd_2880x1620.jpg", "title": "What happens in your brain when you pay attention?", "id": 2798, "speaker": "Mehdi Ordikhani-Seyedlar", "duration": 392, "slug": "mehdi_ordikhani_seyedlar_what_happens_in_your_brain_when_you_pay_attention"}, {"viewed_count": 1986184, "hero": "https://pe.tedcdn.com/images/ted/9bd2cc9f4130b1c408721e3d755e13d168cb38a0_1600x1200.jpg", "title": "Get ready for hybrid thinking", "id": 2015, "speaker": "Ray Kurzweil", "duration": 592, "slug": "ray_kurzweil_get_ready_for_hybrid_thinking"}, {"viewed_count": 1828780, "hero": "https://pe.tedcdn.com/images/ted/353545d58703d32d2bd05323faa35b2cfc389e42_2880x1620.jpg", "title": "This is your brain on communication", "id": 2495, "speaker": "Uri Hasson", "duration": 891, "slug": "uri_hasson_this_is_your_brain_on_communication"}], "recorded_at": "2003-02-02T00:00:00.000+00:00", "slug": "jeff_hawkins_on_how_brain_science_will_change_computing", "speaker_name": "Jeff Hawkins", "viewed_count": 1379286, "event_badge": null, "event_blurb": "This talk was presented at an official TED conference, and was featured by our editors on the home page.", "recommendations": null, "corrections": null}], "event": "TED2003", "name": "Jeff Hawkins: How brain science will change computing"}'
p568
sS'keywords'
p569
(lp570
VAI
p571
aVbrain
p572
aVcognitive science
p573
aVcomputers
p574
aVintelligence
p575
aVmemory
p576
aVscience
p577
aVtechnology
p578
asS'datecrawled'
p579
g563
(S'\x07\xe1\n\x17\x01(\x10\t93'
tRp580
sS'id'
p581
I125
ss.